From mtraverso at gmail.com  Sun Jan  1 19:01:22 2006
From: mtraverso at gmail.com (Martin Traverso)
Date: Sun Jan  1 19:01:25 2006
Subject: [antlr-interest] Syntactic predicate in lexer rule
Message-ID: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>

Hi all,

Happy new year!

I'm having some trouble with the following grammar. I would think the
syntactic predicate in FLOAT should be enough to distinguish between a FLOAT
and an INTEGER followed by two dots, but when parsing stuff like "1..2" the
lexer tries to match a FLOAT. Any ideas why?


grammar T;

range:  number ('..' number)?;
number: INTEGER | FLOAT;

FLOAT:  (DIGITS '.' DIGITS) => DIGITS '.' DIGITS;

INTEGER : DIGITS;

fragment
DIGITS: ('0'..'9')+;


Thanks!

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060101/99d7ffab/attachment.html
From mtraverso at gmail.com  Mon Jan  2 01:41:19 2006
From: mtraverso at gmail.com (Martin Traverso)
Date: Mon Jan  2 01:41:21 2006
Subject: [antlr-interest] Selectively disabling lexer rules
Message-ID: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>

Ter,

Is there a way to selectively disable lexer rules in ANTLR v3? Let me
explain the problem I'm trying to solve. Maybe you have other ideas.

Ruby has a conditional operator like Java:

a ? b : c

But the question mark is also used to represent character literals like so:

?x   -> the character 'x'

The character after the ? has to be a printable character, so new lines,
spaces, etc are not allowed (for those, the literal is ?\n, ?\s, etc)

The problem is that in the conditional expression a space is not required
after the ?. Thus, "a ?b : c" is a valid expression. So you see the
conflict. When parsing that expression the lexer cannot decide whether to
match a character literal or the ? operator.

One approach I considered was to use a flag to guard whether the token for
character literals can be matched (via a semantic predicate) and turn it off
and on when appropriate. Is there a better alternative?

Thanks,
Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060102/223871aa/attachment.html
From navinksinha at lycos.com  Mon Jan  2 03:36:16 2006
From: navinksinha at lycos.com (Navin Sinha)
Date: Mon Jan  2 03:36:21 2006
Subject: [antlr-interest] Handling unicode strings in ANTLR
Message-ID: <20060102113616.ED94ACA09C@ws7-4.us4.outblaze.com>

Hi,
We have used ANTLR to write a translator for a new programming language, Indus - an agent-oriented programming language for distributed systems. We are working on internationalistion of the application. We want user-defined strings in different languages to be treated by the ANTLR-based parser as string literals and ensure that these strings are displayed properly by the user interfaces. 

Can anyone let me know how this can be done ?

Thanx,
Navin

-- 
_______________________________________________

Search for businesses by name, location, or phone number.  -Lycos Yellow Pages

http://r.lycos.com/r/yp_emailfooter/http://yellowpages.lycos.com/default.asp?SRC=lycos10

From ewbank at gmail.com  Mon Jan  2 06:17:30 2006
From: ewbank at gmail.com (Bryan Ewbank)
Date: Mon Jan  2 06:17:33 2006
Subject: [antlr-interest] Fwd: Selectively disabling lexer rules
In-Reply-To: <dd3a065f0601020617n1dce5d59g655e7a2ead977dbb@mail.gmail.com>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<dd3a065f0601020617n1dce5d59g655e7a2ead977dbb@mail.gmail.com>
Message-ID: <dd3a065f0601020617k29103969y6ce5640bdd149f22@mail.gmail.com>

Okay, now to the group :-(

On 1/2/06, Martin Traverso <mtraverso@gmail.com> wrote:
> Ruby has a conditional operator like Java:
>
> a ? b : c
>
>  But the question mark is also used to represent character literals like so:
>
> ?x   -> the character 'x'
>
> The character after the ? has to be a printable character, so new lines,
> spaces, etc are not allowed (for those, the literal is ?\n, ?\s, etc)
>
> The problem is that in the conditional expression a space is not required
> after the ?. Thus, "a ?b : c" is a valid expression. So you see the
> conflict. When parsing that expression the lexer cannot decide whether to
> match a character literal or the ? operator.

I don't think the /lexer/ is where you'd want to do this, because it's
not really a lexical issue; it's a parsing issue.

Perhaps it would help to consider "?" as an ambiguous operator (binary
or unary, based on context) in the same way that "+" and "-" are
commonly treated?

T'would mean that you with need to distinguish "?" followed by
whitespace (always a binary operator) from "?" followed by a printable
character (binary or unary, by context).

Hope this helps,
- Bryan
From seclib at seclib.com  Mon Jan  2 09:20:44 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Mon Jan  2 09:21:05 2006
Subject: [antlr-interest] Re: Syntactic predicate in lexer rule
In-Reply-To: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>
References: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>
Message-ID: <43B960EC.5050900@seclib.com>

The lexer will definitely "try" to match FLOAT, if the token starts with 
DIGITS. But it will not accept it, since the syntactic predication will 
fail. That's expected behavior.

Martin Traverso wrote:
> Hi all,
> 
> Happy new year!
> 
> I'm having some trouble with the following grammar. I would think the 
> syntactic predicate in FLOAT should be enough to distinguish between a 
> FLOAT and an INTEGER followed by two dots, but when parsing stuff like 
> "1..2" the lexer tries to match a FLOAT. Any ideas why?
> 
> 
> grammar T;
> 
> range:  number ('..' number)?;
> number: INTEGER | FLOAT;
> 
> FLOAT:  (DIGITS '.' DIGITS) => DIGITS '.' DIGITS;
> 
> INTEGER : DIGITS;
> 
> fragment
> DIGITS: ('0'..'9')+;
> 
> 
> Thanks!
> 
> Martin

From madcapmaggie at yahoo.com  Mon Jan  2 09:59:11 2006
From: madcapmaggie at yahoo.com (Peggy Fieland)
Date: Mon Jan  2 09:59:14 2006
Subject: [antlr-interest] Handling unicode strings in ANTLR
In-Reply-To: <20060102113616.ED94ACA09C@ws7-4.us4.outblaze.com>
Message-ID: <20060102175911.76389.qmail@web30213.mail.mud.yahoo.com>

You specify the CharVocabulary to include all valid
unicode characters.  If you're generating JAVA that's
pretty much it.  I don't know if version 2.7.6 has the
Unicode C++ support built in or not -- in any case
there's a unicode example in the antlr distribution
examples.

Peggy

--- Navin Sinha <navinksinha@lycos.com> wrote:

> Hi,
> We have used ANTLR to write a translator for a new
> programming language, Indus - an agent-oriented
> programming language for distributed systems. We are
> working on internationalistion of the application.
> We want user-defined strings in different languages
> to be treated by the ANTLR-based parser as string
> literals and ensure that these strings are displayed
> properly by the user interfaces. 
> 
> Can anyone let me know how this can be done ?
> 
> Thanx,
> Navin
> 
> -- 
> _______________________________________________
> 
> Search for businesses by name, location, or phone
> number.  -Lycos Yellow Pages
> 
>
http://r.lycos.com/r/yp_emailfooter/http://yellowpages.lycos.com/default.asp?SRC=lycos10
> 
> 

From parrt at cs.usfca.edu  Mon Jan  2 10:25:19 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan  2 10:26:59 2006
Subject: [antlr-interest] Syntactic predicate in lexer rule
In-Reply-To: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>
References: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>
Message-ID: <274F0FE9-90E2-4EED-859C-72495ED59E87@cs.usfca.edu>

On Jan 1, 2006, at 7:01 PM, Martin Traverso wrote:
> FLOAT:  (DIGITS '.' DIGITS) => DIGITS '.' DIGITS;

An alt with a single pred makes no sense, I'm afraid.  Predicates  
indicate which of 2+ alts to match.

Ter
From parrt at cs.usfca.edu  Mon Jan  2 10:28:12 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan  2 10:29:51 2006
Subject: [antlr-interest] Selectively disabling lexer rules
In-Reply-To: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
Message-ID: <81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>


On Jan 2, 2006, at 1:41 AM, Martin Traverso wrote:

> Ter,
>
> Is there a way to selectively disable lexer rules in ANTLR v3? Let  
> me explain the problem I'm trying to solve. Maybe you have other  
> ideas.
>
> Ruby has a conditional operator like Java:
>
> a ? b : c
>
> But the question mark is also used to represent character literals  
> like so:
>
> ?x   -> the character 'x'
>
> The character after the ? has to be a printable character, so new  
> lines, spaces, etc are not allowed (for those, the literal is ?\n, ? 
> \s, etc)
>
> The problem is that in the conditional expression a space is not  
> required after the ?.

Ugh...ruby is full of these landmines...why do languages by people  
who don't know how to parse become popular!??  ugh.

> Thus, "a ?b : c" is a valid expression. So you see the conflict.  
> When parsing that expression the lexer cannot decide whether to  
> match a character literal or the ? operator.

You could use a simple sem pred after the '?' to look at the next  
chars, looking for ':' I suppose.

If you want to gate out a rule, use {...}?=> on the front of it. :)

Ter
From parrt at cs.usfca.edu  Mon Jan  2 10:30:10 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan  2 10:31:50 2006
Subject: [antlr-interest] Syntactic predicate in lexer rule
In-Reply-To: <274F0FE9-90E2-4EED-859C-72495ED59E87@cs.usfca.edu>
References: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>
	<274F0FE9-90E2-4EED-859C-72495ED59E87@cs.usfca.edu>
Message-ID: <D86CFD5F-D329-4575-BC78-AE55DC223BB3@cs.usfca.edu>


On Jan 2, 2006, at 10:25 AM, Terence Parr wrote:

> On Jan 1, 2006, at 7:01 PM, Martin Traverso wrote:
>> FLOAT:  (DIGITS '.' DIGITS) => DIGITS '.' DIGITS;
>
> An alt with a single pred makes no sense, I'm afraid.  Predicates  
> indicate which of 2+ alts to match.

Actually, I take this back.  There is a quirk i just realized.  Syn  
preds are converted to sem preds (at least for now) for  
implementation, hence, they will be hoisted like any other  
predicate.  The (DIGITS '.' DIGITS) is converted to a boolean test  
and hoisted into the artificial Tokens rule and that might work.

I suggest looking at the DFA for Tokens rule to see how it  
looks...should be an option in antlrworks for that.

Ter
From mtraverso at gmail.com  Mon Jan  2 18:03:38 2006
From: mtraverso at gmail.com (Martin Traverso)
Date: Mon Jan  2 18:03:40 2006
Subject: [antlr-interest] Fwd: Selectively disabling lexer rules
In-Reply-To: <dd3a065f0601020617k29103969y6ce5640bdd149f22@mail.gmail.com>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<dd3a065f0601020617n1dce5d59g655e7a2ead977dbb@mail.gmail.com>
	<dd3a065f0601020617k29103969y6ce5640bdd149f22@mail.gmail.com>
Message-ID: <82b9e79a0601021803w2a45ac32n13a7c9c5c932b383@mail.gmail.com>

>
> T'would mean that you with need to distinguish "?" followed by
> whitespace (always a binary operator) from "?" followed by a printable
> character (binary or unary, by context).


While I do think this is something that the lexer should be able to handle
(obviously, dependent on context, which has to be dictated by the parser),
the problem does not really go away if you push it up to the parser. In that
case, you still need to disambiguate between the "match-all" token that
comes after the '?' and every other token the lexer can recognize.

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060102/ca2bbc31/attachment.html
From mtraverso at gmail.com  Mon Jan  2 18:04:03 2006
From: mtraverso at gmail.com (Martin Traverso)
Date: Mon Jan  2 18:04:05 2006
Subject: [antlr-interest] Selectively disabling lexer rules
In-Reply-To: <81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
Message-ID: <82b9e79a0601021804w3670c62ai78ed4c638c08823@mail.gmail.com>

>
> You could use a simple sem pred after the '?' to look at the next
> chars, looking for ':' I suppose.


The question is how far "the next chars" is. There's no way to tell, and it
could potentially mean looking ahead up to the EOF.

If you want to gate out a rule, use {...}?=> on the front of it. :)



Ok, so I did try to gate out the character literal token with a flag that
gets set in the conditional expression rule. Unfortunately, it does not
work, since the parser needs to do LAs before it even goes into the rule.
Thus, while the rule might match if the parser ever gets to it, the LA is
preventing it from ever getting there.

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060102/7ca339ea/attachment.html
From parrt at cs.usfca.edu  Mon Jan  2 18:08:53 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan  2 18:10:33 2006
Subject: [antlr-interest] Selectively disabling lexer rules
In-Reply-To: <82b9e79a0601021804w3670c62ai78ed4c638c08823@mail.gmail.com>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
	<82b9e79a0601021804w3670c62ai78ed4c638c08823@mail.gmail.com>
Message-ID: <6B372084-DAA9-466A-98C5-C805991A3615@cs.usfca.edu>

Hmm...I wonder if you try the other way:

CHAR_LIT : {Character.isIdentifierChar(input.LA(3))}? '?' ~' ' ;

QUESTION : '?' ;

Ter
From mental at rydia.net  Mon Jan  2 18:38:40 2006
From: mental at rydia.net (MenTaLguY)
Date: Mon Jan  2 18:39:26 2006
Subject: [antlr-interest] Selectively disabling lexer rules
In-Reply-To: <81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
Message-ID: <1136255920.7197.23.camel@localhost.localdomain>

On Mon, 2006-01-02 at 10:28 -0800, Terence Parr wrote:

> Ugh...ruby is full of these landmines...why do languages by people  
> who don't know how to parse become popular!??  ugh.

Probably because, in terms of a language's userbase, people who write
parsers for it are a scant minority.  Consequently, there's relatively
little incentive to make languages with easy-to-parse grammars.

Sucks for us.

-mental
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
Url : http://www.antlr.org/pipermail/antlr-interest/attachments/20060102/e4c6f878/attachment.bin
From parrt at cs.usfca.edu  Mon Jan  2 18:39:02 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan  2 18:40:41 2006
Subject: [antlr-interest] Selectively disabling lexer rules
In-Reply-To: <1136255920.7197.23.camel@localhost.localdomain>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
	<1136255920.7197.23.camel@localhost.localdomain>
Message-ID: <F062874E-C4C0-467F-9C5C-496FE9EEADE5@cs.usfca.edu>

On Jan 2, 2006, at 6:38 PM, MenTaLguY wrote:
> On Mon, 2006-01-02 at 10:28 -0800, Terence Parr wrote:
>
>> Ugh...ruby is full of these landmines...why do languages by people
>> who don't know how to parse become popular!??  ugh.
>
> Probably because, in terms of a language's userbase, people who write
> parsers for it are a scant minority.  Consequently, there's relatively
> little incentive to make languages with easy-to-parse grammars.
>
> Sucks for us.

Yeah, the thing I've noticed though is a correlation between hard to  
parse and "gotchas" or, in the case of C++, hard to parse for humans. ;)

Ter
From mtraverso at gmail.com  Mon Jan  2 18:50:28 2006
From: mtraverso at gmail.com (Martin Traverso)
Date: Mon Jan  2 18:50:31 2006
Subject: [antlr-interest] Selectively disabling lexer rules
In-Reply-To: <6B372084-DAA9-466A-98C5-C805991A3615@cs.usfca.edu>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
	<82b9e79a0601021804w3670c62ai78ed4c638c08823@mail.gmail.com>
	<6B372084-DAA9-466A-98C5-C805991A3615@cs.usfca.edu>
Message-ID: <82b9e79a0601021850m28104d1bv746bb2852ca580e@mail.gmail.com>

>
> Hmm...I wonder if you try the other way:
>
> CHAR_LIT : {Character.isIdentifierChar(input.LA (3))}? '?' ~' ' ;
>
> QUESTION : '?' ;
>


I guess you meant !Character.isIdentifierChar(...), right?

But anyway, that won't prevent CHAR_LIT from matching in the expression "a
?b : c", will it?

Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060102/eef21335/attachment.html
From mtraverso at gmail.com  Mon Jan  2 22:34:05 2006
From: mtraverso at gmail.com (Martin Traverso)
Date: Mon Jan  2 22:34:07 2006
Subject: [antlr-interest] Syntactic predicate in lexer rule
In-Reply-To: <D86CFD5F-D329-4575-BC78-AE55DC223BB3@cs.usfca.edu>
References: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>
	<274F0FE9-90E2-4EED-859C-72495ED59E87@cs.usfca.edu>
	<D86CFD5F-D329-4575-BC78-AE55DC223BB3@cs.usfca.edu>
Message-ID: <82b9e79a0601022234v7eb28ebfyed2a18e2d2375743@mail.gmail.com>

> Actually, I take this back.  There is a quirk i just realized.  Syn
> preds are converted to sem preds (at least for now) for
> implementation, hence, they will be hoisted like any other
> predicate.  The (DIGITS '.' DIGITS) is converted to a boolean test
> and hoisted into the artificial Tokens rule and that might work.


Unfortunately, it doesn't. The lexer is using a cyclic DFA to predict what
to match, and doesn't seem to take advantage of the predicate. In fact, the
predicate is not even referenced anywhere in the lexer (the code for it is
generated, though).

So, I tried with the following grammar, which does have two alts to choose
from:

grammar T;

tokens {
    INTEGER;
    FLOAT;
}

range:  number ('..' number)?;
number: FLOAT | INTEGER;

NUMBER:  (DIGITS '.' DIGITS) => DIGITS '.' DIGITS { type = FLOAT; }
                | DIGITS { type = INTEGER; };

fragment
DIGITS: ('0'..'9')+;


But the cyclic DFA doesn't look right:

s0 -> s1     upon '0'..'9'
s1 -> s1     upon '0'..'9'
s1 -> (s4)   upon '.'  => alt = 1
s1 -> (s2)   otherwise => alt = 2


Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060102/e8bfd9f9/attachment.html
From aheller at gmx.at  Tue Jan  3 00:54:14 2006
From: aheller at gmx.at (Arnulf Heller)
Date: Tue Jan  3 00:54:32 2006
Subject: [antlr-interest] syntax highlighting & pretty printing
Message-ID: <7.0.0.16.0.20051230131733.0035e320@gmx.at>

Hi there,

have there been any thoughts to include such features directly into 
the design of ANTLR?

I never designed a syntax highlighter by myself (just listened to the 
discussions in this list), so please forgive obvious statements.

Each time one designs a language, there is usually demand for a 
modern way of editing in the target language. In my understanding the 
grammar definition of a language is the right starting point for 
doing SH and PP. What I wanted to have as a user of ANTLR is a common 
base - the grammar files - and ANTLR spit out the lexer/parser plus 
SH/PP stuff.

So, given a valid ANTLR grammar file, is there an easy way to 
generate token definition files for popular editors like eclipse on the fly?
Maybe ANTLR itself would be the right tool for syntax highlighting, 
provided it offers the required interface to, e.g., eclipse (in order 
to embed an grammar driven parser into eclipse).

I recognize that this might be hard to do for languages that need 
user code for code books etc, but at least that should work for 
simple grammars.

Concerning pretty printing: What if ANTLR generates string templates 
for every rule in the grammar? I'm not too familiar with how 
stringtemplate works, but I think the return value of each rule 
should be a instance of a string template.

So, if one has a rule like:

ifrule : "if" LPAREN boolexpr RPAREN LCURLY stmts RCURLY;

a proper string template might be (remove syntax errors):

ifrule(boolexpr,stmts) ::= <<
if ( $boolexpr$ )
{
	$stmts$
}
 >>

arnulf

From sebastian.mies at gmx.net  Tue Jan  3 02:45:13 2006
From: sebastian.mies at gmx.net (Sebastian Mies)
Date: Tue Jan  3 02:45:45 2006
Subject: [antlr-interest] syntax highlighting & pretty printing
In-Reply-To: <7.0.0.16.0.20051230131733.0035e320@gmx.at>
References: <7.0.0.16.0.20051230131733.0035e320@gmx.at>
Message-ID: <144343612.20060103114513@gmx.net>

Hi Arnulf,

I have worked framework to do syntax highlighning and syntax
checking on the fly. Pretty printing is not included yet.
But you can generate a editor for eclipse in about 30 min.
from an existing ANTLR 3(!) grammar.
As soon as I have finished the proper partitioning algorithms,
I will release it under FreeBSD or GPL.
Ter is also thinking on these points - so its just a matter of time :)

Regards,
Sebastian.

P.S.: Happy new year! Frohes neues Jahr!

AH> Hi there,

AH> have there been any thoughts to include such features directly into
AH> the design of ANTLR?

AH> I never designed a syntax highlighter by myself (just listened to the
AH> discussions in this list), so please forgive obvious statements.

AH> Each time one designs a language, there is usually demand for a 
AH> modern way of editing in the target language. In my understanding the
AH> grammar definition of a language is the right starting point for 
AH> doing SH and PP. What I wanted to have as a user of ANTLR is a common
AH> base - the grammar files - and ANTLR spit out the lexer/parser plus
AH> SH/PP stuff.

AH> So, given a valid ANTLR grammar file, is there an easy way to 
AH> generate token definition files for popular editors like eclipse on the fly?
AH> Maybe ANTLR itself would be the right tool for syntax highlighting,
AH> provided it offers the required interface to, e.g., eclipse (in order
AH> to embed an grammar driven parser into eclipse).

AH> I recognize that this might be hard to do for languages that need 
AH> user code for code books etc, but at least that should work for 
AH> simple grammars.

AH> Concerning pretty printing: What if ANTLR generates string templates
AH> for every rule in the grammar? I'm not too familiar with how 
AH> stringtemplate works, but I think the return value of each rule 
AH> should be a instance of a string template.

AH> So, if one has a rule like:

AH> ifrule : "if" LPAREN boolexpr RPAREN LCURLY stmts RCURLY;

AH> a proper string template might be (remove syntax errors):

AH> ifrule(boolexpr,stmts) ::= <<
AH> if ( $boolexpr$ )
AH> {
AH>         $stmts$
AH> }
 >>>

AH> arnulf



From parrt at cs.usfca.edu  Tue Jan  3 11:44:17 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan  3 11:45:56 2006
Subject: [antlr-interest] Selectively disabling lexer rules
In-Reply-To: <82b9e79a0601021850m28104d1bv746bb2852ca580e@mail.gmail.com>
References: <82b9e79a0601020141k58747439y833e06701d94877a@mail.gmail.com>
	<81A2ED36-A1FF-4626-8E97-26DCA1F5DF1D@cs.usfca.edu>
	<82b9e79a0601021804w3670c62ai78ed4c638c08823@mail.gmail.com>
	<6B372084-DAA9-466A-98C5-C805991A3615@cs.usfca.edu>
	<82b9e79a0601021850m28104d1bv746bb2852ca580e@mail.gmail.com>
Message-ID: <3D8D6083-E6E1-46CA-873A-BB0CBD11B46F@cs.usfca.edu>


On Jan 2, 2006, at 6:50 PM, Martin Traverso wrote:

> Hmm...I wonder if you try the other way:
>
> CHAR_LIT : {Character.isIdentifierChar(input.LA (3))}? '?' ~' ' ;
>
> QUESTION : '?' ;
>
>
> I guess you meant !Character.isIdentifierChar(...), right?
>
> But anyway, that won't prevent CHAR_LIT from matching in the  
> expression "a ?b : c", will it?

Oh, right.  Crap.  So, the enclosing syntax dictates the answer?  Ok,  
Bryan is right then...you should use something in the parser.

Ter
From parrt at cs.usfca.edu  Tue Jan  3 11:51:13 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan  3 11:52:49 2006
Subject: [antlr-interest] Re: pretty printing with stringtemplate
In-Reply-To: <7.0.0.16.0.20051230131733.0035e320@gmx.at>
References: <7.0.0.16.0.20051230131733.0035e320@gmx.at>
Message-ID: <DE326D06-2AF9-465D-BD39-6F895DEACE87@cs.usfca.edu>


On Jan 3, 2006, at 12:54 AM, Arnulf Heller wrote:

> Hi there,
>
> have there been any thoughts to include such features directly into  
> the design of ANTLR?

Yes.  Prashant Deva and I are working on it and (per Mies' post, he  
has a nice solution too).

> Concerning pretty printing: What if ANTLR generates string  
> templates for every rule in the grammar? I'm not too familiar with  
> how stringtemplate works, but I think the return value of each rule  
> should be a instance of a string template.

That is how output=template mode works in ANTLR v3 :)  Of course you  
must fill in the attributes.

> So, if one has a rule like:
>
> ifrule : "if" LPAREN boolexpr RPAREN LCURLY stmts RCURLY;
>
> a proper string template might be (remove syntax errors):
>
> ifrule(boolexpr,stmts) ::= <<
> if ( $boolexpr$ )
> {
> 	$stmts$
> }
> >>

yes, and you'd write it like this in v3:

options {output=template;}

ifrule : "if" LPAREN boolexpr RPAREN LCURLY s=stmts RCURLY
	-> ifrule(boolexpr={$boolexpr.st}, stmts={$s.slist})
    ;

where stmts must return a list of templates:

stmts returns [List slist]
	:	(s+=stat)+ {$slist = $s;}
	;

stat	:	ifstat -> {$ifstat.st}
	|	ID '=' expr ';' -> assign(lhs={$ID.text}, rhs={$expr.st})
	;

or something like that.  I don't like some of that (too inconvenient)  
but it's ok for now until we learn more about usage patterns.

Terence
From parrt at cs.usfca.edu  Tue Jan  3 12:17:25 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan  3 12:19:02 2006
Subject: [antlr-interest] Syntactic predicate in lexer rule
In-Reply-To: <82b9e79a0601022234v7eb28ebfyed2a18e2d2375743@mail.gmail.com>
References: <82b9e79a0601011901r7860494yf4d78f923fd3b052@mail.gmail.com>
	<274F0FE9-90E2-4EED-859C-72495ED59E87@cs.usfca.edu>
	<D86CFD5F-D329-4575-BC78-AE55DC223BB3@cs.usfca.edu>
	<82b9e79a0601022234v7eb28ebfyed2a18e2d2375743@mail.gmail.com>
Message-ID: <6EF1C07C-3FB9-467B-A6F8-7B416AB93550@cs.usfca.edu>

On Jan 2, 2006, at 10:34 PM, Martin Traverso wrote:
> Unfortunately, it doesn't. The lexer is using a cyclic DFA to  
> predict what to match, and doesn't seem to take advantage of the  
> predicate. In fact, the predicate is not even referenced anywhere  
> in the lexer (the code for it is generated, though).
>
> So, I tried with the following grammar, which does have two alts to  
> choose from:
>
> grammar T;
>
> tokens {
>     INTEGER;
>     FLOAT;
> }
>
> range:  number ('..' number)?;
> number: FLOAT | INTEGER;
>
> NUMBER:  (DIGITS '.' DIGITS) => DIGITS '.' DIGITS { type = FLOAT; }
>                 | DIGITS { type = INTEGER; };
>
> fragment
> DIGITS: ('0'..'9')+;
>
>
> But the cyclic DFA doesn't look right:
>
> s0 -> s1     upon '0'..'9'
> s1 -> s1     upon '0'..'9'
> s1 -> (s4)   upon '.'  => alt = 1
> s1 -> (s2)   otherwise => alt = 2

Actually, that is correct.  There is no ambiguity.  A FLOAT *must*  
have a '.' and so LL(*) simply looks for that; else it's an INT.  Sem  
preds are not used unless they are needed to resolve a syntactic issue.

Ter
From parrt at cs.usfca.edu  Tue Jan  3 16:21:50 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan  3 16:23:26 2006
Subject: [antlr-interest] rough idea of exceptions vs no-exceptions
	backtracking in v3
Message-ID: <AF1D447D-ECCB-49FC-94D4-4763E1828F0B@cs.usfca.edu>

howdy,

I am doing some fuzzy parsing in the lexer using v3.  The basic trick  
of "try to match and if you fail, throw an exception, skip a char and  
retry" works.  It's pretty slow though it turns out.  The exceptions  
per char kill you.  I then tried backtracking using the non-exception  
mechanism in v3 and it's like 5x faster :)

Heh heh heh...thanks to all of you that badgered me into trying to  
build backtracking w/o exceptions. :)

Ter
From sohail at taggedtype.net  Tue Jan  3 16:44:27 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Tue Jan  3 16:44:44 2006
Subject: [antlr-interest] rough idea of exceptions vs no-exceptions
	backtracking in v3
In-Reply-To: <AF1D447D-ECCB-49FC-94D4-4763E1828F0B@cs.usfca.edu>
References: <AF1D447D-ECCB-49FC-94D4-4763E1828F0B@cs.usfca.edu>
Message-ID: <1136335468.18377.1.camel@localhost.localdomain>

On Tue, 2006-01-03 at 16:21 -0800, Terence Parr wrote:
> howdy,
> 
> I am doing some fuzzy parsing in the lexer using v3.  The basic trick  
> of "try to match and if you fail, throw an exception, skip a char and  
> retry" works.  It's pretty slow though it turns out.  The exceptions  
> per char kill you.  I then tried backtracking using the non-exception  
> mechanism in v3 and it's like 5x faster :)
> 
> Heh heh heh...thanks to all of you that badgered me into trying to  
> build backtracking w/o exceptions. :)

I'm glad you took the time to do this. That being said, its not as if
this result was at all unexpected :)

From parrt at cs.usfca.edu  Tue Jan  3 16:46:28 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan  3 16:48:06 2006
Subject: [antlr-interest] rough idea of exceptions vs no-exceptions
	backtracking in v3
In-Reply-To: <1136335468.18377.1.camel@localhost.localdomain>
References: <AF1D447D-ECCB-49FC-94D4-4763E1828F0B@cs.usfca.edu>
	<1136335468.18377.1.camel@localhost.localdomain>
Message-ID: <8D21537B-3ECD-483B-AC9E-4B0DAD0E5980@cs.usfca.edu>


On Jan 3, 2006, at 4:44 PM, Sohail Somani wrote:

> On Tue, 2006-01-03 at 16:21 -0800, Terence Parr wrote:
>> howdy,
>>
>> I am doing some fuzzy parsing in the lexer using v3.  The basic trick
>> of "try to match and if you fail, throw an exception, skip a char and
>> retry" works.  It's pretty slow though it turns out.  The exceptions
>> per char kill you.  I then tried backtracking using the non-exception
>> mechanism in v3 and it's like 5x faster :)
>>
>> Heh heh heh...thanks to all of you that badgered me into trying to
>> build backtracking w/o exceptions. :)
>
> I'm glad you took the time to do this. That being said, its not as if
> this result was at all unexpected :)

Tough crowd! ;)  Actually, this has a HUGE number of exceptions (like  
on each of 80% of the chars in a file).  For a regular parser, not  
sure what the ratio would be... ;)  Big win here though.

Ter
From brannonking at yahoo.com  Tue Jan  3 22:41:09 2006
From: brannonking at yahoo.com (Brannon King)
Date: Tue Jan  3 22:41:10 2006
Subject: [antlr-interest] syntax highlighting & pretty printing
References: <7.0.0.16.0.20051230131733.0035e320@gmx.at>
	<144343612.20060103114513@gmx.net>
Message-ID: <005701c610f9$da163f30$6600000a@brantheman>

Sweet. This is totally what I need. What can I do to help? The hierarchy 
output is working great for the outline view. It seems we could use the 
grammar to generate the code completion, content assist, syntax 
highlighting, tab rules, etc. -- everything that the eclipse 
SourceViewerConfiguration supports should be easily generated from a decent 
grammar. I just wished I understood the guts of the Eclipse TextEditor 
subclasses better. They are all majorly lacking in documentation.

> I have worked framework to do syntax highlighning and syntax
> checking on the fly. Pretty printing is not included yet.
> But you can generate a editor for eclipse in about 30 min.
> from an existing ANTLR 3(!) grammar.
> As soon as I have finished the proper partitioning algorithms,
> I will release it under FreeBSD or GPL.
> Ter is also thinking on these points - so its just a matter of time :) 

From tinker at sogetthis.com  Wed Jan  4 00:25:28 2006
From: tinker at sogetthis.com (tinker)
Date: Wed Jan  4 00:25:31 2006
Subject: [antlr-interest] lexical nondeterminism warning
Message-ID: <f611554c0601040025g3de94d70t7212d46c4f718e20@mail.gmail.com>

Hi,
   I am trying to define the lexer for a scripting language that has
the following constructs:
   LT: '<';     // the less than character
   LE : "<=" | "=<" ;   // less than or equal to
   NEQ : "<>" ;   // Not equal to
   END : "</script>";  // end of script tag
   COMMENT: "<!-" ; // HTML comment begin

  When I tried to process the above grammar file with antlr (v2.7.6)
with lookahead(k) set to 3, I got 4 lexical nondeterminism warnings,
between COMMENT and each of LT, LE, NEQ and END.
    I rewrote LT as following to eliminate the lexical nondeterminism
between it and  COMMENT -
   LT: {!(LA(2)=='!' && LA(3)=='-')}?'<' ; //match LT only when it's
not followed by "!-"

  However, i am still left with the following three warnings:
=========================================
warning:lexical nondeterminism between rules LE and COMMENT upon
     k==1:'<'
     k==2:'<','='
     k==3:<end-of-token>
warning:lexical nondeterminism between rules NEQ and COMMENT upon
     k==1:'<'
     k==2:'>'
     k==3:<end-of-token>
warning:lexical nondeterminism between rules END and COMMENT upon
     k==1:'<'
     k==2:'/'
     k==3:'s'
=========================================

I was wondering what was the recommended way of dealing with such
warnings? Is there any way to rewrite the definitions so that the
warnings go away? Should I add the conditional statements (if
LA(2)....) to each rule?

Any help you can provide would be greatly appreciated.
Thanks,
T
From aheller at gmx.at  Wed Jan  4 00:59:43 2006
From: aheller at gmx.at (Arnulf Heller)
Date: Wed Jan  4 01:00:04 2006
Subject: [antlr-interest] syntax highlighting & pretty printing
Message-ID: <7.0.0.16.0.20060104095913.01e3d3a0@gmx.at>

To: Sebastian Mies <sebastian.mies@gmx.net>
Subject: Re: [antlr-interest] syntax highlighting & pretty printing

>Hi Arnulf,
>
>I have worked framework to do syntax highlighning and syntax
>checking on the fly. Pretty printing is not included yet.
>But you can generate a editor for eclipse in about 30 min.
>from an existing ANTLR 3(!) grammar.
>As soon as I have finished the proper partitioning algorithms,
>I will release it under FreeBSD or GPL.
>Ter is also thinking on these points - so its just a matter of time :)
>
>Regards,
>Sebastian.
>
>P.S.: Happy new year! Frohes neues Jahr!

Hi Sebastian,

that's great news! Cool! Really looking forward to that.

Thanks & HNJ,
Arnulf

PS.: Jubeln h?rt sich Englisch einfach netter an :-)

From ewbank at gmail.com  Wed Jan  4 05:22:53 2006
From: ewbank at gmail.com (Bryan Ewbank)
Date: Wed Jan  4 05:22:56 2006
Subject: [antlr-interest] overloaded functions
Message-ID: <dd3a065f0601040522w37825c67g1b810e960ab04cf7@mail.gmail.com>

Anyone have references on algorithms to disambigute calls of
overloaded functions?  I'm familiar with how C++ does it, but am
looking for other options.

To make it more complex (ugh), the language allows name/value pairs
for parameters as well as positional parameters.  Hence you might see:
   f(10, 2.0)
   f(10, b=2.0)
   f(a=10, b=2.0)
all of which are equivalent functions.

Thanks in advance,
- Bryan Ewbank
From krishanu at cal.interrasystems.com  Wed Jan  4 05:35:51 2006
From: krishanu at cal.interrasystems.com (Krishanu Debnath)
Date: Wed Jan  4 05:34:34 2006
Subject: [antlr-interest] overloaded functions
In-Reply-To: <dd3a065f0601040522w37825c67g1b810e960ab04cf7@mail.gmail.com>
References: <dd3a065f0601040522w37825c67g1b810e960ab04cf7@mail.gmail.com>
Message-ID: <43BBCF37.9080203@cal.interrasystems.com>

Bryan Ewbank wrote:
> Anyone have references on algorithms to disambigute calls of
> overloaded functions?  I'm familiar with how C++ does it, but am
> looking for other options.
> 
> To make it more complex (ugh), the language allows name/value pairs
> for parameters as well as positional parameters.  Hence you might see:
>    f(10, 2.0)
>    f(10, b=2.0)
>    f(a=10, b=2.0)
> all of which are equivalent functions.
> 
> Thanks in advance,
> - Bryan Ewbank
> 
> 

VHDL Language has exactly same function overloading semantics. You may
find it useful looking free VHDL simulator source code like freehdl,
tyvis(?).

Krishanu
From aheller at gmx.at  Wed Jan  4 06:27:55 2006
From: aheller at gmx.at (Arnulf Heller)
Date: Wed Jan  4 06:30:07 2006
Subject: [antlr-interest] Re: pretty printing with stringtemplate
In-Reply-To: <DE326D06-2AF9-465D-BD39-6F895DEACE87@cs.usfca.edu>
References: <7.0.0.16.0.20051230131733.0035e320@gmx.at>
	<DE326D06-2AF9-465D-BD39-6F895DEACE87@cs.usfca.edu>
Message-ID: <7.0.0.16.0.20060104150656.01e528b0@gmx.at>


>
>yes, and you'd write it like this in v3:
>
>options {output=template;}
>
>ifrule : "if" LPAREN boolexpr RPAREN LCURLY s=stmts RCURLY
>         -> ifrule(boolexpr={$boolexpr.st}, stmts={$s.slist})
>    ;
>
>where stmts must return a list of templates:
>
>stmts returns [List slist]
>         :       (s+=stat)+ {$slist = $s;}
>         ;
>
>stat    :       ifstat -> {$ifstat.st}
>         |       ID '=' expr ';' -> assign(lhs={$ID.text}, rhs={$expr.st})
>         ;
>
>or something like that.  I don't like some of that (too inconvenient)
>but it's ok for now until we learn more about usage patterns.
>
>Terence

Ok. Now I begin to understand how ANTLR3 and ST are supposed to play 
together nicely. Very cool.
When I started to play with string template, I [thought that I] was 
forced to program java, initialized string templates in user actions, 
passed them around between rules ... ugly.

This will make the task to generate valid C++ code out of simple 
textual descriptions quite easy.

I vaguely can remember that you alluded to this topic a while ago, 
but: Can you give me a hint how to handle the situation that I need 
to generate two string templates at the same time, one for the header 
and one for the implementation?

Thx,
Arnulf

From seclib at seclib.com  Wed Jan  4 08:48:01 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Wed Jan  4 08:49:49 2006
Subject: [antlr-interest] Re: lexical nondeterminism warning
In-Reply-To: <f611554c0601040025g3de94d70t7212d46c4f718e20@mail.gmail.com>
References: <f611554c0601040025g3de94d70t7212d46c4f718e20@mail.gmail.com>
Message-ID: <43BBFC41.5050407@seclib.com>

Your snippet is fine. I even tried it:

1. Create test.g:
class L extends Lexer;
options
{
	exportVocab=Test;
	k = 3;
	charVocabulary='\u0003'..'\uFFFF';
}

LT: '<';     // the less than character
LE : "<=" | "=<" ;   // less than or equal to
NEQ : "<>" ;   // Not equal to
END : "</script>";  // end of script tag
COMMENT: "<!-" ; // HTML comment begin


2. Run it:
$ java -classpath antlr.jar antlr.Tool test.g
ANTLR Parser Generator   Version 2.7.6 (2005-12-22)   1989-2005


No warning at all. Would you check the grammar and see if there is other 
rules/options?


tinker wrote:
> Hi,
>    I am trying to define the lexer for a scripting language that has
> the following constructs:
>    LT: '<';     // the less than character
>    LE : "<=" | "=<" ;   // less than or equal to
>    NEQ : "<>" ;   // Not equal to
>    END : "</script>";  // end of script tag
>    COMMENT: "<!-" ; // HTML comment begin
> 
>   When I tried to process the above grammar file with antlr (v2.7.6)
> with lookahead(k) set to 3, I got 4 lexical nondeterminism warnings,
> between COMMENT and each of LT, LE, NEQ and END.
>     I rewrote LT as following to eliminate the lexical nondeterminism
> between it and  COMMENT -
>    LT: {!(LA(2)=='!' && LA(3)=='-')}?'<' ; //match LT only when it's
> not followed by "!-"
> 
>   However, i am still left with the following three warnings:
> =========================================
> warning:lexical nondeterminism between rules LE and COMMENT upon
>      k==1:'<'
>      k==2:'<','='
>      k==3:<end-of-token>
> warning:lexical nondeterminism between rules NEQ and COMMENT upon
>      k==1:'<'
>      k==2:'>'
>      k==3:<end-of-token>
> warning:lexical nondeterminism between rules END and COMMENT upon
>      k==1:'<'
>      k==2:'/'
>      k==3:'s'
> =========================================
> 
> I was wondering what was the recommended way of dealing with such
> warnings? Is there any way to rewrite the definitions so that the
> warnings go away? Should I add the conditional statements (if
> LA(2)....) to each rule?
> 
> Any help you can provide would be greatly appreciated.
> Thanks,
> T
> 

From brannonking at yahoo.com  Wed Jan  4 09:18:12 2006
From: brannonking at yahoo.com (Brannon King)
Date: Wed Jan  4 09:18:03 2006
Subject: [antlr-interest] recover: which token set if any?
Message-ID: <001201c61152$dc52eb50$ac46b642@starbridgesystems.com>

I'm having a hard time understanding the right way to do this recovery.
I had my project working well with all the error handling turned off: I
would just capture the exception on the top level. However, that would only
return for me the first error. So I took my error handling code and put it
into the reportError function. I added a constructor for the parser as well
so that I could pass in the necessary params. The issue, then, is that I
don't know how to handle this situation properly: 

cellType :
	LP! CELLTYPE^ i:IDENTIFIER
		 { -1 != Arrays.binarySearch(cellTypes,
			i.getText().toUpperCase()) }?
	RP!;
	exception catch[SemanticException ex]{
		reportError(new RecognitionException(
			"expecting one of [" +
			arrayToString(cellTypes,", ") + 
			"], found '" + i.getText() + "'",
			i.getFilename(), i.getLine(), i.getColumn());
		recover(ex, BLANK);
	}

Can someone fill in the BLANK? I just want it to consume the RP and pick up
where it left off. When I just rethrow a RecognitionException instead of
calling reportError directly, which is what I tried first, it seems to
consume all the RPs that exist in a row. Is that possible? I say this
because it says that the next LP should be an RP. 

Errors like the above also need different location information than my other
errors. The following works for most errors:

MarkerUtilities.setCharStart(attributes, 
	offset + ex.getColumn()); 
MarkerUtilities.setCharEnd(attributes, 
	offset + ex.getColumn() + parser.LT(1).getText().length());

But I need to use LT(0) for errors like the semantic one above. 

It would be nice if I could just tie an array of strings to i and have it
automatically check to make sure that i was in the list. Again, thanks for
any help.

From sohail at taggedtype.net  Wed Jan  4 10:53:27 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Wed Jan  4 10:53:38 2006
Subject: [antlr-interest] overloaded functions
In-Reply-To: <dd3a065f0601040522w37825c67g1b810e960ab04cf7@mail.gmail.com>
References: <dd3a065f0601040522w37825c67g1b810e960ab04cf7@mail.gmail.com>
Message-ID: <1136400807.7847.7.camel@localhost.localdomain>

On Wed, 2006-01-04 at 08:22 -0500, Bryan Ewbank wrote:
> Anyone have references on algorithms to disambigute calls of
> overloaded functions?  I'm familiar with how C++ does it, but am
> looking for other options.
> 
> To make it more complex (ugh), the language allows name/value pairs
> for parameters as well as positional parameters.  Hence you might see:
>    f(10, 2.0)
>    f(10, b=2.0)
>    f(a=10, b=2.0)
> all of which are equivalent functions.

Doesn't your language tell you how it does overloading? As for the
example you show, I would suggest that you get all function calls into
an intermediate form utilizing the function declaration (if your
language allows this). For example:

f(10,2.0) => f arg[0]=10 arg[1]=2.0
f(10,b=2.0) => f arg[0]=10 arg[indexof(b)]=2.0 <- requires declaration
...

If you have no declaration, you'd have to do it at module linking time
(I imagine!)

From brannonking at yahoo.com  Wed Jan  4 10:57:33 2006
From: brannonking at yahoo.com (Brannon King)
Date: Wed Jan  4 10:57:25 2006
Subject: [antlr-interest] error handling v3 style round 2
Message-ID: <001c01c61160$b9ad6900$ac46b642@starbridgesystems.com>

I wasn't around for the previous discussion on this, but I'd like to comment
on it now.

Previously proposed by Terence:

method
	: type ID ...
	;
	exception
		catch[RecognitionException e]
			( {level>0}? ('}' {level--;} | .) )*

That, to me, looks beautiful. It is very close to what I need to do. More
specifically it would be something like this:

method
	: '(' funcName^ i:ID ')'
	{ isValid(i.getText()) }?
	;
	exception
		catch[SemanticException e]
			( {level>0}? (')' {level--;} | .) )*
			{ error("expecting blah, found " + i.getText(), 
				i.file, i.linenum, i.column,
i.getText().length(),
				e.linenum, e.column);
			  recover();
			}

To explain: I need to know the range of characters involved in the found ID
for the editor to mark the error, and I need to recover after I hit that
closing parenthisis. Whatever the case, the recover function needs to be
easy to call; I shouldn't have to spend half a day figuring out what params
it takes.

PS, I like the error alternates as well. The slash looks like a fine
operator to me, though |~ might be more obvious.

From tinker at sogetthis.com  Thu Jan  5 00:28:08 2006
From: tinker at sogetthis.com (tinker)
Date: Thu Jan  5 00:28:12 2006
Subject: [antlr-interest] Re: Re: lexical nondeterminism warning
Message-ID: <f611554c0601050028j75720fb4v7de2484b8deadbb9@mail.gmail.com>

Whups! You were absolutely correct. The warnings infact were occurring
due to another rule 'COMMENT_BODY' that I had defined later on. As
soon as I fixed it's definition, all the warnings vanished.

Many Thanks,
T
:)
From tinker at sogetthis.com  Thu Jan  5 01:52:18 2006
From: tinker at sogetthis.com (tinker)
Date: Thu Jan  5 01:52:21 2006
Subject: [antlr-interest] Re: lexical nondeterminism warning
In-Reply-To: <f611554c0601050028j75720fb4v7de2484b8deadbb9@mail.gmail.com>
References: <f611554c0601050028j75720fb4v7de2484b8deadbb9@mail.gmail.com>
Message-ID: <f611554c0601050152l6da24edcgc05dd55666e6795@mail.gmail.com>

Hi again,
  Well, I know how to restructure my lexer rules so that the above
errors dissappear, but that isn't exactly what I want. Let me go into
more detail and explain:
   The language can have two types of comments embedded in it:
   - Single line comments: These begin with a ' character and last
till the end of line
       ' This is a single line comment
   - Multiline comment: These are just like the HTML comments.
            <!-  this is a multiline comment  -->

Now I can define the following two rules to handle these comments:
---------------------------------------------
 MULTI_COMMENT
  :
  "<!-"
      (options {
			generateAmbigWarnings=false;
		  }:
      {!(LA(2)=='-' && LA(3)=='>')}? '-' // allow '-' if not "-->"
        | WS
        | ~( '-' | '\n'|'\r')
      )*
    "-->";

 SINGLE_COMMENT
  :
    '\'"
      (
        {LA(2) != '>'}? '%' // the script is embedded within <% %> tags
        | ~('\n' | '%')
      )*
  {	if (LA(1) == '\n')
	{
		match('\n');
		newline();
	}
  };
 ---------------------------------------------
Now, when I compile this with antlr 2.7.6, i get no errors at all.
However, this introduces two tokens in the input stream, one for each
type of comment. Instead of this, I want that there be only one token
for all type of comments in the file. So I defined another rule as
follows:
 ---------------------------------------------
protected  MULTI_COMMENT
 :
.....
;
protected  SINGLE_COMMENT
 :
.....
;

COMMENT
:
 SINGLE_COMMENT
 |
  MULTI_COMMENT
;
 ---------------------------------------------
But when I try to compile the grammar now, I get the warnings again.
They are the same warnings as before, and are reproduced below:
=========================================
warning:lexical nondeterminism between rules LE and COMMENT upon
    k==1:'<'
    k==2:'<','='
    k==3:<end-of-token>
warning:lexical nondeterminism between rules NEQ and COMMENT upon
    k==1:'<'
    k==2:'>'
    k==3:<end-of-token>
warning:lexical nondeterminism between rules END and COMMENT upon
    k==1:'<'
    k==2:'/'
    k==3:'s'
=========================================

So can anyone tell me why this is happening, and what I can do to get
around this?

Thanks,
T
From RamosD.External at infineon.com  Thu Jan  5 02:13:02 2006
From: RamosD.External at infineon.com (RamosD.External@infineon.com)
Date: Thu Jan  5 02:13:09 2006
Subject: [antlr-interest] Problems with EOF
Message-ID: <00BDEDEA1DCF5B47A49C12B11EED928F06732552@porse201.eu.infineon.com>


I have problems with my parsers...

If I have the end of file in last line of script, the parser stay on
cycle and do nothing.

Please help me,  I cant understand this problem.

MY CODE:

// Single-line comments
SL_COMMENT
	:	"//"
		(~('\n'|'\r'))* ('\n'|'\r'('\n')?)?
		{$setType(Token.SKIP); newline();}
	;

// multiple-line comments
ML_COMMENT
	:	"/*"
		(	
			options {
				generateAmbigWarnings=false;
			}
		:
			{ LA(2)!='/' }? '*'
		|	'\r' '\n'		{newline();}
		|	'\r'			{newline();}
		|	'\n'			{newline();}
		|	~('*'|'\n'|'\r')
		)*
		"*/"
		{$setType(Token.SKIP);newline();}
	;
THANKS,

Daniel Ramos
From donalmurtagh at yahoo.co.uk  Thu Jan  5 03:37:08 2006
From: donalmurtagh at yahoo.co.uk (DM)
Date: Thu Jan  5 03:37:12 2006
Subject: [antlr-interest] token-matching problem
Message-ID: <20060105113708.11753.qmail@web32002.mail.mud.yahoo.com>

Hi,

I'm using ANTLR to process a file which consists of a series of nested blocks. Most of the blocks
have names which look similar to java identifiers and are matched by the lexer rule:

ID :	('a'..'z'|'A'..'Z') ('a'..'z'|'A'..'Z'|'0'..'9'|'/')*
;

However one of the blocks looks like this:

SubscriptionManager:2
{  
}

Currently, the (simplified) parser rule I'm using to match this is:

subMgr : "SubscriptionManager"! ":"! "2"!
LBRACE!
RBRACE!
;

This rule doesn't add any nodes to the AST, but I need to change it in order to add
"SubscriptionManager:2" to the tree as a single token.

I tried modifying the ID lexer rule to be:

ID :	('a'..'z'|'A'..'Z') ('a'..'z'|'A'..'Z'|'0'..'9'|'/')* (":2")?
;

And changing the parser rule to:
	
subMgr : "SubscriptionManager:2"^
LBRACE!
RBRACE!
;

But this produced a NullPointerException in a subrule of subMgr (not shown in simplified form
above).

I also tried defining a new lexer token type (after undoing the above changes):

SUB_MGR	: ID ':' '2'
;

And changing the parser rule to match a token of this type:
	
subMgr : SUB_MGR^
LBRACE!
RBRACE!
;

This produces the error message: "Exception in thread "main" line 515:15: expecting ':', found
'\r'"

Line 515 contains the first significant (i.e. neither whitespace nor comment) token in the file.
So it seems as though my new SUB_MGR rule is being used as some kind of default. I don't really
understand why?

I guess I could just define a new lexer rule like

SUB_MGR : "SubscriptionManager:2"
;

And then match a token of this type in the parser, but I'd also have to increase the lookahead,
which is currently 3, to about 15 - and I really don't want to do this.

Thanks in advance,
DM


		
___________________________________________________________ 
NEW Yahoo! Cars - sell your car and browse thousands of new and used cars online! http://uk.cars.yahoo.com/
From dskolovos at gmail.com  Thu Jan  5 04:38:09 2006
From: dskolovos at gmail.com (Dimitrios Kolovos)
Date: Thu Jan  5 04:38:15 2006
Subject: [antlr-interest] Keywords can appear in expressions
In-Reply-To: <20060105113708.11753.qmail@web32002.mail.mud.yahoo.com>
References: <20060105113708.11753.qmail@web32002.mail.mud.yahoo.com>
Message-ID: <43BD1331.3080309@gmail.com>

Hi,

In my language some keywords can also appear in expressions e.g.

*operation* doSomething() {}

and

object.operation.name;

When I declare the "operation" keyword like that,

OPERATION : "operation";

it is recognized as keyword in the second case as well.

What I think might work is to declare OPERATION as (' ' | '\t' | '\n') 
"operation" (' ' | '\t' | '\n') but I don't want characters before or 
after "operation" to be consumed. Any ideas on how to do this?

Cheers,
Dimitrios
From madcapmaggie at yahoo.com  Thu Jan  5 07:01:23 2006
From: madcapmaggie at yahoo.com (Peggy Fieland)
Date: Thu Jan  5 07:01:29 2006
Subject: [antlr-interest] Keywords can appear in expressions
In-Reply-To: <43BD1331.3080309@gmail.com>
Message-ID: <20060105150123.5153.qmail@web30213.mail.mud.yahoo.com>

The way that has worked best for me is to enumerate
the keywords that can appear as identifiers:

non_keywords: "OPERATION;

object_name: identifier | non_keywords
;

I finally ended up writing myself a small generator
program that works off of an array of "real" keywords
and generates two rules:

keywords: "REAL_KEYWORD1" | "REAL_KEYWORD2"   (etc)
non_keywords: "CAN_APPEAR_AS_IDENTIFIER1" |
"CAN_APPEAR_AS_IDENTIFIER2" 
  (etc)

The program works off of an array of what the manual
told me were the "real" keywords and takes as input
the ...ParserTokenTypes.txt file
which it uses to generate the two rules (into separate
files, which I 
then merge into the parser by hand).

 I'm working on parsers for several SQL dialects and
as the language we support keeps changing (and as we
find bugs) we update the parsers.  I've had to modify
the "real_keywords" list but the whole thing works
well and is easy to maintain.


Peggy

--- Dimitrios Kolovos <dskolovos@gmail.com> wrote:

> Hi,
> 
> In my language some keywords can also appear in
> expressions e.g.
> 
> *operation* doSomething() {}
> 
> and
> 
> object.operation.name;
> 
> When I declare the "operation" keyword like that,
> 
> OPERATION : "operation";
> 
> it is recognized as keyword in the second case as
> well.
> 
> What I think might work is to declare OPERATION as
> (' ' | '\t' | '\n') 
> "operation" (' ' | '\t' | '\n') but I don't want
> characters before or 
> after "operation" to be consumed. Any ideas on how
> to do this?
> 
> Cheers,
> Dimitrios
> 

From seclib at seclib.com  Thu Jan  5 09:33:52 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Thu Jan  5 09:36:10 2006
Subject: [antlr-interest] Re: lexical nondeterminism warning
In-Reply-To: <f611554c0601050152l6da24edcgc05dd55666e6795@mail.gmail.com>
References: <f611554c0601050028j75720fb4v7de2484b8deadbb9@mail.gmail.com>
	<f611554c0601050152l6da24edcgc05dd55666e6795@mail.gmail.com>
Message-ID: <43BD5880.3010103@seclib.com>

Well, now you meet antlr's "linear approximate lookahead":)
Please read this:
http://www.antlr.org/doc/glossary.html#Linear_approximate_lookahead
and related entries in antlr's FAQ.

You may find my blog usefully as well:
http://seclib.blogspot.com/2005/11/linear-approximate-lookahead.html

Note: antlr may generate correct code even if it gives warnings, but you 
have to read the generated code to be sure.

In your case, the best way is to seperate SINGLE_COMMENT and 
MULTI_COMMENT in lexer, while create a parser rule to group them together:

comment
:SINGLE_COMMENT
|MULTI_COMMENT

If you do so, the lexer does not need to compression the lookahead set 
for nextToken(), and you still have a maintainable grammar.

> COMMENT
> :
>  SINGLE_COMMENT
>  |
>   MULTI_COMMENT
> ;
>  ---------------------------------------------
> But when I try to compile the grammar now, I get the warnings again.
> They are the same warnings as before, and are reproduced below:
> =========================================
> warning:lexical nondeterminism between rules LE and COMMENT upon
>     k==1:'<'
>     k==2:'<','='
>     k==3:<end-of-token>
> warning:lexical nondeterminism between rules NEQ and COMMENT upon
>     k==1:'<'
>     k==2:'>'
>     k==3:<end-of-token>
> warning:lexical nondeterminism between rules END and COMMENT upon
>     k==1:'<'
>     k==2:'/'
>     k==3:'s'
> =========================================
> 
> So can anyone tell me why this is happening, and what I can do to get
> around this?
> 
> Thanks,
> T
> 


-- 
Xue Yong Zhi
http://seclib.blogspot.com

From seclib at seclib.com  Thu Jan  5 09:44:50 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Thu Jan  5 09:45:39 2006
Subject: [antlr-interest] Re: Problems with EOF
In-Reply-To: <00BDEDEA1DCF5B47A49C12B11EED928F06732552@porse201.eu.infineon.com>
References: <00BDEDEA1DCF5B47A49C12B11EED928F06732552@porse201.eu.infineon.com>
Message-ID: <43BD5B12.90305@seclib.com>

Please explain your problem in a better way. I do not understand what do 
you mean by "the parser stay on cycle and do nothing". I think the 
parser will terminate anyway if it meets EOF. Can you give the shortest 
grammar which can duplicate your problem? For example, something like this:

program:
	:	(SL_COMMENT	|	ML_COMMENT)	EOF
	;

RamosD.External@infineon.com wrote:
> I have problems with my parsers...
> 
> If I have the end of file in last line of script, the parser stay on
> cycle and do nothing.
> 
> Please help me,  I cant understand this problem.
> 
> MY CODE:
> 
> // Single-line comments
> SL_COMMENT
> 	:	"//"
> 		(~('\n'|'\r'))* ('\n'|'\r'('\n')?)?
> 		{$setType(Token.SKIP); newline();}
> 	;
> 
> // multiple-line comments
> ML_COMMENT
> 	:	"/*"
> 		(	
> 			options {
> 				generateAmbigWarnings=false;
> 			}
> 		:
> 			{ LA(2)!='/' }? '*'
> 		|	'\r' '\n'		{newline();}
> 		|	'\r'			{newline();}
> 		|	'\n'			{newline();}
> 		|	~('*'|'\n'|'\r')
> 		)*
> 		"*/"
> 		{$setType(Token.SKIP);newline();}
> 	;
> THANKS,
> 
> Daniel Ramos
> 


-- 
Xue Yong Zhi
http://seclib.blogspot.com

From endigitalmind at yahoo.co.uk  Thu Jan  5 12:53:15 2006
From: endigitalmind at yahoo.co.uk (Phil Ritchie)
Date: Thu Jan  5 12:53:20 2006
Subject: [antlr-interest] C# implementation of StringTemplate
Message-ID: <20060105205315.31149.qmail@web25813.mail.ukl.yahoo.com>

Is there a C# equivalent of the
StringTemplate-x.x.x.jar? I want to embark on looking
at StringTemplate but I'm using the antlr.net runtime.
Do I need anything else?



		
___________________________________________________________ 
To help you stay safe and secure online, we've developed the all new Yahoo! Security Centre. http://uk.security.yahoo.com
From duboimat at iro.umontreal.ca  Thu Jan  5 13:21:03 2006
From: duboimat at iro.umontreal.ca (duboimat@iro.umontreal.ca)
Date: Thu Jan  5 13:21:08 2006
Subject: [antlr-interest] C# implementation of StringTemplate
In-Reply-To: <20060105205315.31149.qmail@web25813.mail.ukl.yahoo.com>
References: <20060105205315.31149.qmail@web25813.mail.ukl.yahoo.com>
Message-ID: <20060105162103.lz569hqppcosg08c@webmail.iro.umontreal.ca>

Quoting Phil Ritchie <endigitalmind@yahoo.co.uk>:

> Is there a C# equivalent of the
> StringTemplate-x.x.x.jar? I want to embark on looking
> at StringTemplate but I'm using the antlr.net runtime.
> Do I need anything else?
>
>
>
>
> ___________________________________________________________
> To help you stay safe and secure online, we've developed the all new 
> Yahoo! Security Centre. http://uk.security.yahoo.com
>


you can use 
http://www.stringtemplate.org/share/1136407831149/StringTemplate.zip
you will get the library string template in C#
or stringtemplate.org in  File Sharing section

StringTemplate 2.2 C# Update
Luis Leal Wed Jan 4, 2006 12:50
Fix a bug in the rest operator reported by Andrew Hallock.


I'm using it and it works very well

mat

----------------------------------------------------------------
This message was sent using IMP, the Internet Messaging Program.

From younglv at yahoo.com  Thu Jan  5 13:57:42 2006
From: younglv at yahoo.com (Randy Hammon)
Date: Thu Jan  5 13:57:44 2006
Subject: [antlr-interest] Has anyone done a UTF-16 C++ implementation?
Message-ID: <20060105215742.11010.qmail@web53001.mail.yahoo.com>

Hi All,
This is my first post to the list. We currently use
antlr 2.7.3 to generate a C++ lexer/parser for SQL-99+
and are very happy with it. 

However, we are converting our C++ application to
utf-16 and will need antlr to support this. I perused
the old archive and saw reference to the utf-8
implementation. 

Has anyone created a utf-16 c++ version? 

Thanks,
-randy hammon



		
__________________________________________ 
Yahoo! DSL ? Something to write home about. 
Just $16.99/mo. or less. 
dsl.yahoo.com 

From antlr at shmuelhome.mine.nu  Thu Jan  5 14:49:20 2006
From: antlr at shmuelhome.mine.nu (shmuel siegel)
Date: Thu Jan  5 14:50:05 2006
Subject: [antlr-interest] Re: lexical nondeterminism warning
In-Reply-To: <43BD5880.3010103@seclib.com>
References: <f611554c0601050028j75720fb4v7de2484b8deadbb9@mail.gmail.com>	<f611554c0601050152l6da24edcgc05dd55666e6795@mail.gmail.com>
	<43BD5880.3010103@seclib.com>
Message-ID: <43BDA270.2000707@shmuelhome.mine.nu>

Xue Yong Zhi wrote:
> Well, now you meet antlr's "linear approximate lookahead":)
> ............
> You may find my blog usefully as well:
> http://seclib.blogspot.com/2005/11/linear-approximate-lookahead.html
>
> Note: antlr may generate correct code even if it gives warnings, but 
> you have to read the generated code to be sure.
The example on your blog
RULE1: "ab" | "ba";

RULE2: "ac" | "ca" ;

illustrates a more annoying aspect of "linear approximate lookahead". 
Not only do you get "incorrect" ambiguity warnings, you also get 
incorrect code. The parser will think that RULE1 should match "aa" and 
when it doesn't, the parser throws a recognition exception. This happens 
even when there is a third rule that would match "aa".



-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.371 / Virus Database: 267.14.13/221 - Release Date: 1/4/2006

From jbarnesweb at yahoo.com  Thu Jan  5 20:23:52 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Thu Jan  5 20:23:55 2006
Subject: [antlr-interest] State Machines Galore
Message-ID: <20060106042352.70721.qmail@web54513.mail.yahoo.com>

Thanks, Terrence, for the project/assignment posted at
http://www.cs.usfca.edu/~parrt/course/652/projects-Spring-2004/nfa.html.

You said the following NFA generates (a | b | c):

.s0 -> .a1 -> . -a-> . -> .s5 -> :
       .a2 -> . -b-> . -> @s5
       .a3 -> . -c-> . -> @s5
@a1 -> @a2
@a2 -> @a3

What not use a simpler graph?

.s0 -> .a1 -a-> .s5 -> :
       .a2 -b-> @s5
       .a3 -c-> @s5
@a1 -> @a2
@a2 -> @a3

Where can I find more info about constructing NFA's?
Thanks again for the web page.

Regards,
Jeff

From ric.klaren at gmail.com  Fri Jan  6 00:19:25 2006
From: ric.klaren at gmail.com (Ric Klaren)
Date: Fri Jan  6 00:27:04 2006
Subject: [antlr-interest] Has anyone done a UTF-16 C++ implementation?
In-Reply-To: <20060105215742.11010.qmail@web53001.mail.yahoo.com>
References: <20060105215742.11010.qmail@web53001.mail.yahoo.com>
Message-ID: <bc607a4e0601060019q41417a36wa9c56082f7323991@mail.gmail.com>

Hi,

To start with best wishes for the new year.

On 1/5/06, Randy Hammon <younglv@yahoo.com> wrote:
> However, we are converting our C++ application to
> utf-16 and will need antlr to support this. I perused
> the old archive and saw reference to the utf-8
> implementation.
>
> Has anyone created a utf-16 c++ version?

If you work from the unicode example provided with 2.7.5/6 it should
be pretty trivial to construct an utf-16 version. The approach in the
example is reported to work. Some tweaking may be necessary for how
you store the UTF16 strings after they're lexed. The example decodes
UTF8 and then reencodes them as UTF8 into std::string, you probably
want to do something different there.

Cheers,

Ric
From mail.tinker at gmail.com  Fri Jan  6 06:09:03 2006
From: mail.tinker at gmail.com (tinker tailor)
Date: Fri Jan  6 06:09:06 2006
Subject: [antlr-interest] lexer rule matching problem
Message-ID: <c7b221a70601060609u7ae19f2w5f84d19f0dcf5651@mail.gmail.com>

Hi all,
  I am trying to parse a subset of the vbscript language, and have run
into the following problem:
   The '&' in VBS can be used in two ways -
       1. As a concatenation operator
              e.g.:  a = b & c    or   a=b&c
       2.As part of the prefix ("&H") and optional suffix('&') for
hexadecimal numbers
             e.g.:  a=&H9Abc    or  a=&H9Abc&

So, here are the rules I made in my lexer (lookahead=3):

CONCAT : '&';
HEX : "&h" (HEX_DIGIT)+ (('&')?)! ;
HEX_DIGIT : '0'..'9' | 'a'..'f' ;

Now what I want the lexer to do is to first try and match a hex
number, and only when that fails, to try and match for the CONCAT
token. But I am not really sure how to tell antlr that. :(
 As things stand, the lexer first matches CONCAT, and as a result
throws the 'unexpected token: exception when I give it the following
valid input:
     a = &H345ad&

Any suggestions?

Thanks,
tinker
From jbb at acm.org  Fri Jan  6 06:39:21 2006
From: jbb at acm.org (John B. Brodie)
Date: Fri Jan  6 06:39:26 2006
Subject: [antlr-interest] lexer rule matching problem
In-Reply-To: <c7b221a70601060609u7ae19f2w5f84d19f0dcf5651@mail.gmail.com>
	(message from tinker tailor on Fri, 06 Jan 2006 19:39:03 +0530)
References: <c7b221a70601060609u7ae19f2w5f84d19f0dcf5651@mail.gmail.com>
Message-ID: <E1EuskT-0007Js-00@gecko>

Tinker Tailor asked:
>  I am trying to parse a subset of the vbscript language, and have run
>into the following problem:
>   The '&' in VBS can be used in two ways -
>       1. As a concatenation operator
>              e.g.:  a = b & c    or   a=b&c
>       2.As part of the prefix ("&H") and optional suffix('&') for
>hexadecimal numbers
>             e.g.:  a=&H9Abc    or  a=&H9Abc&
>
>So, here are the rules I made in my lexer (lookahead=3):
>
>CONCAT : '&';
>HEX : "&h" (HEX_DIGIT)+ (('&')?)! ;
>HEX_DIGIT : '0'..'9' | 'a'..'f' ;
>
>Now what I want the lexer to do is to first try and match a hex
>number, and only when that fails, to try and match for the CONCAT
>token. But I am not really sure how to tell antlr that. :(
> As things stand, the lexer first matches CONCAT, and as a result
>throws the 'unexpected token: exception when I give it the following
>valid input:
>     a = &H345ad&
>
>Any suggestions?

untested, but perhaps this might do it:

token { HEX; }
CONCAT : '&' (( 'h' (HEX_DIGIT)+ (('&')?)! ){ $setType(HEX); })? ;
protected HEX_DIGIT : '0'..'9' | 'a'..'f' ;
From mail at martin-probst.com  Fri Jan  6 07:07:38 2006
From: mail at martin-probst.com (Martin Probst)
Date: Fri Jan  6 07:07:44 2006
Subject: [antlr-interest] lexer rule matching problem
In-Reply-To: <E1EuskT-0007Js-00@gecko>
References: <c7b221a70601060609u7ae19f2w5f84d19f0dcf5651@mail.gmail.com>
	<E1EuskT-0007Js-00@gecko>
Message-ID: <1136560058.4983.2.camel@localhost.localdomain>


> token { HEX; }
> CONCAT : '&' (( 'h' (HEX_DIGIT)+ (('&')?)! ){ $setType(HEX); })? ;
> protected HEX_DIGIT : '0'..'9' | 'a'..'f' ;

What happens if someone wants do to this:

a = "foo"
h3 = "bar"
b = a&h3

You'll end up with a token stream of IDENTIFIER EQUALS IDENTIFIER HEX.
The lexer needs to know that it's in a non-operator state (where a
concat cannot occur) as the language is ambiguous otherwise. Maybe you
can also get around it by disambiguating in the parser, e.g. lex the '&'
simply as an AMPERSAND and let the parser figure out what it is.

Martin

From parrt at cs.usfca.edu  Fri Jan  6 10:50:49 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Fri Jan  6 10:52:15 2006
Subject: [antlr-interest] State Machines Galore
In-Reply-To: <20060106042352.70721.qmail@web54513.mail.yahoo.com>
References: <20060106042352.70721.qmail@web54513.mail.yahoo.com>
Message-ID: <0EEFDF54-006B-4F05-9BB7-7C5A252A3D81@cs.usfca.edu>


On Jan 5, 2006, at 8:23 PM, Jeff Barnes wrote:

> Thanks, Terrence, for the project/assignment posted at
> http://www.cs.usfca.edu/~parrt/course/652/projects-Spring-2004/ 
> nfa.html.
>
> You said the following NFA generates (a | b | c):
>
> .s0 -> .a1 -> . -a-> . -> .s5 -> :
>        .a2 -> . -b-> . -> @s5
>        .a3 -> . -c-> . -> @s5
> @a1 -> @a2
> @a2 -> @a3
>
> What not use a simpler graph?
>
> .s0 -> .a1 -a-> .s5 -> :
>        .a2 -b-> @s5
>        .a3 -c-> @s5
> @a1 -> @a2
> @a2 -> @a3

You could...i was showing the output of another tool actually (ANTLR  
v3) ;)

> Where can I find more info about constructing NFA's?

Well, lots of courses have info on constructing them, but you don't  
see a lot of code to do so...i can't give out the course solution  
unfortunately  ;)

> Thanks again for the web page.

My pleasure.

Ter
From parrt at cs.usfca.edu  Fri Jan  6 15:24:00 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Fri Jan  6 15:25:27 2006
Subject: [antlr-interest] proposed enhancement to ANTLR v3 ST integration
Message-ID: <A1C28ECF-5534-4779-8D45-C2BE36044A1F@cs.usfca.edu>

Howdy,

[Added to blog http://www.antlr.org/blog/antlr3/rewrite.tml ]

I've been resisting the temptation to introduce a new symbol to  
handle templates.  For example, to avoid adding a new special symbol,  
I introduced $templates::foo(args) as the template constructor to  
build foo, which translates to:

st = templateLib.getInstanceOf("foo");
st.setAttribute("arg1", ...);
...

With other template libs, you'd do $Java::method(...) etc...  Now I'm  
finding real situations where ST integration can be improved.  The  
ctor problem is reasonably solved, but setting attributes still  
sucks: st.setAttribute("arg1", e1); is repeated many times all over.   
A better notation would be $st.arg1 = e1; but that is highly  
ambiguous with the $x.y notation.  Anyway, after looking at a number  
of real examples now, I find the urge to introduce a new symbol to  
help the human brain separate rule/scope attribute references from  
template syntactic sugar.  I propose the following (developed in  
collaboration with Jean Bovet and influenced by Hartmut Kocher's  
suggestions):

   %foo(...)     ctor (even shorter than $templates::foo(...))
   %(...)        anonymous template from string expr
   %x.y = z;         set template attribute y of x (always set never  
get attr) to z
			[languages like python without ';' must still use the ';' which the
			code generator is free to remove during code gen]
   %(expr).y = z;     template attribute y of StringTemplate-typed  
expr to z

   what about other template scopes?

   %Java::method(...)         scoped constructor
   %CPP::method...)	...

Make sense?  Objections?  hard to tell until you see a real  
example ;)  I see a lot of

a : ID -> {new StringTemplate($ID.text)} ;

which would be now

a : ID -> {%($ID.text)} ;

or even simpler:

a : ID -> %($ID.text) ;

I see lots of setAttribute stuff like:

a[int foo] : ID
	{
	StringTemplate x = $templates::foo();
	...
	x.setAttribute("arg1", $ID.text);
	x.setAttribute("arg2", $a.foo);
	$st = x;
	}
   ;

Now it would be:

a[int foo] : ID
	{
	StringTemplate x = %foo();
	...
	%x.arg1 = $ID.text;
	%x.arg2 = $foo;
	$st = x;
	}
   ;

So x is just a variable like you expect; to use shortcut access to ST  
stuff, you need the %.  Note how the $ stuff is now clearly separated  
from the % template stuff.

Look ok?

Ter


From jbarnesweb at yahoo.com  Sat Jan  7 01:45:19 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Sat Jan  7 01:45:25 2006
Subject: [antlr-interest] State Machines Galore
In-Reply-To: <0EEFDF54-006B-4F05-9BB7-7C5A252A3D81@cs.usfca.edu>
Message-ID: <20060107094519.46577.qmail@web54505.mail.yahoo.com>


--- Terence Parr <parrt@cs.usfca.edu> wrote:

> > You said the following NFA generates (a | b | c):
> >
> > .s0 -> .a1 -> . -a-> . -> .s5 -> :
> >        .a2 -> . -b-> . -> @s5
> >        .a3 -> . -c-> . -> @s5
> > @a1 -> @a2
> > @a2 -> @a3
> >
> > What not use a simpler graph?
> >
> > .s0 -> .a1 -a-> .s5 -> :
> >        .a2 -b-> @s5
> >        .a3 -c-> @s5
> > @a1 -> @a2
> > @a2 -> @a3
> 
> You could...i was showing the output of another tool
> actually (ANTLR  
> v3) ;)


So it appears that ANTLR v3's parse tree isn't (a | b
| c) it is:

         |
        / \
       |   c
      / \
     a   b

and that tree is explicitly expressed in regular
expression as

((a | b) | c)

right?

Regards,
Jeff

From stefan at amiq.ro  Sat Jan  7 05:45:59 2006
From: stefan at amiq.ro (stefan)
Date: Sat Jan  7 05:45:31 2006
Subject: [antlr-interest] proposed enhancement to ANTLR v3 ST integration
In-Reply-To: <A1C28ECF-5534-4779-8D45-C2BE36044A1F@cs.usfca.edu>
References: <A1C28ECF-5534-4779-8D45-C2BE36044A1F@cs.usfca.edu>
Message-ID: <200601071546.03631.stefan@amiq.ro>

Hello Terence,

       some time ago I worked on a prettyprinter. I used a walker to traverse 
the tree and print the information. Almost every node had an associated 
template and implicitly actions for creating the template and settting 
attributes. So, from my point of view it would be nice to have some 
shortcuts.  

Stefan.
From parrt at cs.usfca.edu  Sat Jan  7 10:24:48 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan  7 10:26:12 2006
Subject: [antlr-interest] State Machines Galore
In-Reply-To: <20060107094519.46577.qmail@web54505.mail.yahoo.com>
References: <20060107094519.46577.qmail@web54505.mail.yahoo.com>
Message-ID: <894AF5B5-4C28-4308-8093-F6D1580D3F47@cs.usfca.edu>


On Jan 7, 2006, at 1:45 AM, Jeff Barnes wrote:
>> You could...i was showing the output of another tool
>> actually (ANTLR
>> v3) ;)
>
>
> So it appears that ANTLR v3's parse tree isn't (a | b
> | c) it is:
>
>          |
>         / \
>        |   c
>       / \
>      a   b
>
> and that tree is explicitly expressed in regular
> expression as
>
> ((a | b) | c)
>
> right?

Actually, v3 builds something more complicated.  For your  
entertainment, run

java org.antlr.Tool -dfa -nfa t.g

and you'll get rulename.dot and t_dec-n.dot (the prediction DFA).   
Load with graphviz.  Rinse.  Repeat.  Enjoy fuller, bouncier hair. :) ;)

Ter
From parrt at cs.usfca.edu  Sat Jan  7 10:26:00 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan  7 10:27:22 2006
Subject: [antlr-interest] proposed enhancement to ANTLR v3 ST integration
In-Reply-To: <200601071546.03631.stefan@amiq.ro>
References: <A1C28ECF-5534-4779-8D45-C2BE36044A1F@cs.usfca.edu>
	<200601071546.03631.stefan@amiq.ro>
Message-ID: <36715579-EA80-42A6-AF4D-4A927275B6B2@cs.usfca.edu>

On Jan 7, 2006, at 5:45 AM, stefan wrote:
> Hello Terence,
>
>        some time ago I worked on a prettyprinter. I used a walker  
> to traverse
> the tree and print the information. Almost every node had an  
> associated
> template and implicitly actions for creating the template and settting
> attributes. So, from my point of view it would be nice to have some
> shortcuts.

Ok, thanks, Stefan.  I'm nervous about the complexity of the actions  
in v3, but the separate % symbol will help both human and computer  
alike to disambiguate.  Further, people can do straight actions if  
they want to avoid %.

Ter
From jbarnesweb at yahoo.com  Sat Jan  7 12:23:50 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Sat Jan  7 12:23:51 2006
Subject: [antlr-interest] State Machines Galore
In-Reply-To: <894AF5B5-4C28-4308-8093-F6D1580D3F47@cs.usfca.edu>
Message-ID: <20060107202350.77031.qmail@web54514.mail.yahoo.com>

To the list this time:

> Actually, v3 builds something more complicated.  For
> your  
> entertainment, run
> 
> java org.antlr.Tool -dfa -nfa t.g

Thanks, Terence, for the glimpse into ANTLR 3's
machine. It is, indeed, more complicated. In fact,
most humans could safely regard the extra epsilon
transitions as superfluous. What significance do they
have for ANTLR?

Thanks again for the knowledge.

Jeff



From parrt at cs.usfca.edu  Sat Jan  7 12:28:33 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan  7 12:29:57 2006
Subject: [antlr-interest] State Machines Galore
In-Reply-To: <20060107202320.66024.qmail@web54513.mail.yahoo.com>
References: <20060107202320.66024.qmail@web54513.mail.yahoo.com>
Message-ID: <2A550F0E-E1E5-48B2-8A73-4E3EE58A155E@cs.usfca.edu>


On Jan 7, 2006, at 12:23 PM, Jeff Barnes wrote:

>> Actually, v3 builds something more complicated.  For
>> your
>> entertainment, run
>>
>> java org.antlr.Tool -dfa -nfa t.g
>
> Thanks, Terence, for the glimpse into ANTLR 3's
> machine. It is, indeed, more complicated. In fact,
> most humans could safely regard the extra epsilon
> transitions as superfluous. What significance do they
> have for ANTLR?
>
> Thanks again for the knowledge.

My pleasure.  It turns out I need extra epsilon's to aid in NFA->DFA  
conversion.  I need a state that begins an alternative that does not  
have a downward link to the next alternative :)

Ter
From jbarnesweb at yahoo.com  Sun Jan  8 15:57:08 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Sun Jan  8 15:57:14 2006
Subject: [antlr-interest] State Machines Galore
In-Reply-To: <2A550F0E-E1E5-48B2-8A73-4E3EE58A155E@cs.usfca.edu>
Message-ID: <20060108235708.95081.qmail@web54514.mail.yahoo.com>



--- Terence Parr <parrt@cs.usfca.edu> wrote:

> My pleasure.  It turns out I need extra epsilon's to
> aid in NFA->DFA  
> conversion.  I need a state that begins an
> alternative that does not  
> have a downward link to the next alternative :)

Ahhh, I see. An alternative is not a state and an
NFAState can have at most 2 transitions. Why is that?

Thanks again. It's becoming a little clearer to me.

Jeff

=========
Jeff Barnes
(206)245-6100

There are two rules for being a successful consultant: Rule 1 - Don't tell people everything you know.
From mail.tinker at gmail.com  Sun Jan  8 20:46:09 2006
From: mail.tinker at gmail.com (tinker tailor)
Date: Sun Jan  8 20:46:11 2006
Subject: [antlr-interest] lexer rule matching problem
In-Reply-To: <E1EuskT-0007Js-00@gecko>
References: <c7b221a70601060609u7ae19f2w5f84d19f0dcf5651@mail.gmail.com>
	<E1EuskT-0007Js-00@gecko>
Message-ID: <c7b221a70601082046r4c96a28dpf6af55944fef4b88@mail.gmail.com>

Hi John,
   Seems like this should do just what i want. I'll test it out and
let you know.
Thanks,
Tinker
:)

On 1/6/06, John B. Brodie <jbb@acm.org> wrote:
> Tinker Tailor asked:
> >  I am trying to parse a subset of the vbscript language, and have run
> >into the following problem:
> >   The '&' in VBS can be used in two ways -
> >       1. As a concatenation operator
> >              e.g.:  a = b & c    or   a=b&c
> >       2.As part of the prefix ("&H") and optional suffix('&') for
> >hexadecimal numbers
> >             e.g.:  a=&H9Abc    or  a=&H9Abc&
> >
> >So, here are the rules I made in my lexer (lookahead=3):
> >
> >CONCAT : '&';
> >HEX : "&h" (HEX_DIGIT)+ (('&')?)! ;
> >HEX_DIGIT : '0'..'9' | 'a'..'f' ;
> >
> >Now what I want the lexer to do is to first try and match a hex
> >number, and only when that fails, to try and match for the CONCAT
> >token. But I am not really sure how to tell antlr that. :(
> > As things stand, the lexer first matches CONCAT, and as a result
> >throws the 'unexpected token: exception when I give it the following
> >valid input:
> >     a = &H345ad&
> >
> >Any suggestions?
>
> untested, but perhaps this might do it:
>
> token { HEX; }
> CONCAT : '&' (( 'h' (HEX_DIGIT)+ (('&')?)! ){ $setType(HEX); })? ;
> protected HEX_DIGIT : '0'..'9' | 'a'..'f' ;
>
From mail.tinker at gmail.com  Sun Jan  8 20:59:41 2006
From: mail.tinker at gmail.com (tinker tailor)
Date: Sun Jan  8 20:59:43 2006
Subject: [antlr-interest] lexer rule matching problem
In-Reply-To: <1136560058.4983.2.camel@localhost.localdomain>
References: <c7b221a70601060609u7ae19f2w5f84d19f0dcf5651@mail.gmail.com>
	<E1EuskT-0007Js-00@gecko>
	<1136560058.4983.2.camel@localhost.localdomain>
Message-ID: <c7b221a70601082059t3aac9229j7bfc5faddde09408@mail.gmail.com>

Hi Martin,
  As per the Microsoft VBScript interpreter, for a VBS statement like
    b=a&h3
  the correct token stream to expect would be
    IDENTIFIER EQUALS IDENTIFIER HEX
  which is exactly what we are getting. The official interpreter first
tries to parse the text as a hex, and only when that fails does it try
to interpret it as an identifier. So, the above vbs statement actually
causes the interpreter to throw an error.
   A statement like
      b=b&&h3
  is valid, and produces the following
      IDENTIFIER EQUALS IDENTIFIER CONCAT HEX
So, while diambiguating in the parser might make the language more
logical, since I want to stay faithfull to the official version, I
have to implement the quirks as well.

- tinker
:)



On 1/6/06, Martin Probst <mail@martin-probst.com> wrote:
>
> > token { HEX; }
> > CONCAT : '&' (( 'h' (HEX_DIGIT)+ (('&')?)! ){ $setType(HEX); })? ;
> > protected HEX_DIGIT : '0'..'9' | 'a'..'f' ;
>
> What happens if someone wants do to this:
>
> a = "foo"
> h3 = "bar"
> b = a&h3
>
> You'll end up with a token stream of IDENTIFIER EQUALS IDENTIFIER HEX.
> The lexer needs to know that it's in a non-operator state (where a
> concat cannot occur) as the language is ambiguous otherwise. Maybe you
> can also get around it by disambiguating in the parser, e.g. lex the '&'
> simply as an AMPERSAND and let the parser figure out what it is.
>
> Martin
>
>
From donalmurtagh at yahoo.co.uk  Mon Jan  9 04:49:39 2006
From: donalmurtagh at yahoo.co.uk (DM)
Date: Mon Jan  9 04:49:41 2006
Subject: [antlr-interest] TokenStreamRewriteEngine
Message-ID: <20060109124939.2646.qmail@web32015.mail.mud.yahoo.com>

Hi,

I'm using ANTLR to validate and modify a structured text file.
Originally, I intended to enable the file to be modified by:

1. Building a min/max AST
2. Modifying the min/max AST
3. Printing out the tokens in the modified AST in the original order

As per the approach advocated in the article:
http://www.antlr.org/article/preserving.token.order/preserving.token.order.tml

However, this solution is inefficient, as I'll need to reparse the file after each modification
(in order to reconstruct the min/max AST). This is a particular problem for me, as the file is
very large.

As an alternative approach, TP suggested using his TokenStreamRewriteEngine. An example of using
this is presented in the article:
http://www.antlr.org/article/rewrite.engine/index.tml

However, in this example (generating a C header file from a source file), the necessary
modifications are known a priori. But in my case, the modifications will only be known at runtime,
as they depend on user input.

Is TokenStreamRewriteEngine suitable for use only when one type of modifications are possible? For
example, would it be possible to modify the example in the article to alternatively enable:

- all global variables to be deleted OR
- all global function names to be renamed so they begin with "foo"

Thanks in advance,
DM




	
	
		
___________________________________________________________ 
Yahoo! Messenger - NEW crystal clear PC to PC calling worldwide with voicemail http://uk.messenger.yahoo.com
From mail.tinker at gmail.com  Mon Jan  9 07:20:02 2006
From: mail.tinker at gmail.com (tinker tailor)
Date: Mon Jan  9 07:20:07 2006
Subject: [antlr-interest] lexer rule matching problem
In-Reply-To: <c7b221a70601082046r4c96a28dpf6af55944fef4b88@mail.gmail.com>
References: <c7b221a70601060609u7ae19f2w5f84d19f0dcf5651@mail.gmail.com>
	<E1EuskT-0007Js-00@gecko>
	<c7b221a70601082046r4c96a28dpf6af55944fef4b88@mail.gmail.com>
Message-ID: <c7b221a70601090720p28f70065t2944cc04065e88b2@mail.gmail.com>

Nope, that didn't work! :( But I finally found the solution!! :D

The trouble with the rule:
  CONCAT : '&' (( 'h' (HEX_DIGIT)+ (('&')?)! ){ $setType(HEX); })? ;
is that the lexer can't backtrack if it gets an input like a=a&height
Since the main requirement is that the lexer first try to match a hex
number, and failing that backtrack and just match the ampersand '&', I
decided to check out ...yup, you guessed it...syntactic predicates!
So, after much tinkering (and some tailoring), I finally arrived at a
rule that is able to process all my input files correctly. And for
your viewing pleasure, here it is:
==================
 CONCAT :  ('&')=> (HEX_NUM)=>HEX_NUM{_ttype = HEX;}
                |(OCT_NUM)=>OCT_NUM{_ttype = OCT;}
                | '&'
         ;
protected  HEX_NUM
: '&' 'h' (HEX_DIGIT)+ (('&')?)!
;
protected OCT_NUM
: '&' 'o' ('0' .. '7')+ ;

==================
Note that this rule takes care of the string concatenation operator
'&', as well as HEX (&H1&, &H2) and OCTAL (&O7) numbers.

Now here is another question: valid hex numbers in VB can only have
upto 8 digits. Is there any way in ANTLR that I can specify the number
of times to match a  rule?

off for some well deserved sleep.

- tinker
:)



On 1/9/06, tinker tailor <mail.tinker@gmail.com> wrote:
> Hi John,
>    Seems like this should do just what i want. I'll test it out and
> let you know.
> Thanks,
> Tinker
> :)
>
> On 1/6/06, John B. Brodie <jbb@acm.org> wrote:
> > Tinker Tailor asked:
> > >  I am trying to parse a subset of the vbscript language, and have run
> > >into the following problem:
> > >   The '&' in VBS can be used in two ways -
> > >       1. As a concatenation operator
> > >              e.g.:  a = b & c    or   a=b&c
> > >       2.As part of the prefix ("&H") and optional suffix('&') for
> > >hexadecimal numbers
> > >             e.g.:  a=&H9Abc    or  a=&H9Abc&
> > >
> > >So, here are the rules I made in my lexer (lookahead=3):
> > >
> > >CONCAT : '&';
> > >HEX : "&h" (HEX_DIGIT)+ (('&')?)! ;
> > >HEX_DIGIT : '0'..'9' | 'a'..'f' ;
> > >
> > >Now what I want the lexer to do is to first try and match a hex
> > >number, and only when that fails, to try and match for the CONCAT
> > >token. But I am not really sure how to tell antlr that. :(
> > > As things stand, the lexer first matches CONCAT, and as a result
> > >throws the 'unexpected token: exception when I give it the following
> > >valid input:
> > >     a = &H345ad&
> > >
> > >Any suggestions?
> >
> > untested, but perhaps this might do it:
> >
> > token { HEX; }
> > CONCAT : '&' (( 'h' (HEX_DIGIT)+ (('&')?)! ){ $setType(HEX); })? ;
> > protected HEX_DIGIT : '0'..'9' | 'a'..'f' ;
> >
>
From esof1 at student.cs.ucc.ie  Tue Jan 10 03:51:12 2006
From: esof1 at student.cs.ucc.ie (Edward O'Flynn)
Date: Tue Jan 10 03:51:08 2006
Subject: [antlr-interest] TokenStreamRewriteEngine + java profiling
In-Reply-To: <20060109124939.2646.qmail@web32015.mail.mud.yahoo.com>
References: <20060109124939.2646.qmail@web32015.mail.mud.yahoo.com>
Message-ID: <43C39FB0.6040709@student.cs.ucc.ie>

Hi all

I am using the TokenStreamRewriteEngine to build a java profiling tool, 
that will
count primitive operations, e.g. assignment opertations, comparative 
ops, aritmetic ops.
The way I want to rewrite the code is as follows
e.g.

for(int i=0+counter.incAssign();i<3+counter.incCompar() && 
i>-1+counter.incCompar(), i++)
{//code
}

where counter.incCompar() returns 0

The way i am writing this is as follows

forCond
    :    (expression)?
        {#forCond = #(#[FOR_CONDITION,"FOR_CONDITION"],#forCond);}
        {String insertion="counter.incCompar()";
          engine.insertAfter(LT(0), insertion)
        }  
;
However this just adds counter.incCompar() to the last comnparative 
operation in the for loop
How can add this bit of text to both, is there an easier way then the 
way I am doing it?
I have tried rewriting some of the expression rules but it seems to add 
the text to just about anything,

Will appreciate any help lads

cheers
ed.








From esof1 at student.cs.ucc.ie  Tue Jan 10 03:51:44 2006
From: esof1 at student.cs.ucc.ie (Edward O'Flynn)
Date: Tue Jan 10 03:51:40 2006
Subject: [antlr-interest] TokenStreamRewriteEngine + java profiling
In-Reply-To: <20060109124939.2646.qmail@web32015.mail.mud.yahoo.com>
References: <20060109124939.2646.qmail@web32015.mail.mud.yahoo.com>
Message-ID: <43C39FD0.7070906@student.cs.ucc.ie>

Hi all

I am using the TokenStreamRewriteEngine to build a java profiling tool, 
that will
count primitive operations, e.g. assignment opertations, comparative 
ops, aritmetic ops.
The way I want to rewrite the code is as follows
e.g.

for(int i=0+counter.incAssign();i<3+counter.incCompar() && 
i>-1+counter.incCompar(), i++)
{//code
}

where counter.incCompar() returns 0

The way i am writing this is as follows

forCond
    :    (expression)?
        {#forCond = #(#[FOR_CONDITION,"FOR_CONDITION"],#forCond);}
        {String insertion="counter.incCompar()";
          engine.insertAfter(LT(0), insertion)
        }  
;
However this just adds counter.incCompar() to the last comnparative 
operation in the for loop
How can add this bit of text to both, is there an easier way then the 
way I am doing it?
I have tried rewriting some of the expression rules but it seems to add 
the text to just about anything,

Will appreciate any help lads

cheers
ed.








From atripp at jazillian.com  Tue Jan 10 09:13:35 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Tue Jan 10 09:13:36 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C3EB3F.8010503@jazillian.com>

In a fit of reverse-writer's-block last night, I wrote down
some thoughts on AST treewalking and StringTemplate, titled
"Why I don't Use StringTemplate for Language translation"

The article is here: http://www.jazillian.com/stringTemplate.html

The article also shed a bit more light on my radical pattern-matching
based approach to translating C to Java. ummm...correction...it
really  mostly sheds darkness on the AST-walking approach :)

Enjoy!
Andy
From parrt at cs.usfca.edu  Tue Jan 10 09:25:33 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 09:25:39 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C3EB3F.8010503@jazillian.com>
References: <43C3EB3F.8010503@jazillian.com>
Message-ID: <0A92539A-F454-4979-B7D1-0004499A8ABE@cs.usfca.edu>

Hi Andy,

Nice article!  You should post to the articles section on  
antlr.org. :)  Naturally, I'll respond with a rebuttal when I get a  
chance. ;)

Thanks,
Ter
On Jan 10, 2006, at 9:13 AM, Andy Tripp wrote:

> In a fit of reverse-writer's-block last night, I wrote down
> some thoughts on AST treewalking and StringTemplate, titled
> "Why I don't Use StringTemplate for Language translation"
>
> The article is here: http://www.jazillian.com/stringTemplate.html
>
> The article also shed a bit more light on my radical pattern-matching
> based approach to translating C to Java. ummm...correction...it
> really  mostly sheds darkness on the AST-walking approach :)
>
> Enjoy!
> Andy

From atripp at jazillian.com  Tue Jan 10 10:25:40 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Tue Jan 10 10:25:41 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C3FC24.3050609@jazillian.com>

I posted the article on antlr.org:
http://antlr.org/article/1136917339929/stringTemplate.html

It's in the "articles" section, under "Heresy" ;)

Andy

>Hi Andy,
>
>Nice article!  You should post to the articles section on  
>antlr.org. :)  Naturally, I'll respond with a rebuttal when I get a  
>chance. ;)
>
>Thanks,
>Ter
>On Jan 10, 2006, at 9:13 AM, Andy Tripp wrote:
>
>>/ In a fit of reverse-writer's-block last night, I wrote down
>/>/ some thoughts on AST treewalking and StringTemplate, titled
>/>/ "Why I don't Use StringTemplate for Language translation"
>/>/
>/>/ The article is here: http://www.jazillian.com/stringTemplate.html
>/>/
>/>/ The article also shed a bit more light on my radical pattern-matching
>/>/ based approach to translating C to Java. ummm...correction...it
>/>/ really  mostly sheds darkness on the AST-walking approach :)
>/>/
>/>/ Enjoy!
>/>/ Andy/
>

From parrt at cs.usfca.edu  Tue Jan 10 12:07:30 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 12:09:05 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C3FC24.3050609@jazillian.com>
References: <43C3FC24.3050609@jazillian.com>
Message-ID: <2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>


On Jan 10, 2006, at 10:25 AM, Andy Tripp wrote:

> I posted the article on antlr.org:
> http://antlr.org/article/1136917339929/stringTemplate.html
>
> It's in the "articles" section, under "Heresy" ;)

Ha hah ha!  Cool.  Thanks.

Before posting my thoughts, I would like to hear people's comments  
for/against.  I will add initially, however, that you seem to be  
sweeping under the rug the one big counterexample of your statement,  
"one assumption is that the structure of the input and output  
language ASTs are similar."  I'm pretty sure that ANTLR's input /  
output languages are vastly more different than your C->Java  
translation. ;)

This should make for an excellent discussion, which hopefully will  
get folded in a future book.

Regards,
Ter
From sohail at taggedtype.net  Tue Jan 10 13:14:08 2006
From: sohail at taggedtype.net (sohail@taggedtype.net)
Date: Tue Jan 10 13:14:15 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>
References: <43C3FC24.3050609@jazillian.com>
	<2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>
Message-ID: <49120.127.0.0.1.1136927648.squirrel@taggedtype.net>

>
> On Jan 10, 2006, at 10:25 AM, Andy Tripp wrote:
>
>> I posted the article on antlr.org:
>> http://antlr.org/article/1136917339929/stringTemplate.html
>>
>> It's in the "articles" section, under "Heresy" ;)
>
> Ha hah ha!  Cool.  Thanks.
>
> Before posting my thoughts, I would like to hear people's comments
> for/against.  I will add initially, however, that you seem to be
> sweeping under the rug the one big counterexample of your statement,
> "one assumption is that the structure of the input and output
> language ASTs are similar."  I'm pretty sure that ANTLR's input /
> output languages are vastly more different than your C->Java
> translation. ;)
>
> This should make for an excellent discussion, which hopefully will
> get folded in a future book.

I was struck by the example of 5 lines of C code being folded into one
line of Java code. Why couldn't you have a tree parser do this? It would
be inefficient, but I don't know if that is the point of the article.
From parrt at cs.usfca.edu  Tue Jan 10 13:21:41 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 13:22:53 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <49120.127.0.0.1.1136927648.squirrel@taggedtype.net>
References: <43C3FC24.3050609@jazillian.com>
	<2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>
	<49120.127.0.0.1.1136927648.squirrel@taggedtype.net>
Message-ID: <CEBA2797-578A-4595-AED1-8036D1311757@cs.usfca.edu>


On Jan 10, 2006, at 1:14 PM, sohail@taggedtype.net wrote:
> I was struck by the example of 5 lines of C code being folded into one
> line of Java code. Why couldn't you have a tree parser do this? It  
> would
> be inefficient, but I don't know if that is the point of the article.

Hi.  My impression from reading his article was that Andy was  
interpreting tree walker to be the simple visitor pattern where all  
you can see is "I'm at node function definition" as opposed to the  
more powerful grammar-based tree pattern matching:

funcdef
	: ^(FUNCDEF ID args body)
	;

Specifically he asked where one would worry about whether or not a  
return statement was present in the body.  Seems straightforward to  
have an action after the body rule reference that checked a boolean  
set by body.  You might do this (using the new dynamic scope stuff):

funcdef
scope {
   boolean hasReturn;
}
@init {
   hasReturn = false;
}
	: ^(FUNCDEF ID args body) {if ($hasReturn) ...}
	;

body : stat+ ;

stat : ... | ^(RETURN expr) {$funcdef::hasReturn=true;} | ... ;

Andy, is this easier or harder than you imagined?  Does it address  
your point?

Ter
From thiago.arrais at gmail.com  Tue Jan 10 14:01:43 2006
From: thiago.arrais at gmail.com (Thiago Arrais)
Date: Tue Jan 10 14:01:46 2006
Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
Message-ID: <e163e2f50601101401n2fc7aad9r@mail.gmail.com>

Hello,

We at EclipseFP (http://eclipsefp.sourceforge.net) are developing an
Eclipse-based IDE for the Haskell language and we are using Antlr on
our parser/lexer code. There is of course the need to access the Antlr
library at runtime and the standard way to do this in Eclipse is
having a plugin that contains it. We managed to do that so far by
packaging the antlr inside one of our plugins but we see that this
isn't the best approach, since we don't really maintain the antlr
code. So, we are looking for a plugin (preferarbly with an easy to use
installation process, like an update site) that solely contains it.

I happened to find the antlreclipse plugin at

http://antlreclipse.sourceforge.net/

But the standard setup downloads and installs a collection of plugins
for editing Antlr code. Most of our users won't need all those
plugins, but only the main antlr library for running the haskell
parser code. Is there a way to download only a plugin with the library
code, without the Antlr editor and other plugins?  I see that the
project release page includes a library only package, but it seems
outdated. Is there any other antlr eclipse plugin (one that is not
easily found with a simple web search)?

Am I looking at the wrong place? If so, could anyone point me to the
right direction?

I am willing to provide such a package (maybe for download at the
antlr download page, or helping the antlreclipse folks) if there is
interest.

Cheers,

Thiago Arrais
From atripp at jazillian.com  Tue Jan 10 14:05:57 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Tue Jan 10 14:05:58 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C42FC5.30605@jazillian.com>

> 
>I will add initially, however, that you seem to be  
>sweeping under the rug the one big counterexample of your statement,  
>"one assumption is that the structure of the input and output  
>language ASTs are similar."  I'm pretty sure that ANTLR's input /  
>output languages are vastly more different than your C->Java  
>translation. ;)

Yes, good point! I guess it's not so much an issue of "is the output
language/AST similar to the input one". It's really "can each piece of the output 
language/AST be derived from a single piece of the input language/AST".

Or, "show me a node in the ANTLR input AST, and I will show you the equivalent
node in the Java-version of the ANTLR output AST (probably without thoroughly
examining the whole AST - just looking at the one node".

But..."show me a node in a C AST (let's say INT_NUMBER "0"), and I can't tell
you what the equivalent node is in the output Java AST without a thorough
examination of the AST, both above and below the current node."

So a morse-code-to-English translator is trivial, even though the two ASTs are
completely different. But a Spanish-to-Italian translator is incredibly complex,
even though the ASTs are similar. The difference is really the extent of the
amount of work that needs to be done in examining the input AST. In ANTLR, you
rarely have to look beyond the current AST node. In C-to-Java (at least to the
extent that I've done it), you usually do.

Andy

p.s. I sure hope there's a way to update an article on antlr.org :)

From sohail at taggedtype.net  Tue Jan 10 14:15:00 2006
From: sohail at taggedtype.net (sohail@taggedtype.net)
Date: Tue Jan 10 14:15:09 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <CEBA2797-578A-4595-AED1-8036D1311757@cs.usfca.edu>
References: <43C3FC24.3050609@jazillian.com>
	<2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>
	<49120.127.0.0.1.1136927648.squirrel@taggedtype.net>
	<CEBA2797-578A-4595-AED1-8036D1311757@cs.usfca.edu>
Message-ID: <50714.127.0.0.1.1136931300.squirrel@taggedtype.net>

>
> On Jan 10, 2006, at 1:14 PM, sohail@taggedtype.net wrote:
>> I was struck by the example of 5 lines of C code being folded into one
>> line of Java code. Why couldn't you have a tree parser do this? It
>> would
>> be inefficient, but I don't know if that is the point of the article.
>
> funcdef
> scope {
>    boolean hasReturn;
> }
> @init {
>    hasReturn = false;
> }
> 	: ^(FUNCDEF ID args body) {if ($hasReturn) ...}
> 	;

OT for the topic, but why do we have an @init{...} action where before
just {...} would have sufficed? I'm an totally unfamiliar with antlr v3
though :)
From atripp at jazillian.com  Tue Jan 10 14:29:04 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Tue Jan 10 14:29:04 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C43530.1070909@jazillian.com>

>
>
>On Jan 10, 2006, at 1:14 PM, sohail at taggedtype.net <http://www.antlr.org/mailman/listinfo/antlr-interest> wrote:
>>/ I was struck by the example of 5 lines of C code being folded into one
>/>/ line of Java code. Why couldn't you have a tree parser do this? It  
>/>/ would
>/>/ be inefficient, but I don't know if that is the point of the article.
>/
>Hi.  My impression from reading his article was that Andy was  
>interpreting tree walker to be the simple visitor pattern where all  
>you can see is "I'm at node function definition" as opposed to the  
>more powerful grammar-based tree pattern matching:
>
>funcdef
>	: ^(FUNCDEF ID args body)
>	;
>
>Specifically he asked where one would worry about whether or not a  
>return statement was present in the body.  Seems straightforward to  
>have an action after the body rule reference that checked a boolean  
>set by body.  You might do this (using the new dynamic scope stuff):
>
>funcdef
>scope {
>   boolean hasReturn;
>}
>@init {
>   hasReturn = false;
>}
>	: ^(FUNCDEF ID args body) {if ($hasReturn) ...}
>	;
>
>body : stat+ ;
>
>stat : ... | ^(RETURN expr) {$funcdef::hasReturn=true;} | ... ;
>
>Andy, is this easier or harder than you imagined?  Does it address  
>your point?
>
>Ter
>

Ter,
If I understand you right, you've inadvertently proved my point exactly.
Your code above (if I read it right) only checks that the function 
contains at least one "return".
But it may find a return inside some "if", for example, whereas javac 
does static flow analysis
and will see that there exists a path through the function that does not 
end with a "return".
I mention this in my article.

So this answer is about the level of difficulty that I expected, but it 
doesn't do what it needs to.
Andy
From antlr at shmuelhome.mine.nu  Tue Jan 10 14:29:21 2006
From: antlr at shmuelhome.mine.nu (shmuel siegel)
Date: Tue Jan 10 14:29:35 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <CEBA2797-578A-4595-AED1-8036D1311757@cs.usfca.edu>
References: <43C3FC24.3050609@jazillian.com>	<2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>	<49120.127.0.0.1.1136927648.squirrel@taggedtype.net>
	<CEBA2797-578A-4595-AED1-8036D1311757@cs.usfca.edu>
Message-ID: <43C43541.9030906@shmuelhome.mine.nu>

Terence Parr wrote:
> Hi.  My impression from reading his article was that Andy was  
> interpreting tree walker to be the simple visitor pattern where all  you 
> can see is "I'm at node function definition" as opposed to the  more 
> powerful grammar-based tree pattern matching:
> 
> funcdef
>     : ^(FUNCDEF ID args body)
>     ;
> 
> Specifically he asked where one would worry about whether or not a  
> return statement was present in the body.  Seems straightforward to  
> have an action after the body rule reference that checked a boolean  set 
> by body.  You might do this (using the new dynamic scope stuff):
> 
> funcdef
> scope {
>   boolean hasReturn;
> }
> @init {
>   hasReturn = false;
> }
>     : ^(FUNCDEF ID args body) {if ($hasReturn) ...}
>     ;
> 
> body : stat+ ;
> 
> stat : ... | ^(RETURN expr) {$funcdef::hasReturn=true;} | ... ;
> 
> Andy, is this easier or harder than you imagined?  Does it address  your 
> point?
> 
> Ter
> 
> 
I think that Andy was more bothered by how to translate something like

int func(int x)
{
     if(x=5)
	return 3;
}

since even though it looks like java, it is not valid java.

Shmuel


-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.371 / Virus Database: 267.14.16/225 - Release Date: 1/9/2006



-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.371 / Virus Database: 267.14.16/225 - Release Date: 1/9/2006

From parrt at cs.usfca.edu  Tue Jan 10 14:37:47 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 14:38:59 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C42FC5.30605@jazillian.com>
References: <43C42FC5.30605@jazillian.com>
Message-ID: <7AB6FAD5-B069-401A-AB1E-B49AF9336607@cs.usfca.edu>


On Jan 10, 2006, at 2:05 PM, Andy Tripp wrote:

>> I will add initially, however, that you seem to be  sweeping under  
>> the rug the one big counterexample of your statement,  "one  
>> assumption is that the structure of the input and output  language  
>> ASTs are similar."  I'm pretty sure that ANTLR's input /  output  
>> languages are vastly more different than your C->Java   
>> translation. ;)
>
> Yes, good point! I guess it's not so much an issue of "is the output
> language/AST similar to the input one". It's really "can each piece  
> of the output language/AST be derived from a single piece of the  
> input language/AST".

Well, the ANTLR translation is the farthest possible from each input  
node goes to a single output node.  First, I don't do any tree  
translation at all.  I parse the grammar into an AST from which I  
derive an NFA from which I derive DFA.  I walk the AST multiple  
times, annotating the tree and building other structures such as a  
symbol table, NFA, DFA, etc...  The final codegen.g tree walker  
guides translation but is hardly a simple "see a node, spit out a  
node" kind of thing.

You'll note that the following construct could be used for a subrule  
(a|b):

if ( lookahead consistent with a ) {
   a();
else {
   b();
}

Now that pattern is similar to your

strcasecmp(v1, v2) --> v1.compareToIgnoreCase(v2)

example.  The key difference is that I just spent probably 5,000ms  
walking all over hell and back figuring out what "lookahead  
consistent with a" actually is.

The disconnect I think you may have with ST is that you think it's  
doing more than just spewing text.  It cannot do any processing; you  
must collect data, do analysis, do whatever you want and then use it  
rather than print statements to dump stuff out. :)

> Or, "show me a node in the ANTLR input AST, and I will show you the  
> equivalent
> node in the Java-version of the ANTLR output AST (probably without  
> thoroughly
> examining the whole AST - just looking at the one node".

The structure is there, yes: subrule to what template, but the  
details are computed from rather involved analysis and the results  
jammed in the template.  Templates only say what the output looks  
like, not which output templates to use nor how to fill in data  
values.  I've built lots of language translators over the years and  
ANTLR is much harder than any language translator I've ever been  
involved with.

> But..."show me a node in a C AST (let's say INT_NUMBER "0"), and I  
> can't tell
> you what the equivalent node is in the output Java AST without a  
> thorough
> examination of the AST, both above and below the current node."

Yep, you have to do analysis to figure out the kind of construct to  
generate.  When you know, then you ask the appropriate template to  
spit stuff out :)

i think we are actually in more agreement than you realize...i think  
there is simply a disconnect with how tree walkers + ST would operate.

> So a morse-code-to-English translator is trivial, even though the  
> two ASTs are
> completely different. But a Spanish-to-Italian translator is  
> incredibly complex,
> even though the ASTs are similar. The difference is really the  
> extent of the
> amount of work that needs to be done in examining the input AST. In  
> ANTLR, you
> rarely have to look beyond the current AST node.

Boy I wish that were true!  I've spent almost 3 hard years building  
ANTLR v3. ;)  Simple example.

a : ID ... {$ID.text} ;

I must do use-def chains for all labels and token references etc...  
so that when I see $ID I know what it means; hardly a local AST node  
reference.  Further, I have to go back to the code generator for the  
ID and add a label so that $ID can actually work in the action. :)

> In C-to-Java (at least to the
> extent that I've done it), you usually do.

Your work looks excellent...and I like the pattern based approach for  
small sets of patterns and hope to implement a general mechanism  
sometime myself!

> Andy
>
> p.s. I sure hope there's a way to update an article on antlr.org :)

The old fashioned way. ;)  Send me a new copy ;)

Ter
From parrt at cs.usfca.edu  Tue Jan 10 14:38:38 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 14:39:52 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <50714.127.0.0.1.1136931300.squirrel@taggedtype.net>
References: <43C3FC24.3050609@jazillian.com>
	<2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>
	<49120.127.0.0.1.1136927648.squirrel@taggedtype.net>
	<CEBA2797-578A-4595-AED1-8036D1311757@cs.usfca.edu>
	<50714.127.0.0.1.1136931300.squirrel@taggedtype.net>
Message-ID: <06BE30EA-F6D0-40C1-9AA1-908EE274B881@cs.usfca.edu>


On Jan 10, 2006, at 2:15 PM, sohail@taggedtype.net wrote:
> OT for the topic, but why do we have an @init{...} action where before
> just {...} would have sufficed? I'm an totally unfamiliar with  
> antlr v3
> though :)

Because the amount of stuff I wanted in there got complicated enough  
and because @init {...} is consistent with named actions elsewhere :)

@header {...}
@members {...}
etc...

Ter
From atripp at jazillian.com  Tue Jan 10 14:40:25 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Tue Jan 10 14:40:27 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C437D9.8030800@jazillian.com>

>
>
>I was struck by the example of 5 lines of C code being folded into one
>line of Java code. Why couldn't you have a tree parser do this? It would
>be inefficient, but I don't know if that is the point of the article.
>

You can't have a tree parser look for those 5 lines because
 there might be hundreds of different combinations of 5 lines that would 
all fold into
that one line of Java code.

In order to write a "look for a chunk of code that is really just doing 
a strcpy()" function,
you're going to have to do some real work.

How many ways are there to write your own "strcpy()", each using a few 
lines?
You could use a "for" or "while" loop. You can reference the array using 
pointer syntax or array syntax,
you can use a pointer to loop through or an index. You can increment the 
pointer/index with
i++, ++i, or i=i+1. You could just use strcpy() or strncpy(). You could 
wrap strcpy() with your
own macro or function. You could allocate new memory for
the destination string or assume it's already allocated. You could loop 
until you hit '\0' or use
strlen().

In order to avoid a combinatorial explosion of various patterns to look 
for, you'll need to write
some code that tries to look chunks of code that seem to be doing 
strcpy(), and yet is
flexible enough to handles these kinds variations.

Hope that answers the question.
Andy
From parrt at cs.usfca.edu  Tue Jan 10 14:41:41 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 14:42:55 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C43530.1070909@jazillian.com>
References: <43C43530.1070909@jazillian.com>
Message-ID: <8C118B14-26FE-4184-A01A-5833C0A33C77@cs.usfca.edu>


On Jan 10, 2006, at 2:29 PM, Andy Tripp wrote:
> Ter,
> If I understand you right, you've inadvertently proved my point  
> exactly.

Uh oh! ;)

> Your code above (if I read it right) only checks that the function  
> contains at least one "return".
> But it may find a return inside some "if", for example, whereas  
> javac does static flow analysis
> and will see that there exists a path through the function that  
> does not end with a "return".
> I mention this in my article.

Ah.  Sorry.  If you want flow analysis then yes you must right it.   
Then my boolean is a function call checking flow results.  Either I'd  
walk the tree building flow graphs or I'd build another structure and  
walk it.  What does this have to do with grammars and ST though?  You  
must compute it, period, right?  Use a tree, use a flow graph, use  
flat text, up to you.  Once you have a result to spit out (i.e,. "add  
a return statement or not"), you can use ST to say that.  ST has  
nothing to do with that.  The tree walker merely guides general  
output generation...it would reference a previous pass over the input  
that computed the flow analysis.

Ter


From atripp at jazillian.com  Tue Jan 10 14:50:51 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Tue Jan 10 14:50:51 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C43A4B.1040900@jazillian.com>

>
>
>I think that Andy was more bothered by how to translate something like
>
>int func(int x)
>{
>     if(x=5)
>	return 3;
>}
>
>since even though it looks like java, it is not valid java.
>
>Shmuel
>

I'm worried about that too :)
I do mention that issue in the article, saying "how do you make sure x 
is a boolean when you have if(x)".
My ForceToBooleanRule is one of the most complex, and one of the few 
that uses an ANTLR parser :)

The interesting thing about your example is that the "natural" Java 
translation (what a person would write) is
if (x == 5)
whereas any traditional AST-walking translator would probably produce
if ((x = 5) != 0)

While the second one is technically correct, and is probably what my 
product would produce today,
my product is designed so that I can easily add a rule to check for a 
"if (v=n)" bug, and go ahead and
fix the bug during translation. And I can and do add those sorts of 
rules! Do not try this at home
with your treewalking translator, kids :)

Andy
From antlr at shmuelhome.mine.nu  Tue Jan 10 15:02:39 2006
From: antlr at shmuelhome.mine.nu (shmuel siegel)
Date: Tue Jan 10 15:03:35 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C43A4B.1040900@jazillian.com>
References: <43C43A4B.1040900@jazillian.com>
Message-ID: <43C43D0F.5010403@shmuelhome.mine.nu>

Sorry, my typo got you started on another tact. I meant to use ==. The 
point is that not all paths have a return statement.

Andy Tripp wrote:
>>
>>
>> I think that Andy was more bothered by how to translate something like
>>
>> int func(int x)
>> {
>>     if(x=5)
>>     return 3;
>> }
>>
>> since even though it looks like java, it is not valid java.
>>
>> Shmuel
>>
> 
> I'm worried about that too :)
> I do mention that issue in the article, saying "how do you make sure x 
> is a boolean when you have if(x)".
> My ForceToBooleanRule is one of the most complex, and one of the few 
> that uses an ANTLR parser :)
> 
> The interesting thing about your example is that the "natural" Java 
> translation (what a person would write) is
> if (x == 5)
> whereas any traditional AST-walking translator would probably produce
> if ((x = 5) != 0)
> 
> While the second one is technically correct, and is probably what my 
> product would produce today,
> my product is designed so that I can easily add a rule to check for a 
> "if (v=n)" bug, and go ahead and
> fix the bug during translation. And I can and do add those sorts of 
> rules! Do not try this at home
> with your treewalking translator, kids :)
> 
> Andy
> 
> 



-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.371 / Virus Database: 267.14.16/225 - Release Date: 1/9/2006



-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.371 / Virus Database: 267.14.16/225 - Release Date: 1/9/2006

From parrt at cs.usfca.edu  Tue Jan 10 15:04:52 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 15:06:05 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C43541.9030906@shmuelhome.mine.nu>
References: <43C3FC24.3050609@jazillian.com>	<2371590C-8A32-4CDD-B9FE-60B7D90222FB@cs.usfca.edu>	<49120.127.0.0.1.1136927648.squirrel@taggedtype.net>
	<CEBA2797-578A-4595-AED1-8036D1311757@cs.usfca.edu>
	<43C43541.9030906@shmuelhome.mine.nu>
Message-ID: <5884EB7F-1330-4AF4-8B7D-680D51868392@cs.usfca.edu>


On Jan 10, 2006, at 2:29 PM, shmuel siegel wrote:
> I think that Andy was more bothered by how to translate something like
>
> int func(int x)
> {
>     if(x=5)
> 	return 3;
> }
>
> since even though it looks like java, it is not valid java.

This is a translation analysis issue; once you discover that x=5 is  
not a valid construct in the target language your logic must figure  
out what construct is valid.  When you know what it looks like, then  
generate it with print statements or ST..up to you. :)

Ter
From parrt at cs.usfca.edu  Tue Jan 10 15:08:15 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 15:09:28 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C437D9.8030800@jazillian.com>
References: <43C437D9.8030800@jazillian.com>
Message-ID: <A5CD572D-3892-4243-AFD2-07285A588376@cs.usfca.edu>


On Jan 10, 2006, at 2:40 PM, Andy Tripp wrote:
>> I was struck by the example of 5 lines of C code being folded into  
>> one
>> line of Java code. Why couldn't you have a tree parser do this? It  
>> would
>> be inefficient, but I don't know if that is the point of the article.
>>
>
> You can't have a tree parser look for those 5 lines because
> there might be hundreds of different combinations of 5 lines that  
> would all fold into
> that one line of Java code.

Did you build a general prolog like pattern translator?  If so, what  
strategy of rule application do you use?  You're aware I'm sure that  
depending on the strategy, the same set of patterns may not terminate?

> In order to write a "look for a chunk of code that is really just  
> doing a strcpy()" function,
> you're going to have to do some real work.

That is very true.  Whether you specify a pattern in your style or in  
a set of tree grammar patterns is irrelevant, though, right?

> How many ways are there to write your own "strcpy()", each using a  
> few lines?
> You could use a "for" or "while" loop. You can reference the array  
> using pointer syntax or array syntax,
> you can use a pointer to loop through or an index. You can  
> increment the pointer/index with
> i++, ++i, or i=i+1. You could just use strcpy() or strncpy(). You  
> could wrap strcpy() with your
> own macro or function. You could allocate new memory for
> the destination string or assume it's already allocated. You could  
> loop until you hit '\0' or use
> strlen().

So how do you do that with your patterns?

> In order to avoid a combinatorial explosion of various patterns to  
> look for, you'll need to write
> some code that tries to look chunks of code that seem to be doing  
> strcpy(), and yet is
> flexible enough to handles these kinds variations.

We've only heard problems so far without a solution in your  
style...could you bring some light to how you avoid looking for  
various patterns of code to find strcpy chunks?

Ter

From parrt at cs.usfca.edu  Tue Jan 10 15:16:19 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 10 15:17:33 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C43A4B.1040900@jazillian.com>
References: <43C43A4B.1040900@jazillian.com>
Message-ID: <3F44EF10-0B92-4DC1-840D-B42B4B9395DD@cs.usfca.edu>


On Jan 10, 2006, at 2:50 PM, Andy Tripp wrote:
> The interesting thing about your example is that the "natural" Java  
> translation (what a person would write) is
> if (x == 5)
> whereas any traditional AST-walking translator would probably produce
> if ((x = 5) != 0)
>
> While the second one is technically correct, and is probably what  
> my product would produce today,
> my product is designed so that I can easily add a rule to check for  
> a "if (v=n)" bug, and go ahead and
> fix the bug during translation. And I can and do add those sorts of  
> rules! Do not try this at home
> with your treewalking translator, kids :)

ooops...too late ;)

ifstat
	: ^(IF ^(ASSIGN ID expr) stat ) -> ifassign(...)
	| ^(IF expr stat) -> ifstat(...)
	;

where the ->foo(...) builds a template called foo and I've omitted  
the args for clarity.  This is ANTLR v3.  Not hard...this is  
precisely what grammars are useful for.

Pattern engines have trouble with semantic-based context.  For  
example, I can add a sem pred that tells me that an int ref is in a  
while or for of if...can your pattern matcher say "apply a rule only  
in this semantic or syntactic context"?  ;)

The thing is Andy that you are specifying text based rules and I am  
specifying tree based rules.  Further, I can only assume that you  
have a rule application engine that does this magic whereas I am  
using a weaker but more deterministic linear tree walker.

Note that most academics will agree with you about translation, lest  
you think you're the only one that thinks this way. See TXL,  
Stratego, ...  Also recall from a previous post of mine that your  
pattern matching engine may run into invalid paths or may even not  
terminate depending on your application strategy.  This is a very  
well known problem with this academic approach.

I will also point out that the number of people using declarative  
systems such as the academic ones are not used much by people  
building translators in the wild.  That said, the authors of those  
tools seem to be able to get them to do amazing things!

Ter
From atripp at jazillian.com  Tue Jan 10 15:18:33 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Tue Jan 10 15:18:32 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C440C9.7000500@jazillian.com>

>
>
>Well, the ANTLR translation is the farthest possible from each input  
>node goes to a single output node.  First, I don't do any tree  
>translation at all.  I parse the grammar into an AST from which I  
>derive an NFA from which I derive DFA.  I walk the AST multiple  
>times, annotating the tree and building other structures such as a  
>symbol table, NFA, DFA, etc...  The final codegen.g tree walker  
>guides translation but is hardly a simple "see a node, spit out a  
>node" kind of thing.
>  
>

OK, yea. Do use  ST in ANTLR 2.x, or is it new in 3.0? Do you have any 
pointers to where
I can find out more about how you use ST in ANTLR (or anyone else who is 
using ST
for complex stuff)? I guess I'm reading way to much into the simple 
examples you give in
these articles.

>You'll note that the following construct could be used for a subrule  
>(a|b):
>
>if ( lookahead consistent with a ) {
>   a();
>else {
>   b();
>}
>
>Now that pattern is similar to your
>
>strcasecmp(v1, v2) --> v1.compareToIgnoreCase(v2)
>
>example.  The key difference is that I just spent probably 5,000ms  
>walking all over hell and back figuring out what "lookahead  
>consistent with a" actually is.
>  
>
I think there's a key difference here. In your code, you have a mental 
picture of the AST
structure in your head (though of course it's trivial for this example). 
when I write:
old thing with v and x placeholders --> something else with x and v 
placeholders
I never have to have a mental picture an AST. I'm strictly thinking in 
terms of "patterns" or
"token streams".

>The disconnect I think you may have with ST is that you think it's  
>doing more than just spewing text.  
>
Well, I'm against both the treewalker and the ST approach. I understand 
that the STs are
just spitting out the text. Maybe at some point in the article I blamed 
STs when I should
have blamed treewalking, but the blame remains :)

>It cannot do any processing; you  
>must collect data, do analysis, do whatever you want and then use it  
>rather than print statements to dump stuff out. :)
>
>>/ Or, "show me a node in the ANTLR input AST, and I will show you the  
>/>/ equivalent
>/>/ node in the Java-version of the ANTLR output AST (probably without  
>/>/ thoroughly
>/>/ examining the whole AST - just looking at the one node".
>/
>The structure is there, yes: subrule to what template, but the  
>details are computed from rather involved analysis and the results  
>jammed in the template.  Templates only say what the output looks  
>like, not which output templates to use nor how to fill in data  
>values.  I've built lots of language translators over the years and  
>ANTLR is much harder than any language translator I've ever been  
>involved with.
>  
>
I don't doubt that. But then again, you're much smarter and more 
knowledgable than I am,
so I'll find things difficult that you don't :) It may be that 
treewalking and STs really are
the best solution to my problems, and I just can't get past their 
complexity and syntax.

>>/ But..."show me a node in a C AST (let's say INT_NUMBER "0"), and I  
>/>/ can't tell
>/>/ you what the equivalent node is in the output Java AST without a  
>/>/ thorough
>/>/ examination of the AST, both above and below the current node."
>/
>Yep, you have to do analysis to figure out the kind of construct to  
>generate.  When you know, then you ask the appropriate template to  
>spit stuff out :)
>
>i think we are actually in more agreement than you realize...i think  
>there is simply a disconnect with how tree walkers + ST would operate.
>  
>
So then let me ask, do you really consider ANTLR to have a "treewalking 
design"? How many
node actions does ANTLR have that are fairly trivial? I'll be interested 
to see what you say
about the specific issues I bring up.

My initial design did use the treewalker approach. I worked on it for a 
few months and I
was just overwhelmed with having to keep a mental picture of the AST 
structure.
I takes me a few seconds to type:

strcasecmp(v1, v2) --> v1.compareToIgnoreCase(v2)

And it would take me many times longer if I had to think about the AST
structure for those snippets of code.

>>/ So a morse-code-to-English translator is trivial, even though the  
>/>/ two ASTs are
>/>/ completely different. But a Spanish-to-Italian translator is  
>/>/ incredibly complex,
>/>/ even though the ASTs are similar. The difference is really the  
>/>/ extent of the
>/>/ amount of work that needs to be done in examining the input AST. In  
>/>/ ANTLR, you
>/>/ rarely have to look beyond the current AST node.
>/
>Boy I wish that were true!  I've spent almost 3 hard years building  
>ANTLR v3. ;)  Simple example.
>
>a : ID ... {$ID.text} ;
>
>I must do use-def chains for all labels and token references etc...  
>so that when I see $ID I know what it means; hardly a local AST node  
>reference.  Further, I have to go back to the code generator for the  
>ID and add a label so that $ID can actually work in the action. :)
>  
>
Right, same thing here. I often need a symbol table to lookup a variable 
type, but not only
that, I may need to go look at the declaration for various things (e.g. 
is it declared static?),
and maybe even do a check on every variable reference (is this ever used 
as an int? because
I want to change its type to boolean), and maybe even change every 
variable reference.

So in all that hard work for v3, how much is treewalking really buying 
you? In fact, I wonder
if you'd even say that what most of what ANTLR is doing is treewalking?

>>/ In C-to-Java (at least to the
>/>/ extent that I've done it), you usually do.
>/
>Your work looks excellent...and I like the pattern based approach for  
>small sets of patterns and hope to implement a general mechanism  
>sometime myself!
>
>>/ Andy
>/>/
>/>/ p.s. I sure hope there's a way to update an article on antlr.org :)
>/
>The old fashioned way. ;)  Send me a new copy ;)
>
>Ter
>
Thanks for the great feedback, and thanks for taking my comments the way 
they're
intended.

Andy
From scott at javadude.com  Tue Jan 10 16:37:52 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Tue Jan 10 16:38:07 2006
Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
In-Reply-To: <e163e2f50601101401n2fc7aad9r@mail.gmail.com>
Message-ID: <200601110022.k0B0MNIJ006570@s2.eroute.net>

You can just grab the org.antlr plugin from that distribution and you'll be
fine.

-- Scott 

> -----Original Message-----
> From: antlr-interest-bounces@antlr.org 
> [mailto:antlr-interest-bounces@antlr.org] On Behalf Of Thiago Arrais
> Sent: Tuesday, January 10, 2006 5:02 PM
> To: antlr-interest@antlr.org
> Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
> 
> Hello,
> 
> We at EclipseFP (http://eclipsefp.sourceforge.net) are 
> developing an Eclipse-based IDE for the Haskell language and 
> we are using Antlr on our parser/lexer code. There is of 
> course the need to access the Antlr library at runtime and 
> the standard way to do this in Eclipse is having a plugin 
> that contains it. We managed to do that so far by packaging 
> the antlr inside one of our plugins but we see that this 
> isn't the best approach, since we don't really maintain the 
> antlr code. So, we are looking for a plugin (preferarbly with 
> an easy to use installation process, like an update site) 
> that solely contains it.
> 
> I happened to find the antlreclipse plugin at
> 
> http://antlreclipse.sourceforge.net/
> 
> But the standard setup downloads and installs a collection of 
> plugins for editing Antlr code. Most of our users won't need 
> all those plugins, but only the main antlr library for 
> running the haskell parser code. Is there a way to download 
> only a plugin with the library code, without the Antlr editor 
> and other plugins?  I see that the project release page 
> includes a library only package, but it seems outdated. Is 
> there any other antlr eclipse plugin (one that is not easily 
> found with a simple web search)?
> 
> Am I looking at the wrong place? If so, could anyone point me 
> to the right direction?
> 
> I am willing to provide such a package (maybe for download at 
> the antlr download page, or helping the antlreclipse folks) 
> if there is interest.
> 
> Cheers,
> 
> Thiago Arrais
> 


From atripp at comcast.net  Tue Jan 10 19:25:38 2006
From: atripp at comcast.net (Andy Tripp)
Date: Tue Jan 10 19:25:43 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C47AB2.4030705@comcast.net>

>
>
>On Jan 10, 2006, at 2:29 PM, Andy Tripp wrote:
>> Ter,
>> If I understand you right, you've inadvertently proved my point  
>> exactly.
>
>Uh oh! ;)
>
>> Your code above (if I read it right) only checks that the function  
>> contains at least one "return".
>> But it may find a return inside some "if", for example, whereas  
>> javac does static flow analysis
>> and will see that there exists a path through the function that  
>> does not end with a "return".
>> I mention this in my article.
>
>Ah.  Sorry.  If you want flow analysis then yes you must right it.   
>Then my boolean is a function call checking flow results.  Either I'd  
>walk the tree building flow graphs or I'd build another structure and  
>walk it.  What does this have to do with grammars and ST though?  
>

The point is that in this case, the tree walker isn't "guiding general 
output generation". Yes,
the "check-for-missing-return logic kicks in at each 
Function-declaration-type node in the tree,
but there's a lot of code there, and I don't really see the benefit of 
it being inside of a treewalker.
With the treewalker, you are grouping together the 100 rules that all 
happen to kick in
at a Function-declaration-type node in the tree, at that's not the best 
way to group them.

>You  
>must compute it, period, right?  Use a tree, use a flow graph, use  
>flat text, up to you.  Once you have a result to spit out (i.e,. "add  
>a return statement or not"), you can use ST to say that.  
>
As I say in the article, it's almost never that simple. In the case of a 
missing return, I also go
look at all the calls to the function and if the return value is ever 
used, I give a warning, because I
really don't know what value to return. Also, if the function is the 
special "main" function, I need to
do a System.exit() rather than a return.


>ST has  
>nothing to do with that.  The tree walker merely guides general  
>output generation...it would reference a previous pass over the input  
>that computed the flow analysis.
>
Why not just compute the flow analysis as needed?

My general objection to the tree walker is that I don't see it as 
"guiding general output generation", but
rather as "embedding calls to the code that does all the work at 
arbitrary places in a parser grammar
amidst ANTLR syntax."

I'd rather have code that says "Here are my 200 rules, in the order they 
should fire". That seems like
the better way to "guide output generation".

>
>Ter
>

From atripp at comcast.net  Tue Jan 10 19:39:57 2006
From: atripp at comcast.net (Andy Tripp)
Date: Tue Jan 10 19:40:00 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C47E0D.5010208@comcast.net>

>
>
>On Jan 10, 2006, at 2:40 PM, Andy Tripp wrote:
>>> I was struck by the example of 5 lines of C code being folded into  
>>> one
>>> line of Java code. Why couldn't you have a tree parser do this? It  
>>> would
>>> be inefficient, but I don't know if that is the point of the article.
>>>
>>
>> You can't have a tree parser look for those 5 lines because
>> there might be hundreds of different combinations of 5 lines that  
>> would all fold into
>> that one line of Java code.
>
>Did you build a general prolog like pattern translator?  If so, what  
>strategy of rule application do you use?  You're aware I'm sure that  
>depending on the strategy, the same set of patterns may not terminate?
>
My pattern matcher is specialized to understand C syntax. The only 
special ability it has is
that you have "v" placeholders that will match a variable or constant, 
and "x" placeholders that will
match anything. So "v1 = strcpy(x)" will match what you'd expect it to 
match, where the matcher
will look for the appropriate right paren.

>
>> In order to write a "look for a chunk of code that is really just  
>> doing a strcpy()" function,
>> you're going to have to do some real work.
>
>That is very true.  Whether you specify a pattern in your style or in  
>a set of tree grammar patterns is irrelevant, though, right?
>
Only relevent in the sense that one or the other is going to be easier 
to write and read and have
enough flexibility. I find it far easier to read "if (v1=0; v1<v2; 
v1++)" than the equivalent
AST tree structure in ANTLR syntax, especially when you consider that 
we're doing more
than matching AST structure here: when I repeat "v1" there, all the 
"v1"s must match the same
variable. As always, I'm sure that can be done with ANTLR, but I bet it 
muddles things up a bit.

>
>> How many ways are there to write your own "strcpy()", each using a  
>> few lines?
>> You could use a "for" or "while" loop. You can reference the array  
>> using pointer syntax or array syntax,
>> you can use a pointer to loop through or an index. You can  
>> increment the pointer/index with
>> i++, ++i, or i=i+1. You could just use strcpy() or strncpy(). You  
>> could wrap strcpy() with your
>> own macro or function. You could allocate new memory for
>> the destination string or assume it's already allocated. You could  
>> loop until you hit '\0' or use
>> strlen().
>
>So how do you do that with your patterns?
>
I can't...I have to write the code. But now that I've written that code 
which checks for all these
patterns, at what point in the grammar to I invoke it? There is no one 
place that it fits. The
treewalker approach is just getting in the way here if I were to use it.

>
>> In order to avoid a combinatorial explosion of various patterns to  
>> look for, you'll need to write
>> some code that tries to look chunks of code that seem to be doing  
>> strcpy(), and yet is
>> flexible enough to handles these kinds variations.
>
>We've only heard problems so far without a solution in your  
>style...could you bring some light to how you avoid looking for  
>various patterns of code to find strcpy chunks?
>
Sorry, I didn't mean to imply that I had an special solution, just a 
bunch of Java code. I was just
answering the other poster's question about "why not just check for 
those 5 lines".

>
>Ter
>


From sohail at taggedtype.net  Tue Jan 10 19:47:59 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Tue Jan 10 19:48:05 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C43530.1070909@jazillian.com>
References: <43C43530.1070909@jazillian.com>
Message-ID: <1136951279.8408.0.camel@localhost.localdomain>

this is the fourth thread you've started on replies, fix your mail
client!

From sohail at taggedtype.net  Tue Jan 10 19:58:17 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Tue Jan 10 19:58:21 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C47AB2.4030705@comcast.net>
References: <43C47AB2.4030705@comcast.net>
Message-ID: <1136951897.8408.8.camel@localhost.localdomain>

On Tue, 2006-01-10 at 22:25 -0500, Andy Tripp wrote:
> As I say in the article, it's almost never that simple. In the case of a 
> missing return, I also go
> look at all the calls to the function and if the return value is ever 
> used, I give a warning, because I
> really don't know what value to return. Also, if the function is the 
> special "main" function, I need to
> do a System.exit() rather than a return.

How the heck would you write a pattern based rule for static *flow
analysis* to check if there is a path that does not end in return?

I'll be so bold as to say that you can't unless you hand-coded it.

> >ST has  
> >nothing to do with that.  The tree walker merely guides general  
> >output generation...it would reference a previous pass over the input  
> >that computed the flow analysis.
> >
> Why not just compute the flow analysis as needed?
> 
> My general objection to the tree walker is that I don't see it as 
> "guiding general output generation", but
> rather as "embedding calls to the code that does all the work at 
> arbitrary places in a parser grammar
> amidst ANTLR syntax."

Hardly arbitrary. Is your software open source? I'd like to take a look
at how you managed to do all these wonderful things without writing
code.

> I'd rather have code that says "Here are my 200 rules, in the order they 
> should fire". That seems like
> the better way to "guide output generation".

So rather than use existing languages than tools, invent your own?

From atripp at comcast.net  Tue Jan 10 20:12:20 2006
From: atripp at comcast.net (Andy Tripp)
Date: Tue Jan 10 20:12:34 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C485A4.8020108@comcast.net>

>
>
>On Jan 10, 2006, at 2:50 PM, Andy Tripp wrote:
>> The interesting thing about your example is that the "natural" Java  
>> translation (what a person would write) is
>> if (x == 5)
>> whereas any traditional AST-walking translator would probably produce
>> if ((x = 5) != 0)
>>
>> While the second one is technically correct, and is probably what  
>> my product would produce today,
>> my product is designed so that I can easily add a rule to check for  
>> a "if (v=n)" bug, and go ahead and
>> fix the bug during translation. And I can and do add those sorts of  
>> rules! Do not try this at home
>> with your treewalking translator, kids :)
>
>ooops...too late ;)
>
>ifstat
>	: ^(IF ^(ASSIGN ID expr) stat ) -> ifassign(...)
>	| ^(IF expr stat) -> ifstat(...)
>	;
>
>where the ->foo(...) builds a template called foo and I've omitted  
>the args for clarity.  This is ANTLR v3.  Not hard...this is  
>precisely what grammars are useful for.
>
Here is my code that what we want. Just one line:
if (v1=v2) --> if (v1 == v2)
I find that much more readable than the four lines you have, but beyond 
that, consider:
* my pattern-matching language is trivial (v's match variables, x's 
match anything, that's it) compared to ANTLR
* you still have to write ifassign() and ifstat()
* you're going to have the logic for 10-20 other if-related rules mixed 
in here

>
>Pattern engines have trouble with semantic-based context.  For  
>example, I can add a sem pred that tells me that an int ref is in a  
>while or for of if...can your pattern matcher say "apply a rule only  
>in this semantic or syntactic context"?  ;)
>
I have things to that Java code can be written around the pattern 
matching, so yes, it can be done.
But yes, this was my biggest fear when deciding to drop the treewalker 
approach and go with the
"loose" pattern-matching approach. I figured I'd rather deal with this 
problem occasionally rather
than deal with ASTs always. I've been happily surprised at how few times 
this has bitten me.
I know the DMS tool from Semantic Designs has a nice thing where they do 
a similar pattern matching,
but you can optionally specify a semantic or syntactic context. I guess 
my biggest problem here has
been trying to figure out if a "*" is multiplication or pointer - not 
easy to do without having already
built a whole AST ahead of time :(

>
>The thing is Andy that you are specifying text based rules and I am  
>specifying tree based rules.  Further, I can only assume that you  
>have a rule application engine that does this magic whereas I am  
>using a weaker but more deterministic linear tree walker.
>
I have a few hundred of these "pattern-matching" rules, but also about  
150 rules written in Java.
I think it's more about how to best design that outer layer that calls 
all these rules. I have just
one method that calls all rules (the Java-code ones and the 
pattern-match text ones) in a particular
order. That function is nothing but a flat list of rules to fire, in 
order. I find that much easier than if
the rules where invoked by a treewalker inside a grammar. Especially 
because rule firing order is
so important and so hard to get right.

>Note that most academics will agree with you about translation, lest  
>you think you're the only one that thinks this way. See TXL,  
>Stratego, ...  
>
Hmm. I had looked at those and others long ago. IIRC, they were all 
tree-based transformations.

>Also recall from a previous post of mine that your  
>pattern matching engine may run into invalid paths or may even not  
>terminate depending on your application strategy.  This is a very  
>well known problem with this academic approach.
>
My pattern matching is very trivial. I haven't had any problems.

>
>I will also point out that the number of people using declarative  
>systems such as the academic ones are not used much by people  
>building translators in the wild.  That said, the authors of those  
>tools seem to be able to get them to do amazing things!
>
Yes, and this is why I get frustrated reading about them. Every example 
I could find for
TXL, Stratego,  DMS, and even ANTLR seems to use such simple examples to 
show how flexible they are.
I look at the examples and say "but you're ignoring all the difficult 
real-world issues!" That's why
I wrote this article. I'm hoping you (or someone else) can take a simple 
but non-trivial example like
"how to convert 'hello world' from C to Java" or "how to convert printf 
to System.out.println", and show
me how treewalkers and ST make that easier. Because I think once you 
address the few "gotchas"
that I bring up in my article, maybe you'll see that "oh, in this case, 
treewalkers don't help, we're just
going to have to write a bunch of code".

And then the next step is to convince you that converting main() and 
printf() are not the difficult cases,
those are the easier ones! Whereas a PrettyPrinter fits into the 
treewalker mold like a glove, a
C to Java translator doesn't fit at all.

>
>Ter
>


From atripp at comcast.net  Tue Jan 10 20:26:21 2006
From: atripp at comcast.net (Andy Tripp)
Date: Tue Jan 10 20:26:36 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C488ED.4040100@comcast.net>

>
>
>On Tue, 2006-01-10 at 22:25 -0500, Andy Tripp wrote:
>> As I say in the article, it's almost never that simple. In the case of a 
>> missing return, I also go
>> look at all the calls to the function and if the return value is ever 
>> used, I give a warning, because I
>> really don't know what value to return. Also, if the function is the 
>> special "main" function, I need to
>> do a System.exit() rather than a return.
>
>How the heck would you write a pattern based rule for static *flow
>analysis* to check if there is a path that does not end in return?
>
>I'll be so bold as to say that you can't unless you hand-coded it.
>
Yes, I do. Sorry, didn't mean to imply otherwise. I'm not saying that 
pattern-based-rules can
do a lot. I'm just saying that very few of the translation rules are 
simple, so the "embed simple
transforms in a grammar" approach doesn't apply.

>
>> >ST has  
>> >nothing to do with that.  The tree walker merely guides general  
>> >output generation...it would reference a previous pass over the input  
>> >that computed the flow analysis.
>> >
>> Why not just compute the flow analysis as needed?
>> 
>> My general objection to the tree walker is that I don't see it as 
>> "guiding general output generation", but
>> rather as "embedding calls to the code that does all the work at 
>> arbitrary places in a parser grammar
>> amidst ANTLR syntax."
>
>Hardly arbitrary. Is your software open source? I'd like to take a look
>at how you managed to do all these wonderful things without writing
>code.
>
By "arbitrary" here, I mean that if I ask "where is the 
missing-return-check rule invoked?", it's
not at all obvious (to others...obviously it is obvious to the person 
who wrote it). Same for all the
other rules. In my approach, my rules are just fired sequentially, 
there's just a single, flat list
of them.

Again, I am writing code, and my simple pattern matching does not do 
anything magical.
My point here was that if I've got 150 rules, I'd like to see them 
listed, in order, like this:
Rule[] rules = {
symbolTableBuilderRule,
preprocessorHandlingRule,
gotoRemoverRule,
keywordRemoverRule,
...
}

I think that's a lot easier than:

                       // Here we are at the METHOD_CALL node in the 
ANTLR C Grammar,
                      // so here are 40 rules that should be invoked at 
that point in the AST:
                      ...

>
>> I'd rather have code that says "Here are my 200 rules, in the order they 
>> should fire". That seems like
>> the better way to "guide output generation".
>
>So rather than use existing languages than tools, invent your own?
>
No, I'm just using Java code (as shown with the "rule list" above).

As for invoking a pattern-matching-rule, text files can contain rules, 
one per line, like this:
"v = v + 1; --> v++;"
And a rule is created with ordinary Java code:
new SnippetRule("myfile.txt");

My code is not open source, but I have just finished a design document 
which I may publish.
Andy


From atripp at comcast.net  Tue Jan 10 21:00:45 2006
From: atripp at comcast.net (Andy Tripp)
Date: Tue Jan 10 21:00:50 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
Message-ID: <43C490FD.1040108@comcast.net>

I must be driving you guys nuts by not posting any code, so here is some.

On the issue of that we stumbled on of checking for "if (x=5)", here's 
what I
do. I have a ForceToBooleanRule that checks for all the places that
Java requires a boolean expression. At each of those, I use ANTLR to
parse the expression into an AST, and then traverse that tree, changing 
things
from int to boolean type. That's a bit vague, I know. And the 
lexer/parser/expressionChanger
 code isn't even shown here, it's within the 
ExpressionUtils.forceToBoolean() call.
What is shown here is just the "ForceToBooleanRule" code: A rule that's 
written
in plain Java code, that looks for various patterns in a Token stream 
(NOT an AST).

As always, I do think I have a point here. That is the issue of "where 
would a Rule like this be
invoked in the treewalker approach?" Do you really want to go through 
the bother
of finding the right place for this inside the ANTLR C grammar?
Is there even really a valid set of "right places" that represent the 
four bullet items
in the code below (beneath "for", "while", "do-while", and "if")?
 I don't want to bother with all that. I'd rather do what this code does...
just assume that we're looking through a sequence of Tokens, and do just 
two checks:
 Are we at a "for" (and if so, the expression is between the next ";" 
and the following ";")?
 Are we at a "while" or "if" (if so the expression is everything between 
the next "(" and its matching ")".

No AST tree structure knowledge required! Just write the rule code using
the more intuitive "sequence of tokens" mental image.

(Some background: the match() method is called on every Token in every C 
file. If
it returns true, then the apply() method is called to make the change. 
The Source class
has lots of methods for working with a sequence of Tokens.)
--------------------------------------------------------------------------------------
// certain places in Java require a boolean type, where C allows "int" type:
// * for condition:  for (int i=0; b; i++)
// * while:  while (b)
// * do-while: do { } while (b);
// * if: if (b)

public class ForceToBooleanRule extends Rule {
    private String newexpr;
    private Token startToken = null;
    private Token endToken = null;

    // if we see one of the patterns listed above, set startToken and 
endToken and return true.
    public boolean match(Source source) {
        String current = source.currentToken.getText();
        if (current.equals("for")) {
            startToken = source.findToken(";");
            endToken = source.findToken(source.getTokenAt(startToken, 
+1), ";");
        }
        else if (current.equals("while") ||
                 current.equals("if")) {
            startToken = source.getTokenAt(+1); // '('
            endToken = source.findMatchingParen(startToken);
        }
        else {
            return false;
        }
        String expr = source.getTextBetween(startToken, endToken);

        // here is where the expression is parsed and changed to be 
boolean type:
        newexpr = ExpressionUtils.forceToBoolean(expr, source);
        return !expr.equals(newexpr);
    }

    // change the expression:
    public void apply(Source source) {
        source.replaceTokenRange(startToken, endToken, 
startToken.getText()+newexpr+endToken.getText());
    }
}

From sohail at taggedtype.net  Tue Jan 10 22:45:03 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Tue Jan 10 22:45:11 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C490FD.1040108@comcast.net>
References: <43C490FD.1040108@comcast.net>
Message-ID: <1136961903.9239.11.camel@localhost.localdomain>

> --------------------------------------------------------------------------------------
> // certain places in Java require a boolean type, where C allows "int" type:
> // * for condition:  for (int i=0; b; i++)
> // * while:  while (b)
> // * do-while: do { } while (b);
> // * if: if (b)
> 
> public class ForceToBooleanRule extends Rule {
>     private String newexpr;
>     private Token startToken = null;
>     private Token endToken = null;
> 
>     // if we see one of the patterns listed above, set startToken and 
> endToken and return true.
>     public boolean match(Source source) {
>         String current = source.currentToken.getText();
>         if (current.equals("for")) {

Is there some reason you just didn't do 
if (source.currentToken.getType()==Parser.FOR)...? :)

>         // here is where the expression is parsed and changed to be 
> boolean type:
>         newexpr = ExpressionUtils.forceToBoolean(expr, source);
>         return !expr.equals(newexpr);
>     }

forceToBoolean must be... err... interesting :)

From thiago.arrais at gmail.com  Wed Jan 11 03:38:11 2006
From: thiago.arrais at gmail.com (Thiago Arrais)
Date: Wed Jan 11 03:38:13 2006
Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
In-Reply-To: <200601110022.k0B0MNIJ006570@s2.eroute.net>
References: <e163e2f50601101401n2fc7aad9r@mail.gmail.com>
	<200601110022.k0B0MNIJ006570@s2.eroute.net>
Message-ID: <e163e2f50601110338m74fcd893k@mail.gmail.com>

2006/1/10, Scott Stanchfield <scott@javadude.com>:
> You can just grab the org.antlr plugin from that distribution and you'll be
> fine.

The problem is it is a little outdated. Their last release was on
2005-06-26, while the last ANTLR release was on 2005-12-22.

Maybe I need to go talk directly to them. But it'd be good to know if
there is a wish to release a official org.antlr Eclipse plugin (or if
that one can somehow be considered official), or if we ca package our
own "unofficial" org.antlr plugin. For the time being, it is called
net.sf.eclipsefp.antlr, to avoid name collisions. I think an official
Eclipse plugin (available for download through the antlr site, maybe)
would help more than confuse.

Cheers,

Thiago Arrais
From harsha.nagesh at csfb.com  Wed Jan 11 05:09:17 2006
From: harsha.nagesh at csfb.com (Nagesh, Harsha)
Date: Wed Jan 11 05:09:32 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalke rs
Message-ID: <FDFBED0CBC3CA04BB7F633CC85ADDA5B15AAD68A@enyc12p32001.corpny.csfb.com>


Andy,

	From what you describe and from a bit of Stratego that I know, I think
you maybe doing something that Stratego supports very well (atleast the part
of listing-rules-and-firing-them-without-embedding-them-inside-grammar)
Stratego has constructs to specify pattern matching rules and also has
a library of calls which direct how a rule can be applied. For example,
you can specify that a rule can be applied top-down on the tree and where
ever there is a match for the pattern of the rule, the transformation is
applied and there are many other in built "strategies" (as stratego calls
it) for transformation. However, my experience with stratego has been that
it has a steep learning curve, poorly documented and does not work for
larger real world examples (or atleast the knowledge of making it work
for such problems is buried deep in the minds of the developers of 
stratego - who are grad students with paper deadlines ! ) :(

I also want to add a few words about my experience with ANTLR - it was easy to
pick up, as I could write some java/c# code when a pattern matched and
found syntax directed translation much easier to get a complex example
working than a AST based transformation. I find that tree based Xformations
in antlr is not at all well documented and has syntax that is buried
somewhere in the manual, which has only few toy examples. I think that the
there is also no single place on antlr's website where I can systamatically
learn the differences of both the approaches, how does antlr contrast to
other systems (not by theory, but by examples) or even for that matter,
what is new in antlr v3 about which there is so much traffic on this list.
Forgive me for venting my frustration, maybe its just me and my slow
thinking, but I think if there is more well structured documentation, 
organized well on antlr.org it would be so much easier for a newbie...and
to add to this confusion more sites are being created for string template,
and there was one for programtransformation.org (?) etc...For a new person
it takes a good bit of effort to understand what is what and how do all these
tools come together. (In stratego, there have more than 50 different
executables which can be piped in a chain to get something meaningful - imagine
the nightmare for even a competant person to understand the tool linkage...
a lot of effort is spent into learning of how to impleemnt something in the
system, than the things that you want your program to do..

just my 2c

Harsha




This material has been prepared by individual sales and/or trading personnel and does not constitute investment research.  Please follow the attached hyperlink to an important disclaimer: http://www.csfb.com/legal_terms/disclaimer_americas_salestrading.shtml




-----Original Message-----
From: antlr-interest-bounces@antlr.org
[mailto:antlr-interest-bounces@antlr.org]On Behalf Of Andy Tripp
Sent: Wednesday, January 11, 2006 12:01 AM
To: antlr-interest@antlr.org
Subject: [antlr-interest] New article on StringTemplates and Treewalkers


I must be driving you guys nuts by not posting any code, so here is some.

On the issue of that we stumbled on of checking for "if (x=5)", here's 
what I
do. I have a ForceToBooleanRule that checks for all the places that
Java requires a boolean expression. At each of those, I use ANTLR to
parse the expression into an AST, and then traverse that tree, changing 
things
from int to boolean type. That's a bit vague, I know. And the 
lexer/parser/expressionChanger
 code isn't even shown here, it's within the 
ExpressionUtils.forceToBoolean() call.
What is shown here is just the "ForceToBooleanRule" code: A rule that's 
written
in plain Java code, that looks for various patterns in a Token stream 
(NOT an AST).

As always, I do think I have a point here. That is the issue of "where 
would a Rule like this be
invoked in the treewalker approach?" Do you really want to go through 
the bother
of finding the right place for this inside the ANTLR C grammar?
Is there even really a valid set of "right places" that represent the 
four bullet items
in the code below (beneath "for", "while", "do-while", and "if")?
 I don't want to bother with all that. I'd rather do what this code does...
just assume that we're looking through a sequence of Tokens, and do just 
two checks:
 Are we at a "for" (and if so, the expression is between the next ";" 
and the following ";")?
 Are we at a "while" or "if" (if so the expression is everything between 
the next "(" and its matching ")".

No AST tree structure knowledge required! Just write the rule code using
the more intuitive "sequence of tokens" mental image.

(Some background: the match() method is called on every Token in every C 
file. If
it returns true, then the apply() method is called to make the change. 
The Source class
has lots of methods for working with a sequence of Tokens.)
--------------------------------------------------------------------------------------
// certain places in Java require a boolean type, where C allows "int" type:
// * for condition:  for (int i=0; b; i++)
// * while:  while (b)
// * do-while: do { } while (b);
// * if: if (b)

public class ForceToBooleanRule extends Rule {
    private String newexpr;
    private Token startToken = null;
    private Token endToken = null;

    // if we see one of the patterns listed above, set startToken and 
endToken and return true.
    public boolean match(Source source) {
        String current = source.currentToken.getText();
        if (current.equals("for")) {
            startToken = source.findToken(";");
            endToken = source.findToken(source.getTokenAt(startToken, 
+1), ";");
        }
        else if (current.equals("while") ||
                 current.equals("if")) {
            startToken = source.getTokenAt(+1); // '('
            endToken = source.findMatchingParen(startToken);
        }
        else {
            return false;
        }
        String expr = source.getTextBetween(startToken, endToken);

        // here is where the expression is parsed and changed to be 
boolean type:
        newexpr = ExpressionUtils.forceToBoolean(expr, source);
        return !expr.equals(newexpr);
    }

    // change the expression:
    public void apply(Source source) {
        source.replaceTokenRange(startToken, endToken, 
startToken.getText()+newexpr+endToken.getText());
    }
}


==============================================================================
Please access the attached hyperlink for an important electronic communications disclaimer: 

http://www.csfb.com/legal_terms/disclaimer_external_email.shtml

==============================================================================

From scott at javadude.com  Wed Jan 11 05:27:59 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Wed Jan 11 05:28:12 2006
Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
In-Reply-To: <e163e2f50601110338m74fcd893k@mail.gmail.com>
Message-ID: <200601111312.k0BDCOou014327@s2.eroute.net>

I released that one ;)

I haven't had a chance to update it to the official 2.7.6 yet, but it's
pretty close. I'm going to try to update it soon, but I need to have time to
test it against the development parts of the plugin.

If you want to make a version using the official 2.7.6 antlr, all you need
to do is create an

  org.antlr.2.7.6

directory, and copy in the most recent antlr.jar from http://antlr.org, and
create a plugin.xml in it with the following content:

<?xml version="1.0" encoding="UTF-8"?>
<?eclipse version="3.0"?>
<plugin
   id="org.antlr"
   name="Antlr Plug-in"
   version="2.7.6"
   provider-name="http://antlr.org">

   <runtime>
      <library name="antlr.jar">
         <export name="*"/>
      </library>
   </runtime>
   <requires>
   </requires>

</plugin>

Drop that directory in c:/eclipse/plugins (or wherever you have eclipse
installed)


NOTE: I wouldn't recommend people who want to use the antlr-eclipse
development plugin do this yet; I haven't tested the official 2.7.6 against
the development plugin yet.


-- Scott 

> -----Original Message-----
> From: antlr-interest-bounces@antlr.org 
> [mailto:antlr-interest-bounces@antlr.org] On Behalf Of Thiago Arrais
> Sent: Wednesday, January 11, 2006 6:38 AM
> To: antlr-interest@antlr.org
> Subject: Re: [antlr-interest] ANTLR Library as Eclipse Plugin
> 
> 2006/1/10, Scott Stanchfield <scott@javadude.com>:
> > You can just grab the org.antlr plugin from that distribution and 
> > you'll be fine.
> 
> The problem is it is a little outdated. Their last release 
> was on 2005-06-26, while the last ANTLR release was on 2005-12-22.
> 
> Maybe I need to go talk directly to them. But it'd be good to 
> know if there is a wish to release a official org.antlr 
> Eclipse plugin (or if that one can somehow be considered 
> official), or if we ca package our own "unofficial" org.antlr 
> plugin. For the time being, it is called 
> net.sf.eclipsefp.antlr, to avoid name collisions. I think an 
> official Eclipse plugin (available for download through the 
> antlr site, maybe) would help more than confuse.
> 
> Cheers,
> 
> Thiago Arrais
> 


From gabriel.adrian.radu at googlemail.com  Wed Jan 11 06:17:26 2006
From: gabriel.adrian.radu at googlemail.com (Gabriel Radu)
Date: Wed Jan 11 06:17:29 2006
Subject: [antlr-interest] Lexical nondeterminism
Message-ID: <67e2ed240601110617l76a741cg@mail.gmail.com>

Hi all,


I am trying to write a antler grammar and I am getting a following result:

ANTLR Parser Generator   Version 2.7.5 (20050128)   1989-2005 jGuru.com
ServiceCompiler.g: warning:lexical nondeterminism between rules
INT_or_FLOAT_or_MACADR_or_VERSIONSTRING and DEFAULT upon
AuvitranServiceCompiler.g:     k==1:'D','d'
AuvitranServiceCompiler.g:     k==2:'E','e'
AuvitranServiceCompiler.g:     k==3:'F','f'
AuvitranServiceCompiler.g:     k==4:'A','a'
AuvitranServiceCompiler.g:     k==5:'U','u'
AuvitranServiceCompiler.g:     k==6:'L','l'
AuvitranServiceCompiler.g:     k==7:'T','t'
AuvitranServiceCompiler.g:     k==8:<end-of-token>
AuvitranServiceCompiler.g:     k==9:<end-of-token>
AuvitranServiceCompiler.g:     k==10:<end-of-token>


The interesting parts of the lexer are:

//----------------------------------------------------------------------
// Lexer
//----------------------------------------------------------------------

class ServiceLexer extends Lexer;
options {
  k = 10;
}


//----------------------------------------------------------------------
// White speace:

WS_
  : (' ' | '\t')
  { $setType(ANTLR_USE_NAMESPACE(antlr)Token::SKIP); }
;

NEWLINE
    : '\n'
    |	'\r'
    | "\r\n"
    | "\n\r"
;


//----------------------------------------------------------------------
// Chars:

NONTOCLIT
    :   'g'..'u' | 'x'..'z'
    |   'G'..'U' | 'X'..'Z'
;



//----------------------------------------------------------------------
// Numbers:

protected DIGIT
	:	'0'..'9'
;

protected HEXLIT
  : 'a'..'f' | 'A'..'F'
;

protected HEXDIG
  : (DIGIT | HEXLIT)
;

protected INT
  :	(HEXDIG)+
;

protected FLOAT
  : (DIGIT)+ DOT (DIGIT)+
;

protected MACADRSEPARATOR
  : DOT
;

protected MACADR
  :
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG
;



protected VERSIONSTRING_L
  : ( DIGIT )+ DOT ( DIGIT )+ DOT ( DIGIT )+ ('A'..'Z'|'a'..'z')?
;

protected VERSIONSTRING_S
  : ( DIGIT )+ DOT ( DIGIT )+ ('A'..'Z'|'a'..'z')
;

protected VERSIONSTRING : ;

INT_or_FLOAT_or_MACADR_or_VERSIONSTRING

   : ( DIGIT (DIGIT)? DOT DIGIT ( DIGIT (DIGIT)? )? DOT )
          => VERSIONSTRING_L { $setType( VERSIONSTRING ); }

   | ( DIGIT (DIGIT)? DOT DIGIT ( DIGIT (DIGIT)? )? ('A'..'Z'|'a'..'z') )
          => VERSIONSTRING_S { $setType( VERSIONSTRING ); }

   | ( ( DIGIT )+ DOT ) => FLOAT { $setType( FLOAT ); }

   | ( HEXDIG HEXDIG MACADRSEPARATOR ) => MACADR { $setType( MACADR ); }

   | ( ( DIGIT )+ ) => INT { $setType( INT ); }

;



//----------------------------------------------------------------------
// Punctuation:

DOT:    '.' ;

COMMA:	',' ;

COLON:	':' ;

SCOLON:	';' ;



//[ some more text]



//----------------------------------------------------------------------
DEFAULT:
    ('D' | 'd')
    ('E' | 'e')
    ('F' | 'f')
    ('A' | 'a')
    ('U' | 'u')
    ('L' | 'l')
    ('T' | 't')
;


The gramar compiles fine if I take out the

DEFAULT:
    ('D' | 'd')
    ('E' | 'e')
    ('F' | 'f')
    ('A' | 'a')
    ('U' | 'u')
    ('L' | 'l')
    ('T' | 't')
;

rule, or the

   | ( DIGIT (DIGIT)? DOT DIGIT ( DIGIT (DIGIT)? )? ('A'..'Z'|'a'..'z') )
          => VERSIONSTRING_S { $setType( VERSIONSTRING ); }

production from the INT_or_FLOAT_or_MACADR_or_VERSIONSTRING rule.


Does anyone know why I am getting the nondeterminism warning, and how
to solve the problem?


Kind regards,
Gabriel
From antlr at jazillian.com  Wed Jan 11 07:49:13 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Wed Jan 11 07:49:16 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalke rs
Message-ID: <43C528F9.709@jazillian.com>


>>/ --------------------------------------------------------------------------------------
>/>/ // certain places in Java require a boolean type, where C allows "int" type:
>/>/ // * for condition:  for (int i=0; b; i++)
>/>/ // * while:  while (b)
>/>/ // * do-while: do { } while (b);
>/>/ // * if: if (b)
>/>/ 
>/>/ public class ForceToBooleanRule extends Rule {
>/>/     private String newexpr;
>/>/     private Token startToken = null;
>/>/     private Token endToken = null;
>/>/ 
>/>/     // if we see one of the patterns listed above, set startToken and 
>/>/ endToken and return true.
>/>/     public boolean match(Source source) {
>/>/         String current = source.currentToken.getText();
>/>/         if (current.equals("for")) {
>/
>Is there some reason you just didn't do 
>if (source.currentToken.getType()==Parser.FOR)...? :)
>  
>
Only a very small reason: I find it easier to remember that this token
has text "for" than to remember that the lexer type is Parser.FOR.
Not a big deal, and half the time I do use "Parser.FOR". But not as 
trivial as
you might think considering that "<" is Parser.LTE in the C grammar and it's
"LE" in the Java grammar, and it's not clear whether this rule working on C
code, Java code, or (most likely) a mix of the two :)

>>/         // here is where the expression is parsed and changed to be 
>/>/ boolean type:
>/>/         newexpr = ExpressionUtils.forceToBoolean(expr, source);
>/>/         return !expr.equals(newexpr);
>/>/     }
>/
>forceToBoolean must be... err... interesting :)
>
It's actually quite straightforward: parse the expression into an AST, 
and recursively process it.
When we hit a "0" node, replace it with a "false", any other "int" node, 
replace it with "true".
Most boolean operators are replaced with "!=", and we do some special 
stuff for type casts.
When we find variables and function calls, we've got to look up the type 
in a symbol table.

Andy


From prashant.deva at gmail.com  Wed Jan 11 06:20:49 2006
From: prashant.deva at gmail.com (Prashant Deva)
Date: Wed Jan 11 08:10:44 2006
Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
In-Reply-To: <e163e2f50601110338m74fcd893k@mail.gmail.com>
References: <e163e2f50601101401n2fc7aad9r@mail.gmail.com>
	<200601110022.k0B0MNIJ006570@s2.eroute.net>
	<e163e2f50601110338m74fcd893k@mail.gmail.com>
Message-ID: <41fed8f80601110620g223ee1dbh2d36bb17ec8934e@mail.gmail.com>

Look if all you need is the antlr jar in your classpath, then why dont you
download it directly from antlr.org.

I dont get it, you are asking for an antlr plugin for eclipse, then you say
all you want is the antlr jar and nothing else.
Well, then simply go to antlr.org and download the latest antlr distribution
which contains the antlr jar.

--
Prashant Deva
Creator, ANTLR Studio
Founder, Placid Systems, www.placidsystems.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060111/c0ed8485/attachment-0001.html
From dev at arabink.com  Wed Jan 11 08:35:22 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Wed Jan 11 08:35:28 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalke rs
In-Reply-To: <43C528F9.709@jazillian.com>
References: <43C528F9.709@jazillian.com>
Message-ID: <43C533CA.5030400@arabink.com>

Andy Tripp wrote:
> 
(Resposting; sorry about the dup, Andy; used the wrong address first 
time 'round)
 >
...etc...

Hi all,

I'm relatively new to AntlrWorld, having (re)discovered it only a few 
weeks ago, and then discovered StringTemplate, which has since consumed 
most of my waking hours.

I can't really follow the hairy details of this thread, but I think I 
see an abstract pattern.  Please tell me if the following makes sense:

The core issue is design strategy for language transformation.  If we 
can think of a continuum of design options, then (possibly) we can put 
the Antlr strategy on one end, and the (Jazillion?) on the other.

(I'm being very schematic here; perhaps the actual workings of antlr and 
jazillion don't fit the schema.  Please advise.)

We can call the Antlr approach "source-driven transformation"; the 
Jazillion approach "target-driven" transformation.

By "source-driven", I mean that the process looks sth like:

     a.  write grammar to parse source language
     b.  generate source AST
     c.  write (tree) transformation grammar that attaches actions to 
(AST) productions, producing either:

         c1.  a target AST that can then be run through other 
transformers, in particular a pretty-printer; or
         c2.  a text in the target language

So in practice a source-driven strategy means writing code to feed into 
a parser generator.  The driver will invoke the parser on a source text. 
  Grammatical structure of the source text controls processing.

By "target-driven" I mean a process that looks something like:

     For each element in the target language,

         a.  write transformation logic mapping source elements to 
target element
         b.  write (or generate) a "rule", which is a little parser to 
examine the source text for elements needed to generate said target 
element; attach transformations from (a) to production in the grammar

In practice a target-driven strategy means writing a set of rules 
(functions) to be called in turn at each token in the source text.  I.e. 
Start with a target element and see if the corresponding source 
production(s) match(es); or, try to find the appropriate target element 
by testing various source productions.  Source language structure 
controls processing within the driver itself.

The source-driven approach embeds target generation code in a source 
grammar; the target-driven approach embeds source-grammar in target 
generation code.

I hope that is somewhere in the ballpark; it's nice and clean so it 
would be a shame if it was also stupid.  ;)   I think I understand how 
antlr works pretty well, but I'm not sure about the Jazillion approach.

If this schema is accurate/useful, then I would suggest building on the 
paper "Why I don't Use..." to produce a more general consideration of 
the pros and cons of the respective approaches.  Something like 
*"Language Transformation Strategies: Source-Driven v. Target-Driven in 
a Fight to the Death!"*  As it stands, the article is interesting 
(though a bit hard to follow for somebody like me, w/out lots of parsing 
experience), but it sometimes gives (me at least) the impression of 
saying "my approach is better because, well, because I like it more". 
That's not necessarily a bad thing, but I gather that in large part 
that's because you find the one approach fits better with the way you 
think about the problem, which doesn't imply that it is a "better" 
approach.  I'd like to see a more dispassionate consideration of the 
pros and cons.  The "mental model" one needs for each strategy is 
obviously very important, but there are other considerations: 
efficiency, maintainability, etc. - the usual suspects.

And of course the overalln approach could be generalized, i.e. design an 
abstract uber-language (cf. IDL).  Then you can write one 
source->uberlang transformer per source lang, and one uberlang->target 
transformer per target language.  I suppose somebody already does this 
(or has decided it's impossible or impractical).

thanks,

gregg
From dev at arabink.com  Wed Jan 11 08:46:06 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Wed Jan 11 08:46:15 2006
Subject: [antlr-interest] Source- v. Target-driven xforms (was: Re: New
 article on StringTemplates and Treewalkers)
In-Reply-To: <43C533CA.5030400@arabink.com>
References: <43C528F9.709@jazillian.com> <43C533CA.5030400@arabink.com>
Message-ID: <43C5364E.5060302@arabink.com>

Sorry, meant to rename thread first time.  A major correction below:
> 
> Hi all,
> 
> I'm relatively new to AntlrWorld, having (re)discovered it only a few 
> weeks ago, and then discovered StringTemplate, which has since consumed 
> most of my waking hours.
> 
> I can't really follow the hairy details of this thread, but I think I 
> see an abstract pattern.  Please tell me if the following makes sense:
> 
> The core issue is design strategy for language transformation.  If we 
> can think of a continuum of design options, then (possibly) we can put 
> the Antlr strategy on one end, and the (Jazillion?) on the other.
> 
> (I'm being very schematic here; perhaps the actual workings of antlr and 
> jazillion don't fit the schema.  Please advise.)
> 
> We can call the Antlr approach "source-driven transformation"; the 
> Jazillion approach "target-driven" transformation.
> 
> By "source-driven", I mean that the process looks sth like:
> 
>     a.  write grammar to parse source language
>     b.  generate source AST
>     c.  write (tree) transformation grammar that attaches actions to 
> (AST) productions, producing either:
> 
>         c1.  a target AST that can then be run through other 
> transformers, in particular a pretty-printer; or
>         c2.  a text in the target language
> 
> So in practice a source-driven strategy means writing code to feed into 
> a parser generator.  The driver will invoke the parser on a source text. 
>  Grammatical structure of the source text controls processing.
> 
> By "target-driven" I mean a process that looks something like:
> 
>     For each element in the target language,
> 
>         a.  write transformation logic mapping source elements to target 
> element
>         b.  write (or generate) a "rule", which is a little parser to 
> examine the source text for elements needed to generate said target 
> element; attach transformations from (a) to production in the grammar

Clarification:  "rule" = *set* of parsers; attach transformations from 
(a) to these parsers.
> 
> In practice a target-driven strategy means writing a set of rules 
> (functions) to be called in turn at each token in the source text.  I.e. 
> Start with a target element and see if the corresponding source 
> production(s) match(es); or, try to find the appropriate target element 
> by testing various source productions.  Source language structure 
> controls processing within the driver itself.

Major correction for last sentence above:  *Target* language structure 
controls processing...

> 
> The source-driven approach embeds target generation code in a source 
> grammar; the target-driven approach embeds source-grammar in target 
> generation code.
> 
> I hope that is somewhere in the ballpark; it's nice and clean so it 
> would be a shame if it was also stupid.  ;)   I think I understand how 
> antlr works pretty well, but I'm not sure about the Jazillion approach.
> 
> If this schema is accurate/useful, then I would suggest building on the 
> paper "Why I don't Use..." to produce a more general consideration of 
> the pros and cons of the respective approaches.  Something like 
> *"Language Transformation Strategies: Source-Driven v. Target-Driven in 
> a Fight to the Death!"*  As it stands, the article is interesting 
> (though a bit hard to follow for somebody like me, w/out lots of parsing 
> experience), but it sometimes gives (me at least) the impression of 
> saying "my approach is better because, well, because I like it more". 
> That's not necessarily a bad thing, but I gather that in large part 
> that's because you find the one approach fits better with the way you 
> think about the problem, which doesn't imply that it is a "better" 
> approach.  I'd like to see a more dispassionate consideration of the 
> pros and cons.  The "mental model" one needs for each strategy is 
> obviously very important, but there are other considerations: 
> efficiency, maintainability, etc. - the usual suspects.
> 
> And of course the overalln approach could be generalized, i.e. design an 
> abstract uber-language (cf. IDL).  Then you can write one 
> source->uberlang transformer per source lang, and one uberlang->target 
> transformer per target language.  I suppose somebody already does this 
> (or has decided it's impossible or impractical).
> 
> thanks,
> 
> gregg
> 

From thiago.arrais at gmail.com  Wed Jan 11 09:08:33 2006
From: thiago.arrais at gmail.com (Thiago Arrais)
Date: Wed Jan 11 09:08:35 2006
Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
In-Reply-To: <41fed8f80601110620g223ee1dbh2d36bb17ec8934e@mail.gmail.com>
References: <e163e2f50601101401n2fc7aad9r@mail.gmail.com>
	<200601110022.k0B0MNIJ006570@s2.eroute.net>
	<e163e2f50601110338m74fcd893k@mail.gmail.com>
	<41fed8f80601110620g223ee1dbh2d36bb17ec8934e@mail.gmail.com>
Message-ID: <e163e2f50601110908laeed5ecr@mail.gmail.com>

Prashant,

2006/1/11, Prashant Deva <prashant.deva@gmail.com>:
> I dont get it, you are asking for an antlr plugin for eclipse, then you say
> all you want is the antlr jar and nothing else.

We only need the antlr jar packaged as an Eclipse plugin, pretty much
like the way JUnit was packaged inside Eclipse. "Plugin" here is used
as a Eclipse packaging unit term, not the broader term for a set of
features distributed as a component.

Scott's previous suggestion pretty much solves the issue. I just need
to know if we could use the name org.antlr on one of our project's
packaging units and if there was already such a package.

Cheers,

Thiago Arrais
From antlr at jazillian.com  Wed Jan 11 09:19:02 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Wed Jan 11 09:19:16 2006
Subject: [antlr-interest] Re: Source-driven v. Target-driven xforms (was Re:
 New article on StringTemplates and Treewalkers)
In-Reply-To: <43C532CC.5000900@arabink.com>
References: <43C528F9.709@jazillian.com> <43C532CC.5000900@arabink.com>
Message-ID: <43C53E06.4090700@jazillian.com>

Hi Gregg,

Yes, very good description of the issue.
Generally, I think of it  as "tree driven" vs. "rule driven" rather than 
"source-driven"
and "target driven". In "tree driven", the  source language grammar 
drives the design.
In rule-driven, the  design is a sequential application of rules.

In my daily development, I spend almost 100% of my time thinking in terms of
"this chunk of C code becomes this chunk of Java", and almost zero on 
"What is
the (tree) structure of this code?"

When I started with the tree-driven approach and using ANTLR to do 
tranformation, I felt completely bogged down in
AST structure and found myself constantly thinking about *how* to do 
things rather than what needed
to be done.

I didn't write this article to say that the rule-driven way is always 
better, I just tried to explain why I've found
it better for my application. Normally, I wouldn't even bother to spell 
out my thoughts like that, but when
someone as smart and knowledgable as Terence is doing things the other 
way, I'm never going to be able
to get rid of that nagging feeling that I'm just missing something and 
I've made a terrible mistake.

On one hand, when Terence says "your pattern matcher may never 
terminate", I can't help but assume he's right
and I just haven't yet noticed some fatal flaw. But on the other hand, 
an expert in computation complexity will
tell you "your traveling salesman algorithm may take forever", and you 
know right away that he's talking
about *in theory*, but you know full well that it works just fine *in 
practice*.

Anyway, I'm ranting again. The one thing that we can agree on is that 
I've finally setup my email client for
reading antlr-interest posts, so I hope my responses will not appear to 
be new threads all the time, and that's
a good thing.

Andy :)


Gregg Reynolds wrote:

> Andy Tripp wrote:
>
>>
> ...etc...
>
> Hi all,
>
> I'm relatively new to AntlrWorld, having (re)discovered it only a few 
> weeks ago, and then discovered StringTemplate, which has since 
> consumed most of my waking hours.
>
> I can't really follow the hairy details of this thread, but I think I 
> see an abstract pattern.  Please tell me if the following makes sense:
>
> The core issue is design strategy for language transformation.  If we 
> can think of a continuum of design options, then (possibly) we can put 
> the Antlr strategy on one end, and the (Jazillion?) on the other.
>
> (I'm being very schematic here; perhaps the actual workings of antlr 
> and jazillion don't fit the schema.  Please advise.)
>
> We can call the Antlr approach "source-driven transformation"; the 
> Jazillion approach "target-driven" transformation.
>
> By "source-driven", I mean that the process looks sth like:
>
>     a.  write grammar to parse source language
>     b.  generate source AST
>     c.  write (tree) transformation grammar that attaches actions to 
> (AST) productions, producing either:
>
>         c1.  a target AST that can then be run through other 
> transformers, in particular a pretty-printer; or
>         c2.  a text in the target language
>
> So in practice a source-driven strategy means writing code to feed 
> into a parser generator.  The driver will invoke the parser on a 
> source text.  Grammatical structure of the source text controls 
> processing.
>
> By "target-driven" I mean a process that looks something like:
>
>     For each element in the target language,
>
>         a.  write transformation logic mapping source elements to 
> target element
>         b.  write (or generate) a "rule", which is a little parser to 
> examine the source text for elements needed to generate said target 
> element; attach transformations from (a) to production in the grammar
>
> In practice a target-driven strategy means writing a set of rules 
> (functions) to be called in turn at each token in the source text.  
> I.e. Start with a target element and see if the corresponding source 
> production(s) match(es); or, try to find the appropriate target 
> element by testing various source productions.  Source language 
> structure controls processing within the driver itself.
>
> The source-driven approach embeds target generation code in a source 
> grammar; the target-driven approach embeds source-grammar in target 
> generation code.
>
> I hope that is somewhere in the ballpark; it's nice and clean so it 
> would be a shame if it was also stupid.  ;)  I think I understand how 
> antlr works pretty well, but I'm not sure about the Jazillion approach.
>
> If this schema is accurate/useful, then I would suggest building on 
> the paper "Why I don't Use..." to produce a more general consideration 
> of the pros and cons of the respective approaches.  Something like 
> *"Language Transformation Strategies: Source-Driven v. Target-Driven 
> in a Fight to the Death!"*  As it stands, the article is interesting 
> (though a bit hard to follow for somebody like me, w/out lots of 
> parsing experience), but it sometimes gives (me at least) the 
> impression of saying "my approach is better because, well, because I 
> like it more". That's not necessarily a bad thing, but I gather that 
> in large part that's because you find the one approach fits better 
> with the way you think about the problem, which doesn't imply that it 
> is a "better" approach.  I'd like to see a more dispassionate 
> consideration of the pros and cons.  The "mental model" one needs for 
> each strategy is obviously very important, but there are other 
> considerations: efficiency, maintainability, etc. - the usual suspects.
>
> And of course the overalln approach could be generalized, i.e. design 
> an abstract uber-language (cf. IDL).  Then you can write one 
> source->uberlang transformer per source lang, and one uberlang->target 
> transformer per target language.  I suppose somebody already does this 
> (or has decided it's impossible or impractical).
>
> thanks,
>
> gregg
>

From dev at arabink.com  Wed Jan 11 09:34:18 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Wed Jan 11 09:34:29 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C3EB3F.8010503@jazillian.com>
References: <43C3EB3F.8010503@jazillian.com>
Message-ID: <43C5419A.9070507@arabink.com>

Andy Tripp wrote:
> In a fit of reverse-writer's-block last night, I wrote down
> some thoughts on AST treewalking and StringTemplate, titled
> "Why I don't Use StringTemplate for Language translation"
> 
> The article is here: http://www.jazillian.com/stringTemplate.html
> 

Hi Andy,

A few holes to poke in your article.  Which I mean in the nicest 
possible way!

 From your paper:  "But the main rationale for separating the "view" 
from the "controller" and "model" is so that we can have multiple 
"views", and that we can easily change the "view" without having to 
touch the "model" or the "controller. Certain applications may have 
multiple "views" (ANTLR, for example, which takes a single input in 
ANTLR-language, but generates Java code for Java programmers, C code for 
C programmers, etc). But for other applications, such as a 
"Any-dialect-of-C to Java" or "C or C++ to Java", the mapping is 
many-to-one, not one-to-many."

Isn't this a false dichotomy?  The same considerations apply to both 
situations.  If antlr can do many-to-one (source grammar to a variety of 
target languages) that is only because somebody took the trouble to 
write the target generation code.  It's not one-to-many, but many 
one-to-ones.  This is exactly what happens with a many-to-one mapping 
(variety of source languages to one target language): for each source 
language somebody has to take the trouble to write the transformation 
code, and you again end up with many one-to-ones.

So if it is a problem for Antlr, it is the same problem for Jazillion or 
any other code xformer, regardless of implementation technique.

Actually I think "MVC" is probably not the best idiom for discussion 
parsing and transformation, coming as it does from the world of 
graphical representation of data.  (Personally I don't find it useful to 
think of the result of a translation as a "view" of the source; e.g. 
calling the parser code generated by Antlr a "view" of the source 
grammar doesn't work for me.  Nobody considers the machine code emitted 
by a compiler to be a "view" of the source code.)

The real question is not separation of m v and c, but of the 
*genericity* (adaptability, flexibility, whatever) of the "service": 
given a parser generator, is its backend architecture general enough to 
make it easy to write specialized emitters?  Given a language 
transformer (e.g. Jazillion), is its frontend architecture general 
enough to make it easy to specialize it for a variety of input languages?

More specifically:  how hard would it be to write an ML or Haskell 
emitter for Antlr (something I'd like to see)?

How hard would it be to write an ML or Haskell front-end for Jazillion? 
  (I mean relative to a C frontend, not relative to a backend to Antlr, 
which would no doubt be easier.)

(Note GCC is a good example of genericity both on the front and back ends.)

A general observation:  you contrast the Antlr (AST) approach to 
"pattern-matching" in a few places (e.g. "is what you've got using 
StringTemplates and AST walking better than what you'd have with some 
(unspecified here) pattern-matching approach?"

But parsing *is* pattern matching, no?  So it isn't clear (to me) what 
exact contrast you're trying to establish.

One of the examples you give to illustrate the difficulty of AST-walking:

	2.  At any "printf function" node, loop through the format string and 
arguments, and do lots of processing to replace them with Java using the 
"+" operator.

My understanding is that you would just write a production for the 
grammar of the args of the printf function, which you could take 
directly from the C grammar, augmented by info from the printf 
definition in the library.  The "lots of processing" must occur 
regardless of implementation strategy, but in Antlr the grammar 
recognition part (looping through the format string and args) is clear 
and simple(?).

Correct me if I'm wrong, but I get the impression you're thinking about 
writing by hand a bunch of the AST parsing logic that Antlr generates 
automatically for tree grammars, rather the way you might need to 
proceed if you were using a less sophisticated parser generator 
(lex/yacc, etc.)  In that case, yes, it would definitely be a pain 
because you might need to do it all by hand.  But if I understand Antlr 
correctly, it saves you the trouble by supporting tree grammar.  So the 
interesting contrast is not necessarily between your approach and 
Antlr's, but between Antlr v. other parser generators.

All for now.  I'm not sure I agree with your paper, but it has certainly 
provoked thought.

-gregg
From jbb at acm.org  Wed Jan 11 10:16:56 2006
From: jbb at acm.org (John B. Brodie)
Date: Wed Jan 11 10:17:11 2006
Subject: [antlr-interest] Lexical nondeterminism
In-Reply-To: <67e2ed240601110617l76a741cg@mail.gmail.com> (message from
	Gabriel Radu on Wed, 11 Jan 2006 14:17:26 +0000)
References: <67e2ed240601110617l76a741cg@mail.gmail.com>
Message-ID: <E1EwkWm-0000ZQ-00@gecko>


Gabriel Radu asked:
>I am trying to write a antler grammar and I am getting a following result:
>
>ANTLR Parser Generator   Version 2.7.5 (20050128)   1989-2005 jGuru.com
>ServiceCompiler.g: warning:lexical nondeterminism between rules
>INT_or_FLOAT_or_MACADR_or_VERSIONSTRING and DEFAULT upon
>AuvitranServiceCompiler.g:     k==1:'D','d'
>AuvitranServiceCompiler.g:     k==2:'E','e'
>AuvitranServiceCompiler.g:     k==3:'F','f'
>AuvitranServiceCompiler.g:     k==4:'A','a'
>AuvitranServiceCompiler.g:     k==5:'U','u'
>AuvitranServiceCompiler.g:     k==6:'L','l'
>AuvitranServiceCompiler.g:     k==7:'T','t'
>AuvitranServiceCompiler.g:     k==8:<end-of-token>
>AuvitranServiceCompiler.g:     k==9:<end-of-token>
>AuvitranServiceCompiler.g:     k==10:<end-of-token>
>
>The interesting parts of the lexer are:
>
>...lots of informative stuff snipped...

You have:

>protected INT
>  :	(HEXDIG)+
>;

and

>protected VERSIONSTRING_L
>  : ( DIGIT )+ DOT ( DIGIT )+ DOT ( DIGIT )+ ('A'..'Z'|'a'..'z')?
>;
>
>protected VERSIONSTRING_S
>  : ( DIGIT )+ DOT ( DIGIT )+ ('A'..'Z'|'a'..'z')
>;
>
>protected VERSIONSTRING : ;
>
>INT_or_FLOAT_or_MACADR_or_VERSIONSTRING
>
>   : ( DIGIT (DIGIT)? DOT DIGIT ( DIGIT (DIGIT)? )? DOT )
>          => VERSIONSTRING_L { $setType( VERSIONSTRING ); }
>
>   | ( DIGIT (DIGIT)? DOT DIGIT ( DIGIT (DIGIT)? )? ('A'..'Z'|'a'..'z') )
>          => VERSIONSTRING_S { $setType( VERSIONSTRING ); }
>
>   | ( ( DIGIT )+ DOT ) => FLOAT { $setType( FLOAT ); }
>
>   | ( HEXDIG HEXDIG MACADRSEPARATOR ) => MACADR { $setType( MACADR ); }
>
>   | ( ( DIGIT )+ ) => INT { $setType( INT ); }
>
>;

and

>DEFAULT:
>    ('D' | 'd')
>    ('E' | 'e')
>    ('F' | 'f')
>    ('A' | 'a')
>    ('U' | 'u')
>    ('L' | 'l')
>    ('T' | 't')
>;

i believe that your ambiguity arises from INT being a sequence of
HEXDIG (dispite the predicate in the INT_or_FLOAT_...whatever rule).

thus the intput string `default` could be a DEFAULT or an INT followed
by NONTOCLITs.

while your k=10 lookahead would seem to be plenty to disambiguate this
(just need to look at the first 5 symbols); it has been my
exprience that lookahead is not considered when one of the items being
considered is expressed as a loop (e.g. either ()+ or ()*). that is, Antlr
will not try to do the 5 symbol lookahead before entering the INT loop.

so if an INT really is a sequence of HEXDIG then you will need to add
another predicated alternative to your INT_or_...whatever rule.

on the other hand if an INT is really a sequence of DIGIT then just
fix the protected INT rule and set the k=3 and (I think, not tested)
and you will have fixed this ambiguity.


on another issue which you did not (yet) ask about. you should be
really careful with your syntax predicates. consider the input string
"11.22.33.44.55.66". it would seem that this should scan as a MACADR,
yet your predicate for VERSIONSTRING_L will match this string and you
will end up scanning it as a VERSIONSTRING ("11.22.33") followed by DOT
followed by another VERSIONSTRING (i think).

attached is a version of your scanner that addresses this issue.

hope this helps...

//--------------------------begin attachment--------------------------

//----------------------------------------------------------------------
// Lexer
//----------------------------------------------------------------------

class ServiceLexer extends Lexer;

//----------------------------------------------------------------------
// White speace:

WS_ : (' ' | '\t') { $setType(SKIP); } ;

NEWLINE
    : '\n' ( '\r' )?
    | '\r' ( '\n' )?
;


//----------------------------------------------------------------------
// Chars:

NONTOCLIT
    :   'g'..'u' | 'x'..'z'
    |   'G'..'U' | 'X'..'Z'
;

protected LETTER : 'A'..'Z' | 'a'..'z' ;



//----------------------------------------------------------------------
// Numbers:

protected DIGIT
	:	'0'..'9'
;

protected HEXLIT
  : 'a'..'f' | 'A'..'F'
;

protected HEXDIG
  : ( DIGIT | HEXLIT )
;

protected INT
  :	( HEXDIG )+
;

protected FLOAT
  : ( DIGIT )+ DOT ( DIGIT )+
;

protected MACADRSEPARATOR
  : DOT
;

protected MACADR
  :
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG MACADRSEPARATOR
    HEXDIG HEXDIG
;

protected VERSIONSTRING
  : ( DIGIT )+ DOT ( DIGIT )+ ( ( DOT ( DIGIT )+ ( LETTER )? ) | LETTER )
;

INT_or_FLOAT_or_MACADR_or_VERSIONSTRING_or_DEFAULT
    : ( DEFAULT ) => ( DEFAULT { $setType( DEFAULT ); } )
    | ( MACADR ) => ( MACADR { $setType( MACADR ); } )
    | ( VERSIONSTRING ) => ( VERSIONSTRING { $setType( VERSIONSTRING ); } )
    | ( FLOAT ) => ( FLOAT { $setType( FLOAT ); } )
    | ( INT ) => ( INT { $setType( INT ); } )
;



//----------------------------------------------------------------------
// Punctuation:

DOT:    '.' ;

COMMA:	',' ;

COLON:	':' ;

SCOLON:	';' ;



//[ some more text]



//----------------------------------------------------------------------
protected DEFAULT:
    ('D' | 'd')
    ('E' | 'e')
    ('F' | 'f')
    ('A' | 'a')
    ('U' | 'u')
    ('L' | 'l')
    ('T' | 't')
;


//---------------------------end attachment---------------------------


From dev at arabink.com  Wed Jan 11 10:22:25 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Wed Jan 11 10:22:31 2006
Subject: [antlr-interest] Re: Source-driven v. Target-driven xforms (was
	Re: New article on StringTemplates and Treewalkers)
In-Reply-To: <43C53E06.4090700@jazillian.com>
References: <43C528F9.709@jazillian.com> <43C532CC.5000900@arabink.com>
	<43C53E06.4090700@jazillian.com>
Message-ID: <43C54CE1.70005@arabink.com>

Andy Tripp wrote:
> Hi Gregg,
> 
> Yes, very good description of the issue.
> Generally, I think of it  as "tree driven" vs. "rule driven" rather than 
> "source-driven"
> and "target driven". In "tree driven", the  source language grammar 
> drives the design.
> In rule-driven, the  design is a sequential application of rules.
> 

Understandable, but as I mentioned in my other post, "rule" is 
ambiguous, so this terminology might be troublesome for people not so 
familiar with parsing or your approach.  In ParserWorld, "rule" is 
commonly a synonym for "grammatical production" (which may have attached 
actions) (and it could be a tree grammar production), but in 
JazillionTown it means specifically a function that does a little 
parsing and then some actions.  I think that will be confusing for your 
readers.  Unfortunately I can't think of a better term at the moment.

Howsabout "target-centered rule-driven" v. "source-centered 
tree-driven"?  Oh boy!  Acronyms: TCRD v. SCTD!  ;)

A Jazillion "rule" is analogous to an antlr "rule" turned inside out, 
and vice-versa, no?

But "tree-driven" makes sense to me, since it creates and uses ASTs, 
whereas Jazillion doesn't.

> 
> When I started with the tree-driven approach and using ANTLR to do 
> tranformation, I felt completely bogged down in
> AST structure and found myself constantly thinking about *how* to do 
> things rather than what needed
> to be done.
> 
Well, that's where I have to hold my tongue, since it's all theoretical 
to me.  But as a general issue, I wonder how much of that is 
attributable to Antlr's meta-language, by which I mean the English 
language used to document the works.  After all, anybody who can read C 
and understand C code must be parsing it, and therefore must have a 
structured model of the code rattling around in the skull: a tree, if 
not an AST.  If one sees "if (x=1)", one can surely see that "x=1" is an 
expression, and that it is composed of a variable, etc.  Which amounts 
to a tree, even if one doesn't use tree language (parent, child, root, 
etc.) to talk about it.

In any case, I think you've put your finger on a very important point, 
namely that  even if the AST-based approach has advantages, it may 
require the fabled "paradigm shift", and let's face it, most people 
coding to deadline don't have the luxury - it takes time, and there's 
always the risk that the new paradigm won't deliver.  So then the 
question is, can the AST approach be explained in a metalanguage that is 
closer to the way most programmers ordinarily think?  By the same token, 
can we come up with a meta-language for your approach that connects it 
with the implied parse tree/AST?  Hmm.  (If you can't tell, I'm actually 
much more interested in the expressiveness of language and metalanguage 
than I am in actual software. ;)

-gregg
From parrt at cs.usfca.edu  Wed Jan 11 10:28:37 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Wed Jan 11 10:29:46 2006
Subject: [antlr-interest] ANTLR Library as Eclipse Plugin
In-Reply-To: <e163e2f50601110908laeed5ecr@mail.gmail.com>
References: <e163e2f50601101401n2fc7aad9r@mail.gmail.com>
	<200601110022.k0B0MNIJ006570@s2.eroute.net>
	<e163e2f50601110338m74fcd893k@mail.gmail.com>
	<41fed8f80601110620g223ee1dbh2d36bb17ec8934e@mail.gmail.com>
	<e163e2f50601110908laeed5ecr@mail.gmail.com>
Message-ID: <FC6775CF-5B77-47C2-970B-E57DEB4756DA@cs.usfca.edu>


On Jan 11, 2006, at 9:08 AM, Thiago Arrais wrote:
> Scott's previous suggestion pretty much solves the issue. I just need
> to know if we could use the name org.antlr on one of our project's
> packaging units and if there was already such a package.

Hi. :)  Be advised that ANTLR v3 uses org.antlr.* rather than antlr.*  
partially to distinguish it from v2 versions.

Ter
From samuelgoto at gmail.com  Wed Jan 11 11:00:52 2006
From: samuelgoto at gmail.com (Samuel Goto)
Date: Wed Jan 11 11:00:55 2006
Subject: [antlr-interest] CPP parser
Message-ID: <820a80710601111100w3f84797dpc1655d061f474c65@mail.gmail.com>

Hi,

         This is my first message to the list. It is about cpp parsing and I
have tried the list archieves and google ... hope I don't make any mistake
... heheheh

          Well, ok. So I want to parse C++. I am writing a SystemC ( witch
is C++ ) to Verilog ( or VHDL ) translator.

          All I need is a C++ parser with an AST, or a suggestion on a
technique to make code analysis.

          I am using with sucess the GnuC grammar with antrl. I wrote a
SystemC ( a subset of C++ ) extension of the GnuC ( wich extends StdC ), and
this is doing great for now !!! It actually translates a lot of SystemC
models to Verilog !!! But I want the full expression power of C++. So I need
to change to a C++ front end.

        The problem is : the c++ grammar that comes with antlr is great, but
it doesn't come with an AST. I have tried many things to substitute the AST,
like a tree walker, a tree parser and string template. The thing is : they
just don't do the job for me, i can't use them or they take more work to
build than I expected.

         I tried other tools too : bison, elsa, sablecc, yacc, etc. They
don't have what I need : an AST or something similar.

        Well, since c++ is a very common language, and I was sure the
community at this point would have written a ( easy to use ) c++ front end
with an AST, I am starting to think that I am the one who is having a bad
idea about what I really need ( hehehe ... this is usually the case ...
heheheh ... ).

        Therefore, I am asking : how can I use the c++ grammar for a
translator ?

        I tried a tree parser, but it is more work than I was expecting ...
isn't there an easier way to do this ? Perhaps I am missing something ....

        Any ideas ?

       PS By the way : GREAT job at antlr !!! Congratulations !!!

--
f u cn rd ths u cn b a gd prgmr !
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060111/f80831fd/attachment.html
From atripp at jazillian.com  Wed Jan 11 11:08:43 2006
From: atripp at jazillian.com (Andy Tripp)
Date: Wed Jan 11 11:08:47 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C5419A.9070507@arabink.com>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
Message-ID: <43C557BB.9080706@jazillian.com>



Gregg Reynolds wrote:

> Andy Tripp wrote:
>
>> In a fit of reverse-writer's-block last night, I wrote down
>> some thoughts on AST treewalking and StringTemplate, titled
>> "Why I don't Use StringTemplate for Language translation"
>>
>> The article is here: http://www.jazillian.com/stringTemplate.html
>>
>
> Hi Andy,
>
> A few holes to poke in your article.  Which I mean in the nicest 
> possible way!
>
> From your paper:  "But the main rationale for separating the "view" 
> from the "controller" and "model" is so that we can have multiple 
> "views", and that we can easily change the "view" without having to 
> touch the "model" or the "controller. Certain applications may have 
> multiple "views" (ANTLR, for example, which takes a single input in 
> ANTLR-language, but generates Java code for Java programmers, C code 
> for C programmers, etc). But for other applications, such as a 
> "Any-dialect-of-C to Java" or "C or C++ to Java", the mapping is 
> many-to-one, not one-to-many."
>
> Isn't this a false dichotomy?  The same considerations apply to both 
> situations.  If antlr can do many-to-one (source grammar to a variety 
> of target languages) 

You mean "one-to-many", here, not "many-to-one", don't you? ANTLR itself 
has just one input language, and "many" output languages (C++, Java, C#).

> that is only because somebody took the trouble to write the target 
> generation code.  It's not one-to-many, but many one-to-ones.  This is 
> exactly what happens with a many-to-one mapping (variety of source 
> languages to one target language): for each source language somebody 
> has to take the trouble to write the transformation code, and you 
> again end up with many one-to-ones.

No, I don't think that ANTLR is many one-to-ones at all. There is only 
one input language, there is a lot of code to derive the output, and then
there are minor variations on the output to make it fit either C++, 
Java, or C# syntax.

>
> So if it is a problem for Antlr, it is the same problem for Jazillion 
> or any other code xformer, regardless of implementation technique.

I do agree that (and I'm not sure if this is your point or not) ANTLR 
and Jazillian seem like they should both be designed the same way.
That's why I wrote this - to try to understand why my "rule-based" way 
seems better to me, and yet the "treewalker" way seems better
to Terence and a lot of people in the translation world. I assume it's 
something I'm missing, but who knows?

>
>
> Actually I think "MVC" is probably not the best idiom for discussion 
> parsing and transformation, coming as it does from the world of 
> graphical representation of data.  (Personally I don't find it useful 
> to think of the result of a translation as a "view" of the source; 
> e.g. calling the parser code generated by Antlr a "view" of the source 
> grammar doesn't work for me.  

Me neither, I hope I didn't say that.

> Nobody considers the machine code emitted by a compiler to be a "view" 
> of the source code.)

Ah, but they do. I do, and  that's exactly what Terence is saying in the 
StringTemplate article...that the target Java, python, and bytecode
are simple three slightly different "views" of the output. I agree with 
that.

>
> The real question is not separation of m v and c, but of the 
> *genericity* (adaptability, flexibility, whatever) of the "service": 
> given a parser generator, is its backend architecture general enough 
> to make it easy to write specialized emitters?  Given a language 
> transformer (e.g. Jazillion), is its frontend architecture general 
> enough to make it easy to specialize it for a variety of input languages?

In my case, I haven't cared too much (yet) that the frontend by able to 
handle multiple input languages (or that the backend be able
to output multiple languages for that matter). Just a single C-to-Java 
translator is hard enough, and I've been happy to spend 3 years full time
thinking about all the ways to do that really well, rather than 
expanding my scope. Having said that, I'm now working on C++ to Java, 
though :)

>
> More specifically:  how hard would it be to write an ML or Haskell 
> emitter for Antlr (something I'd like to see)?

Good question, and my related question is "will StringTemplate make that 
any easier?".

>
>
> How hard would it be to write an ML or Haskell front-end for 
> Jazillion?  (I mean relative to a C frontend, not relative to a 
> backend to Antlr, which would no doubt be easier.)

Answer: very hard: the translation rules are all C-specific. To put it 
bluntly, the Jazillian "front-end" is not in any way separated from the 
"engine"
and "backend". I believe it's impossible to design such a 
any-language-to-any-language translation engine, despite the fact that
Semantic Designs claims to have such a product.

>
> (Note GCC is a good example of genericity both on the front and back 
> ends.)

Right, I'm familiar with the gcc 4.0 architecture. IIRC it only supports 
C/C++ with gcc-specific extensions and Java as input,
and executable and Java bytecode as output. Good luck on getting it to 
input or output ML, Haskell, or Lisp :)

>
> A general observation:  you contrast the Antlr (AST) approach to 
> "pattern-matching" in a few places (e.g. "is what you've got using 
> StringTemplates and AST walking better than what you'd have with some 
> (unspecified here) pattern-matching approach?"
>
> But parsing *is* pattern matching, no?  So it isn't clear (to me) what 
> exact contrast you're trying to establish.

I'm not refering to ANTLR parsing here, but ANTLR treewalking. But yes, 
we could consider treewalking to be "pattern-matching on
two-dimensional trees", while I'm saying I prefer "pattern-matching on 
one-dimensional token streams". Simply because it's trivial to
form mental pictures of token streams. When we read "int[] i;", our 
brain has already tokenized it into a sequence of 5 tokens:
int [ ] i ;
But given that same chunk of code, our brains to NOT easily form an AST 
structure:
VAR_DEC
     TYPE "int"
     ARRAY_DEC  "[]"
     NAME "i"

Avoiding mental pictures of AST trees altogether is just a HUGE 
productivity boost, at least for me.
I'd say I'm at least twice as productive in writing rules (both simple 
text-replacement ones and
complex ones written in Java code), and probably more like 5-10x more 
productive
by largely ignoring AST structures.
    

>
>
> One of the examples you give to illustrate the difficulty of AST-walking:
>
>     2.  At any "printf function" node, loop through the format string 
> and arguments, and do lots of processing to replace them with Java 
> using the "+" operator.
>
> My understanding is that you would just write a production for the 
> grammar of the args of the printf function, which you could take 
> directly from the C grammar, augmented by info from the printf 
> definition in the library.  The "lots of processing" must occur 
> regardless of implementation strategy, but in Antlr the grammar 
> recognition part (looping through the format string and args) is clear 
> and simple(?).

That's right, except I disagree about the "clear and simple". It's not 
all that hard, but it's also not trivial. I prefer to just use plain old 
Java.
To parse arguments, for example, I have a Java method that loops through 
a token list, looking for commas and doing a little
bit of logic with matching parens/brackets/braces:

List<List<Token>> parseArgs(List<Token> tokens);

Each argument is returned as a List of Tokens, and so all arguments are 
just a List of Lists of Tokens.
To someone who knows ANTLR well, this approach may not seem any easier, 
but I do.
Then again, I hate it when I see CSS syntax inside HTML, so maybe it's 
just me :)

>
> Correct me if I'm wrong, but I get the impression you're thinking 
> about writing by hand a bunch of the AST parsing logic that Antlr 
> generates automatically for tree grammars, rather the way you might 
> need to proceed if you were using a less sophisticated parser 
> generator (lex/yacc, etc.)

No, No. I use ANTLR for all lexing and parsing, I would never do that by 
hand. It's just that I'm doing translation from token-stream
to token-stream (generally avoiding parsing) rather than from AST-to-AST.

> In that case, yes, it would definitely be a pain because you might 
> need to do it all by hand.  But if I understand Antlr correctly, it 
> saves you the trouble by supporting tree grammar.  So the interesting 
> contrast is not necessarily between your approach and Antlr's, but 
> between Antlr v. other parser generators.

One key difference with ANTLR vs. Jazillian is that Terence gets to 
design the ANTLR input grammar, but I didn't get
to design the C input grammar. This way, the ANTLR input grammar is well 
designed, and designed to do everything that
ANTLR needs it to do. By contrast, the C grammar isn't quite so great. 
For example, I want to handle preprocessor stuff
(#include, #define, etc) with the same approach that I use for 
everything else. And yet the C language grammar knows
nothing at all about preprocessor directives.

>
> All for now.  I'm not sure I agree with your paper, but it has 
> certainly provoked thought.
>
> -gregg

Thanks for the input.
Andy
From scheng at innaworks.com  Wed Jan 11 11:13:27 2006
From: scheng at innaworks.com (Stephen Cheng)
Date: Wed Jan 11 11:13:44 2006
Subject: [antlr-interest] [was: CPP parser] AST and pre-processor
In-Reply-To: <820a80710601111100w3f84797dpc1655d061f474c65@mail.gmail.com>
Message-ID: <001c01c616e3$1b6ca4d0$0201010a@scheng>

I am curious about how the C parser deals with pre-processor primitives in
the AST. Do we need to pre-process the C source prior to feeding into antlr
to generate the C AST?

 

Stephen

 

  _____  

From: antlr-interest-bounces@antlr.org
[mailto:antlr-interest-bounces@antlr.org] On Behalf Of Samuel Goto
Sent: Thursday, 12 January 2006 8:01 a.m.
To: antlr-interest@antlr.org
Subject: [antlr-interest] CPP parser

 

Hi,

         This is my first message to the list. It is about cpp parsing and I
have tried the list archieves and google ... hope I don't make any mistake
... heheheh

          Well, ok. So I want to parse C++. I am writing a SystemC ( witch
is C++ ) to Verilog ( or VHDL ) translator.

          All I need is a C++ parser with an AST, or a suggestion on a
technique to make code analysis.

          I am using with sucess the GnuC grammar with antrl. I wrote a
SystemC ( a subset of C++ ) extension of the GnuC ( wich extends StdC ), and
this is doing great for now !!! It actually translates a lot of SystemC
models to Verilog !!! But I want the full expression power of C++. So I need
to change to a C++ front end.

        The problem is : the c++ grammar that comes with antlr is great, but
it doesn't come with an AST. I have tried many things to substitute the AST,
like a tree walker, a tree parser and string template. The thing is : they
just don't do the job for me, i can't use them or they take more work to
build than I expected.

         I tried other tools too : bison, elsa, sablecc, yacc, etc. They
don't have what I need : an AST or something similar.

        Well, since c++ is a very common language, and I was sure the
community at this point would have written a ( easy to use ) c++ front end
with an AST, I am starting to think that I am the one who is having a bad
idea about what I really need ( hehehe ... this is usually the case ...
heheheh ... ).

        Therefore, I am asking : how can I use the c++ grammar for a
translator ?

        I tried a tree parser, but it is more work than I was expecting ...
isn't there an easier way to do this ? Perhaps I am missing something ....

        Any ideas ?

       PS By the way : GREAT job at antlr !!! Congratulations !!!

-- 
f u cn rd ths u cn b a gd prgmr ! 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060112/2cc97ca7/attachment-0001.html
From antlr at jazillian.com  Wed Jan 11 11:25:01 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Wed Jan 11 11:25:08 2006
Subject: [antlr-interest] Re: Source-driven v. Target-driven xforms (was
	Re: New article on StringTemplates and Treewalkers)
In-Reply-To: <43C54CE1.70005@arabink.com>
References: <43C528F9.709@jazillian.com> <43C532CC.5000900@arabink.com>
	<43C53E06.4090700@jazillian.com> <43C54CE1.70005@arabink.com>
Message-ID: <43C55B8D.2050905@jazillian.com>

Gregg Reynolds wrote:

> Andy Tripp wrote:
>
>> Hi Gregg,
>>
>> Yes, very good description of the issue.
>> Generally, I think of it  as "tree driven" vs. "rule driven" rather 
>> than "source-driven"
>> and "target driven". In "tree driven", the  source language grammar 
>> drives the design.
>> In rule-driven, the  design is a sequential application of rules.
>>
>
> Understandable, but as I mentioned in my other post, "rule" is 
> ambiguous, so this terminology might be troublesome for people not so 
> familiar with parsing or your approach.  In ParserWorld, "rule" is 
> commonly a synonym for "grammatical production" (which may have 
> attached actions) (and it could be a tree grammar production), but in 
> JazillionTown it means specifically a function that does a little 
> parsing and then some actions.  I think that will be confusing for 
> your readers.  Unfortunately I can't think of a better term at the 
> moment.

Yea, "rule" is probably confusing to many. Some use the term "term 
rewriting" too.
Also, I don't think of my "rule" as doing "a little parsing and them 
some actions", I think of it as
"a mapping of an input pattern to a replacement pattern". That's how you 
start to think when you've got hundreds of
little things like:

sprintf(stderr, --> printf(

...and you have to think like that, because in fact the thing you're 
matching on may not even be "parseable" - it's not a valid
C construct on it's own, and you can't build an AST from it!

>
> Howsabout "target-centered rule-driven" v. "source-centered 
> tree-driven"?  Oh boy!  Acronyms: TCRD v. SCTD!  ;)
>
> A Jazillion "rule" is analogous to an antlr "rule" turned inside out, 
> and vice-versa, no?
>
> But "tree-driven" makes sense to me, since it creates and uses ASTs, 
> whereas Jazillion doesn't.
>
>>
>> When I started with the tree-driven approach and using ANTLR to do 
>> tranformation, I felt completely bogged down in
>> AST structure and found myself constantly thinking about *how* to do 
>> things rather than what needed
>> to be done.
>>
> Well, that's where I have to hold my tongue, since it's all 
> theoretical to me.  But as a general issue, I wonder how much of that 
> is attributable to Antlr's meta-language, by which I mean the English 
> language used to document the works.  After all, anybody who can read 
> C and understand C code must be parsing it, and therefore must have a 
> structured model of the code rattling around in the skull: a tree, if 
> not an AST.  If one sees "if (x=1)", one can surely see that "x=1" is 
> an expression, and that it is composed of a variable, etc.  Which 
> amounts to a tree, even if one doesn't use tree language (parent, 
> child, root, etc.) to talk about it.

I never care too much about the theory, only how things work out in 
practice. Even if people do generally picture some
tree-like structure when they read C code, I think the tree structure is 
often "wrong". That's why we often write
"if (x=5)" so often, even in writing Java. If we where good at picturing 
ASTs, we would know that the child of an IF node
must be boolean type and that the ASSIGNMENT operator returns a type 
that matches it's children, which is "int" here.

>
> In any case, I think you've put your finger on a very important point, 
> namely that  even if the AST-based approach has advantages, it may 
> require the fabled "paradigm shift", and let's face it, most people 
> coding to deadline don't have the luxury - it takes time, and there's 
> always the risk that the new paradigm won't deliver.  

Yes, though I would call it a "mindset shift" for developers to stop 
thinking in terms of "snippets of code" and start thinking in terms of
"AST tree structures". ANTLR gurus already made that shift many years 
ago, and are good at making shifts like that. I guess I'm not.

> So then the question is, can the AST approach be explained in a 
> metalanguage that is closer to the way most programmers ordinarily 
> think?  By the same token, can we come up with a meta-language for 
> your approach that connects it with the implied parse tree/AST?  Hmm.  
> (If you can't tell, I'm actually much more interested in the 
> expressiveness of language and metalanguage than I am in actual 
> software. ;)

TXL (among others) has a nice language that lets you specify tree 
transforms. In fact, I guess XSLT does that too.

>
>
> -gregg
>

From antlr at jazillian.com  Wed Jan 11 11:36:33 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Wed Jan 11 11:36:36 2006
Subject: [antlr-interest] Re: Source-driven v. Target-driven xforms (was
	Re: New article on StringTemplates and Treewalkers)
In-Reply-To: <43C54CE1.70005@arabink.com>
References: <43C528F9.709@jazillian.com> <43C532CC.5000900@arabink.com>
	<43C53E06.4090700@jazillian.com> <43C54CE1.70005@arabink.com>
Message-ID: <43C55E41.20502@jazillian.com>


>
> Understandable, but as I mentioned in my other post, "rule" is 
> ambiguous, so this terminology might be troublesome for people not so 
> familiar with parsing or your approach.  In ParserWorld, "rule" is 
> commonly a synonym for "grammatical production" (which may have 
> attached actions) (and it could be a tree grammar production), but in 
> JazillionTown it means specifically a function that does a little 
> parsing and then some actions.  I think that will be confusing for 
> your readers.  Unfortunately I can't think of a better term at the 
> moment.
>
> Howsabout "target-centered rule-driven" v. "source-centered 
> tree-driven"?  Oh boy!  Acronyms: TCRD v. SCTD!  ;)
>
> A Jazillion "rule" is analogous to an antlr "rule" turned inside out, 
> and vice-versa, no?

Speaking of using the term "rule", I'm going to try to submit a paper 
(maybe even this article or a variation) and give a talk at
the 7th International Workshop on Rule-Based Programming:
http://www.dcs.kcl.ac.uk/events/RULE06/


From scheng at innaworks.com  Wed Jan 11 11:55:37 2006
From: scheng at innaworks.com (Stephen Cheng)
Date: Wed Jan 11 11:55:53 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C557BB.9080706@jazillian.com>
Message-ID: <002701c616e9$0064b9b0$0201010a@scheng>


> > (Note GCC is a good example of genericity both on the front and back
> > ends.)
> 
> Right, I'm familiar with the gcc 4.0 architecture. IIRC it only supports
> C/C++ with gcc-specific extensions and Java as input,
> and executable and Java bytecode as output. Good luck on getting it to
> input or output ML, Haskell, or Lisp :)
> 
> >

We have studied GCC in details as well.

Ultimately an architecture is really defined by what it is *NOT* designed to
do. The GCC IR and back-end is only designed to generate low level machine
code for register-based machine. The IR really does not have enough
information to handle generation to Java bytecode (or .NET CLR) which is a
stack-based machine. The support for Java bytecode output is a hack - it has
a wholly separate IR and so forth, and this is why it would be extremely
unlikely to ever see a GCC C++ to java bytecode compiler.

I don't know enough about ML, Haskell or LISP, however I don't see why the
GCC IR and backend is not powerful to cope with ML, Haskell, LISP. However
obviously a lot of work needs to be done to create a front end to
"translate" ML, Haskell or LISP to the GCC IR.

Cheers,
Stephen Cheng
CEO Innaworks

mBooster (www.innaworks.com) - the world's first true optimizing compiler
for J2ME


From monty at codetransform.com  Wed Jan 11 12:36:55 2006
From: monty at codetransform.com (Monty Zukowski)
Date: Wed Jan 11 12:37:31 2006
Subject: [antlr-interest] [was: CPP parser] AST and pre-processor
In-Reply-To: <001c01c616e3$1b6ca4d0$0201010a@scheng>
References: <001c01c616e3$1b6ca4d0$0201010a@scheng>
Message-ID: <4DB1A060-794C-44EA-B466-82D0D8B2557E@codetransform.com>


On Jan 11, 2006, at 11:13 AM, Stephen Cheng wrote:

> I am curious about how the C parser deals with pre-processor  
> primitives in the AST. Do we need to pre-process the C source prior  
> to feeding into antlr to generate the C AST?
>
>
>

Yes, you must preprocess the C source first.

As for C++ AST, I have no suggestions other than extending the tree  
parser and tree emitter from the GnuC translation toolkit.

Monty
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060111/a366e266/attachment.html
From dev at arabink.com  Wed Jan 11 13:52:17 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Wed Jan 11 13:52:30 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C557BB.9080706@jazillian.com>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com>
Message-ID: <43C57E11.5080007@arabink.com>

Andy Tripp wrote:
> 

>>
>> Isn't this a false dichotomy?  The same considerations apply to both 
>> situations.  If antlr can do many-to-one (source grammar to a variety 
>> of target languages) 
> 
> 
> You mean "one-to-many", here, not "many-to-one", don't you? ANTLR itself 
> has just one input language, and "many" output languages (C++, Java, C#).

Oops.

> 
>> that is only because somebody took the trouble to write the target 
>> generation code.  It's not one-to-many, but many one-to-ones.  This is 
>> exactly what happens with a many-to-one mapping (variety of source 
>> languages to one target language): for each source language somebody 
>> has to take the trouble to write the transformation code, and you 
>> again end up with many one-to-ones.
> 
> 
> No, I don't think that ANTLR is many one-to-ones at all. There is only 
> one input language, there is a lot of code to derive the output, and then
> there are minor variations on the output to make it fit either C++, 
> Java, or C# syntax.

Ok, syntactically, maybe the backend code is mixed up.  But 
conceptually?  After all, what is the difference between many-one and 
many one-one, rilly?

> 
>>
>> So if it is a problem for Antlr, it is the same problem for Jazillion 
>> or any other code xformer, regardless of implementation technique.
> 
> 
> I do agree that (and I'm not sure if this is your point or not) ANTLR 
> and Jazillian seem like they should both be designed the same way.

Not at all, I'm only trying abstract in order to find the gist nut of 
the problem.  After all, if you went to the trouble of trying antlr and 
finding it lacking, there's something there, there.
>>
>> Actually I think "MVC" is probably not the best idiom for discussion 
>> parsing and transformation, coming as it does from the world of 
>> graphical representation of data.  (Personally I don't find it useful 
>> to think of the result of a translation as a "view" of the source; 
>> e.g. calling the parser code generated by Antlr a "view" of the source 
>> grammar doesn't work for me.  
> 
> 
> Me neither, I hope I didn't say that.

Sorry, that actually belongs on a different note to Mr. Parr regarding 
his (excellent) paper on separating MVC.  I like the content, just 
interested in other (possibly "better") ways of expressing it.

> 
>> Nobody considers the machine code emitted by a compiler to be a "view" 
>> of the source code.)
> 
> 
> Ah, but they do. I do, and  that's exactly what Terence is saying in the 
> StringTemplate article...that the target Java, python, and bytecode
> are simple three slightly different "views" of the output. I agree with 
> that.
> 

Well, you're a special case so we get to remove you from the sample.  ;)

But the article was about a straightforward source to source 
transformation - not machine code generation (Java byte code is not 
machine code).  I wonder if you and/or Mr. Parr really think of compiled 
code - machine code - as a "view" of the source.  Ordinarily I mean - of 
course one can talk about it that way for special purposes.

>>
>> The real question is not separation of m v and c, but of the 
>> *genericity* (adaptability, flexibility, whatever) of the "service": 
>> given a parser generator, is its backend architecture general enough 
>> to make it easy to write specialized emitters?  Given a language 
>> transformer (e.g. Jazillion), is its frontend architecture general 
>> enough to make it easy to specialize it for a variety of input languages?
> 
> 
> In my case, I haven't cared too much (yet) that the frontend by able to 
> handle multiple input languages (or that the backend be able
> to output multiple languages for that matter). Just a single C-to-Java 
> translator is hard enough, and I've been happy to spend 3 years full time
> thinking about all the ways to do that really well, rather than 
> expanding my scope. Having said that, I'm now working on C++ to Java, 
> though :)
> 
>>
>> More specifically:  how hard would it be to write an ML or Haskell 
>> emitter for Antlr (something I'd like to see)?
> 
> 
> Good question, and my related question is "will StringTemplate make that 
> any easier?".

For the actual text generation, yes (I think); but that has nothing to 
do with target v. source driven transformation strategies.

>>
>> How hard would it be to write an ML or Haskell front-end for 
>> Jazillion?  (I mean relative to a C frontend, not relative to a 
>> backend to Antlr, which would no doubt be easier.)
> 
> 
> Answer: very hard: the translation rules are all C-specific. To put it 
> bluntly, the Jazillian "front-end" is not in any way separated from the 
> "engine"
> and "backend". I believe it's impossible to design such a 
> any-language-to-any-language translation engine, despite the fact that
> Semantic Designs claims to have such a product.
> 
I guess Lisp or some similar lambda calculus thingee would be best for 
the urlanguage.  Wouldn't that be a fun project?  No doubt somebody 
somewhere has tried.
>>
>> (Note GCC is a good example of genericity both on the front and back 
>> ends.)
> 
> 
> Right, I'm familiar with the gcc 4.0 architecture. IIRC it only supports 
> C/C++ with gcc-specific extensions and Java as input,
> and executable and Java bytecode as output. Good luck on getting it to 
> input or output ML, Haskell, or Lisp :)

I looked into that a bit once.  I don't remember the details, but there 
are languages for which GCC just ain't the right tool.

> 
>>
>> A general observation:  you contrast the Antlr (AST) approach to 
>> "pattern-matching" in a few places (e.g. "is what you've got using 
>> StringTemplates and AST walking better than what you'd have with some 
>> (unspecified here) pattern-matching approach?"
>>
>> But parsing *is* pattern matching, no?  So it isn't clear (to me) what 
>> exact contrast you're trying to establish.
> 
> 
> I'm not refering to ANTLR parsing here, but ANTLR treewalking. But yes, 
> we could consider treewalking to be "pattern-matching on
> two-dimensional trees", while I'm saying I prefer "pattern-matching on 
> one-dimensional token streams". Simply because it's trivial to
> form mental pictures of token streams. When we read "int[] i;", our 
> brain has already tokenized it into a sequence of 5 tokens:
> int [ ] i ;
> But given that same chunk of code, our brains to NOT easily form an AST 
> structure:
> VAR_DEC
>     TYPE "int"
>     ARRAY_DEC  "[]"
>     NAME "i"

Yep.  Although I daresay it depends on which language one is most 
comfortable with.  In lisp dialects it's pretty straightforward to thing 
in terms of something more treelike.  Then again, given the mainstream 
resistance to all those parentheses...

> 
> Avoiding mental pictures of AST trees altogether is just a HUGE 
> productivity boost, at least for me.
> I'd say I'm at least twice as productive in writing rules (both simple 
> text-replacement ones and
> complex ones written in Java code), and probably more like 5-10x more 
> productive
> by largely ignoring AST structures.

That's interesting.  Can't argue with experience.  I suggest we cadge a 
few million bucks out of the DOD to do a study.

-gregg

From sohail at taggedtype.net  Wed Jan 11 13:56:47 2006
From: sohail at taggedtype.net (sohail@taggedtype.net)
Date: Wed Jan 11 13:56:57 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C557BB.9080706@jazillian.com>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com>
Message-ID: <54345.127.0.0.1.1137016607.squirrel@taggedtype.net>

> Gregg Reynolds wrote:
>
>> Andy Tripp wrote:
>> More specifically:  how hard would it be to write an ML or Haskell
>> emitter for Antlr (something I'd like to see)?
>
> Good question, and my related question is "will StringTemplate make that
> any easier?".

Now you're just being mean. This is as big a difference as generating code
for a stack based machine when your AST assumes a register based machine
(like gcc). This is an analogy for functional languages and imperative
languages like C++ or Java. Therefore, you might need to tweak your AST
(but then again, you might not!)

>> How hard would it be to write an ML or Haskell front-end for
>> Jazillion?  (I mean relative to a C frontend, not relative to a
>> backend to Antlr, which would no doubt be easier.)
>
> Answer: very hard: the translation rules are all C-specific. To put it
> bluntly, the Jazillian "front-end" is not in any way separated from the
> "engine"
> and "backend". I believe it's impossible to design such a
> any-language-to-any-language translation engine, despite the fact that
> Semantic Designs claims to have such a product.

With some constraints, I think this is possible.

> brain has already tokenized it into a sequence of 5 tokens:
> int [ ] i ;
> But given that same chunk of code, our brains to NOT easily form an AST
> structure:

I think some people do. Thats why lisp is so easy to read. For those :)

From gcaglar at gmail.com  Wed Jan 11 14:46:58 2006
From: gcaglar at gmail.com (Gokhan Caglar)
Date: Wed Jan 11 14:47:01 2006
Subject: [antlr-interest] Syntactic predicate for single alternatives
Message-ID: <2cc5308c0601111446m7f3963d1sc97349c75d1bf452@mail.gmail.com>

Hi I'm wondering how I can write a syntactic predicate for a special case.
Here is a very simle grammar:

class SmallParser extends Parser;

program
    :
        (DO THIS)=>
        (statement1)*

        (statement2)?
    ;

statement1
    : DO THIS
    ;

statement2
    : DO THAT
    ;

class SmallLexer extends Lexer;

options {
    caseSensitive=false;
    caseSensitiveLiterals=false;
}

tokens
{
    DO="do";
    THIS="this";
    THAT="that";
}


protected
WS_CHAR
    : ' '
    | '\t'
    | '\f'
    | ( options {generateAmbigWarnings=false;}
        : "\r\n"
        | '\r'
        | '\n'
        )
        { newline(); }
    ;

WS : (WS_CHAR)+
  { _ttype = Token.SKIP; }
 ;

At the program rule I think statement2 is an alternative to statement1 in
the following construct:  (statement1)* statement2

However I get the error:  warning:Syntactic predicate ignored for single
alternative

Thanks,

Gokhan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060111/1a954d32/attachment.html
From prashant.deva at gmail.com  Wed Jan 11 20:43:40 2006
From: prashant.deva at gmail.com (Prashant Deva)
Date: Wed Jan 11 20:44:16 2006
Subject: [antlr-interest] Syntactic predicate for single alternatives
In-Reply-To: <2cc5308c0601111446m7f3963d1sc97349c75d1bf452@mail.gmail.com>
References: <2cc5308c0601111446m7f3963d1sc97349c75d1bf452@mail.gmail.com>
Message-ID: <41fed8f80601112043q32bff883m8273b662a40e5f7@mail.gmail.com>

> At the program rule I think statement2 is an alternative to statement1 in
> the following construct:  (statement1)* statement2
>
No, statement2 is not an alternative in this case. It just follows
statement1. Which is why you get the syntactic predicate ignored warning,
cause there is no need for it.

To make statement2 an alternative, write  the rule like this -




program
    :
        (DO THIS)=>  (statement1)*

        | (statement2)?
    ;

Notice the '|' operator which separates 2 alternatives.

--
Prashant Deva
Creator, ANTLR Studio
Founder, Placid Systems, www.placidsystems.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060112/40266890/attachment.html
From gcaglar at gmail.com  Wed Jan 11 23:42:55 2006
From: gcaglar at gmail.com (Gokhan Caglar)
Date: Wed Jan 11 23:42:58 2006
Subject: [antlr-interest] Syntactic predicate for single alternatives
In-Reply-To: <41fed8f80601112043q32bff883m8273b662a40e5f7@mail.gmail.com>
References: <2cc5308c0601111446m7f3963d1sc97349c75d1bf452@mail.gmail.com>
	<41fed8f80601112043q32bff883m8273b662a40e5f7@mail.gmail.com>
Message-ID: <2cc5308c0601112342w229b5a8dw9c140674417677c9@mail.gmail.com>

On 1/11/06, Prashant Deva <prashant.deva@gmail.com> wrote:
>
>
> At the program rule I think statement2 is an alternative to statement1 in
> > the following construct:  (statement1)* statement2
> >
> No, statement2 is not an alternative in this case. It just follows
> statement1. Which is why you get the syntactic predicate ignored warning,
> cause there is no need for it.
>

No it is an alternative, if it hadn't been an alternative, there would be no
ambiguity in the first place.  The parser has two alts to choose, one token
is not enough to decide.  When the k is set to 2 the ambiguity goes away.  I
am asking if there is a way to do this with a syntactic predicate and
specially handle this case?


To make statement2 an alternative, write  the rule like this -
>
>
>
>
> program
>     :
>         (DO THIS)=>  (statement1)*
>
>         | (statement2)?
>     ;
>
> Notice the '|' operator which separates 2 alternatives.
>
> --
> Prashant Deva
> Creator, ANTLR Studio
> Founder, Placid Systems, www.placidsystems.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060111/dd8192d9/attachment-0001.html
From sohail at taggedtype.net  Wed Jan 11 23:46:20 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Wed Jan 11 23:46:27 2006
Subject: [antlr-interest] Public service announcement
Message-ID: <1137051980.8141.0.camel@localhost.localdomain>

http://www.gweep.ca/~edmonds/usenet/ml-etiquette.html

:)

From dev at arabink.com  Thu Jan 12 03:02:55 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Thu Jan 12 03:03:04 2006
Subject: [antlr-interest] terminology: "protected"
Message-ID: <43C6375F.20402@arabink.com>

Hi,

I'm not sure if this is the right place for it, but here's a suggestion 
to remedy the nomenclature of "protected" rules, which, as Mr. Parr 
notes, "sucks".  Actually it doesn't seem all that sucky to me, but I 
think a better term is "splice".

Also I suggest a splop (splicing operator):  ','.  That's right, from 
our ol' pal Lisp.  For antlr, I propose that splicing means essentially 
macro expansion without tokenization.  For example,

if FOO = X Y Z then

	A ,FOO C  =>  A X Y Z C

Same result for FOO = (X Y Z); i.e. splicing "opens" a list and merges 
its contents.

Example from the Ref Man:

STRING: '"' ( ESCAPE | ~('"'|'\\') )* '"' ;

protected
ESCAPE
     :    '\\'
          ( 'n' { $setText("\n"); }
          | 'r' { $setText("\r"); }
          | 't' { $setText("\t"); }
          | '"' { $setText("\""); }
          )
     ;

This use would become simply:

STRING: '"' ( ,ESCAPE | ~('"'|'\\') )* '"' ;

which tells the reader explicitly that we're dealing with a 
non-tokenizing splice (no need to look up the defn).

The defn becomes

,ESCAPE : ...   or  splicer ESCAPE : ...   or the like.  I rather prefer 
the first alternative.

This gives us a nice metalanguage:  if

	A = B ,C D

then we can say that A _splices_ C, and _delegates to_ B and D. 
"Delegates" instead of "calls", since grammar productions are not 
functions, and it is highly desireable (IMHO) to avoid dependency on 
both implementation language (Java) and procedural language in general 
in a metalanguage for grammars.  (FWIW, this all springs from a 
nearly-complete attempt to express a kind of abstract syntax and formal 
semantics of a language corresponding to antlr and StringTemplate. 
Which e.g. removes dependency on Java, object-oriented stuff, procedural 
thinking, etc. )

This (possibly) has the additional virtue of grammatical unification, 
since the same concept and notation works for Antrl "standard" grammars 
as noted above, StringTemplates, and maybe also Tree grammars.

For templates,  "abc $foo() def" becomes "abc ,foo def", where ",foo" 
has the same meaning as above: syntactically splice (macro expand) foo 
in place.  A big win (IMO) is that this eliminates the current reliance 
of notions of function calling.  Here's an example from the ST refman:

<html>
<body>
...
$searchbox()$
...
</body>
</html>

With splop this becomes

<html>
<body>
...
,searchbox
...
</body>
</html>

Nice a clean.  No fuss no muss, and no alien notion of calling a 
function.  (Obviously more detail is required, e.g. param handling, but 
I'll save that for a page to be posted to the web soonish.  Or laterish.)

For trees its a bit hairier, since it isn't clear what it means to 
splice a subtree into a tree.  Or, the meaning isn't always intuitively 
obvious, as it is in the case of string (list) splicing.

For example, splicing into a list qua list is obvious (see Lisp), but if 
the list is construed as a tree representation, it isn't so obvious 
sometimes.  Consider

	(A ,(B C D) E)

Syntactic (lexical?) splice results in (A B C D E); simply a list merge. 
   But if these lists represent trees, such a lexical merge has the 
effect of hoisting the children of B to become its siblings.  Probably 
not the intention, or at least a violation of the Priciple of Least 
Surprise.  I haven't figured out yet exactly how splicing should be 
construed in a tree grammar.

Some other questions:  what does (A (B ,C D) E) mean?  (A ,(B ,C D) E)?

Apologies for going on so long.  I have just one more proposal:  call 
the tree grammar operator '^' the "hoisting operator", and change the 
semantics to eliminate surprises.  Specifically, scope hoisting 
semantics to the local environment by default.  E.g.

	expr MULT^ (ID EXPONENT^ expr)

should produce MULT expr (EXPONENT ID expr).  Possible objection:  what 
about ID ( PLUS^ ID )* ??  Possible answer: first, each group is matched 
in a new local environment; then, to hoist the PLUS out of the local 
scope, we simply use our new friend SPLOP:

	ID ( ,PLUS^ ID)*

The splice operator moves (hoists) PLUS outside of the local scope, and 
the hoisting op moves it to the root of its new local scope.  The parens 
ensure retain their meaning for matching purposes.  (Just an idea; I 
haven't thought it all the way through yet.)

Whew.  Rather more detail than I realized - it all seems so short and 
simple in my head.  Most of the above I've thought through and I think 
it works, but you may find some holes.  I hope somebody finds this 
interesting/useful.

Thanks for your indulgence,

gregg reynolds

P.S.  I make no claim as to the practicality of implementing the above. 
  That's what programmers are for.  ;)

P.P.S.  multitudinous thanks to the Supreme Dictator for gracing a 
heartless and indifferent world with the blessing of Antlr+ST.  My brain 
has been quite inflamed with visions of languages and grammars and such 
for the past two weeks or so - I begin to fear Human Spontaneous 
Combustion.  Not so much because Antlr+ST is useful (I do plan to use 
it), but because there's so much food for thought there - it fired my 
imagination.  (Now I've got approx 2 million ideas of which approx 9 are 
good, plus or minus 7.)  The insight that parse grammars and output 
templates are essentially the same is quite brilliant and startling (for 
me at least).  So I've begun to think about both in completely different 
(and deeper) ways thanks to Antlr+ST, which is just about the highest 
complement one can give.

But you have to come up with something better than "StringTemplate".  No 
sizzle to that at all.  Maybe "astre"?  "Another String Template $R 
Engine", where R is up to the reader - Resovler, Regurgitator, etc.  Or 
"Another String Template Rubbish Extruder"?

From mail at martin-probst.com  Thu Jan 12 03:38:37 2006
From: mail at martin-probst.com (Martin Probst)
Date: Thu Jan 12 03:38:47 2006
Subject: [antlr-interest] terminology: "protected"
In-Reply-To: <43C6375F.20402@arabink.com>
References: <43C6375F.20402@arabink.com>
Message-ID: <1137065917.10673.9.camel@localhost.localdomain>

I agree that "protected" is a bad wording, but I don't quite agree with
your splicing thing too. Basically your requiring the user to specify
within the rule that is using the "spliced" rule that the rule is
spliced. 

> which tells the reader explicitly that we're dealing with a 
> non-tokenizing splice (no need to look up the defn).

I don't see why that would be desirable. To me, a "spliced" rule is
nothing special, except that it's internal to the lexer (maybe that
would be a much nicer wording?), and cannot be directly accessed from
the parser. The calling rule doesn't care about the fact, it just says
"and at this point, I need the stuff defined in FOO".

Plus: it does not have the properties of a macro expansion, does it? And
if so: who cares? That's IMHO an implementation detail - from the
language point of view it's just a sequence of matches.

I'd propose to call those rules "internal" - as stated, they cannot be
directly accessed from outside of the Lexer (in the rule matching
meaning) and "internal" also expresses the Java protected behaviour.

Martin

From dev at arabink.com  Thu Jan 12 04:28:00 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Thu Jan 12 04:28:10 2006
Subject: [antlr-interest] terminology: "protected"
In-Reply-To: <1137065917.10673.9.camel@localhost.localdomain>
References: <43C6375F.20402@arabink.com>
	<1137065917.10673.9.camel@localhost.localdomain>
Message-ID: <43C64B50.1010207@arabink.com>

Martin Probst wrote:
> I agree that "protected" is a bad wording, but I don't quite agree with
> your splicing thing too. Basically your requiring the user to specify
> within the rule that is using the "spliced" rule that the rule is
> spliced. 

Hello Martin,

Thanks for the feedback; comments below.
> 
>>which tells the reader explicitly that we're dealing with a 
>>non-tokenizing splice (no need to look up the defn).
> 
> 
> I don't see why that would be desirable. To me, a "spliced" rule is
> nothing special, except that it's internal to the lexer (maybe that
> would be a much nicer wording?), and cannot be directly accessed from
> the parser.

I guess it depends on what you mean by "special".  If I understand antlr 
correctly, "protected" rules are not merely internal: most importantly 
"evaluation" (so to speak) works differently for spliced v. tokenizing 
rules.  Spliced rules don't tokenize.  By "tokenizing" I mean the result 
of matching the subrule is bound to a token rather than being spliced. 
So one could also specify a difference in scoping, e.g. matching of a 
tokenizing subrule occurs in a local scope, whereas a spliced subrule is 
matched in the scope of the rule that does the splicing.

This is basically a variation on how macros and splicing works in 
Lisp/Scheme, which is why it is so useful.  Much of its usefulness is 
simply that it makes the language more expressive.

In fact, with splicing notation, we could allow a rule to be both 
tokenizing and non-tokenizing.  E.g.

	,A = ....  // splicing (non-tokenizing) and internal only
	FOO = (X Y Z)  // bisemous(?): hoisted to nextToken, but may be spliced too
	BAR = B FOO C    // delegation to tokenizing rule FOO
	BAZ = I ,FOO J   // splice non-tokenizing FOO
	BUZ = Q A R	// error? delegation to splice-only rule

  The calling rule doesn't care about the fact, it just says
> "and at this point, I need the stuff defined in FOO".

It makes a difference whether or not "the stuff defined in FOO" is 
"tokenized" or spliced.  That's why IMO an explicit splicing operator is 
a good thing.  It allows the designer a degree of control over 
tokenizing, and it helps the reader understand the intention of the writer.

> 
> Plus: it does not have the properties of a macro expansion, does it? And
> if so: who cares? That's IMHO an implementation detail - from the
> language point of view it's just a sequence of matches.

Well, my thinking about "splice" and "macro" is inspired by scheme, but 
isn't quite the same.  I think of splicing in antlr ("calling" a 
protected subtemplate) as equivalent to referencing a #defined 
identifier in C.  (This may not be entirely accurate, but it's my 
understanding of the 2.7.5 documentation.)  There's a big difference 
indeed between expanding a macro and evaluation an expression.  If you 
splice a rule (expand a macro), you first construct the text by merging 
(a purely syntactic operation, no matching/eval/etc.), and the result is 
another piece of grammar to be matched.  But if you delegate, you first 
do the matches (in a new local scope), then tokenize the result (bind it 
to a single token) which is inserted.  So the components are *not* 
inserted into the syntax.

In a word, you end up with different token structures depending on 
whether you splice or delegate.  At least that's the idea.

> 
> I'd propose to call those rules "internal" - as stated, they cannot be
> directly accessed from outside of the Lexer (in the rule matching
> meaning) and "internal" also expresses the Java protected behaviour.

Internal/external, hidden/exposed, etc. - that's all distinct from the 
core issue of splicing v. tokenizing, no?  Which might be construed more 
usefully as syntactic v. semantic splicing.  I suppose one might argue 
that the internal/external distinction is itself an irrelevant 
implementation detail - what counts is tokenizing.

Thanks,

gregg
From mail at martin-probst.com  Thu Jan 12 04:53:01 2006
From: mail at martin-probst.com (Martin Probst)
Date: Thu Jan 12 04:53:09 2006
Subject: [antlr-interest] terminology: "protected"
In-Reply-To: <43C64B50.1010207@arabink.com>
References: <43C6375F.20402@arabink.com>
	<1137065917.10673.9.camel@localhost.localdomain>
	<43C64B50.1010207@arabink.com>
Message-ID: <1137070381.10673.25.camel@localhost.localdomain>



> There's a big difference 
> indeed between expanding a macro and evaluation an expression.  If you 
> splice a rule (expand a macro), you first construct the text by merging 
> (a purely syntactic operation, no matching/eval/etc.), and the result is 
> another piece of grammar to be matched.  But if you delegate, you first 
> do the matches (in a new local scope), then tokenize the result (bind it 
> to a single token) which is inserted.  So the components are *not* 
> inserted into the syntax.
> 
> In a word, you end up with different token structures depending on 
> whether you splice or delegate.  At least that's the idea.

Just an example:
FOO: "abc" BAR;
BAR: "def";

vs.

FOO: "abc" BAR;
protected BAR: "def";

vs.

FOO: "abc" "def";
(protected) BAR: "def";

All of these will currently result in a single FOO token containing
"abcdef" on input "abcdef". There is no observable difference to the
user, except for non-determinism problems if something else than BAR can
match "def".

> But if you delegate, you first 
> do the matches (in a new local scope), then tokenize the result (bind it 
> to a single token) which is inserted.  So the components are *not* 
> inserted into the syntax.

As far as I know if you "delegate", e.g. do not have a protected rule,
it does not return a Token instead of a String or something - there is
also no (Java) implementation difference, but that should not matter to
the user anyways.

I'm not sure what you're referring to with local scope, but if mean that
a "spliced" rule should be able to access stuff from the scope of the
"calling" rule, then this is -sorry- pure madness. Macros are evil! A
single "," operator that changes the semantic meanings of the access to
scopes is just completely confusing and does not have any reasonable
use. You actually have (protected/internal/sub)rules so you can separate
your code, not so you can mix it all together and have scope accesses
from the other end of the source file.

> > I'd propose to call those rules "internal" - as stated, they cannot be
> > directly accessed from outside of the Lexer (in the rule matching
> > meaning) and "internal" also expresses the Java protected behaviour.
> 
> Internal/external, hidden/exposed, etc. - that's all distinct from the 
> core issue of splicing v. tokenizing, no?

Well, I'm arguing that there is no splicing issue, just an
internal/external issue.

>   Which might be construed more 
> usefully as syntactic v. semantic splicing.  I suppose one might argue 
> that the internal/external distinction is itself an irrelevant 
> implementation detail - what counts is tokenizing.

Internal vs. External has a huge impact, e.g.
FOO: "abc" BAR;
BAR: "def";
BAZ: "def";
does not work, as BAR and BAZ are identical. Add "protected" or
"internal" or whatever to BAR, and it will work. The example is a bit
contrived, but you get the idea.

Regards,
Martin

PS: can you use another word for what you call "tokenize"? I think it's
reserved for the process of splitting an input up into several Tokens,
e.g. what the Lexer does.


From dev at arabink.com  Thu Jan 12 07:17:33 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Thu Jan 12 07:17:42 2006
Subject: [antlr-interest] terminology: "protected"
In-Reply-To: <1137070381.10673.25.camel@localhost.localdomain>
References: <43C6375F.20402@arabink.com>	
	<1137065917.10673.9.camel@localhost.localdomain>	
	<43C64B50.1010207@arabink.com>
	<1137070381.10673.25.camel@localhost.localdomain>
Message-ID: <43C6730D.6060407@arabink.com>

Martin Probst wrote:
> 
...
> 
> Just an example:
> FOO: "abc" BAR;
> BAR: "def";
> 
> vs.
> 
> FOO: "abc" BAR;
> protected BAR: "def";
> 
> vs.
> 
> FOO: "abc" "def";
> (protected) BAR: "def";
> 
> All of these will currently result in a single FOO token containing
> "abcdef" on input "abcdef". There is no observable difference to the
> user, except for non-determinism problems if something else than BAR can
> match "def".
> 

Yes, but what if you want to mess about with (sub) matched elements 
within a rule action?  With A : B C you can reference B and C, even if 
they have a internal (sub) structure.  But with A : ,B C you can't 
reference B, only its "contents".  Can A's action reference names in B 
or C?  Or only the names 'B' and 'C'?  Which is to say that in a sense 
its all about naming.

(At this point I guess I should remind you that this design emerged from 
my thinking about a more general parser/template language, and may or 
may not clash with the antlr implementation.  But I think the language 
and concept present at least an interesting possibility for Antlr.)

> 
>>But if you delegate, you first 
>>do the matches (in a new local scope), then tokenize the result (bind it 
>>to a single token) which is inserted.  So the components are *not* 
>>inserted into the syntax.
> 
> 
> As far as I know if you "delegate", e.g. do not have a protected rule,
> it does not return a Token instead of a String or something - there is
> also no (Java) implementation difference, but that should not matter to
> the user anyways.
> 
See the article on protected rules at 
http://www.jguru.com/faq/view.jsp?EID=125:  "...'You get a Token object 
for every lexical rule in your lexer grammar.' This is indeed the 
default case for ANTLR's lexer grammars... To distinguish these "helper" 
rules from rules that result in tokens, use the protected modifier."

Mr. Parr chose "protected" by analogy: it controls access visibility in 
Java, and in Antlr "helper" rules (protected ones) are not "seen" by the 
parser - they don't get "hoisted" into the nextToken logic.  That may be 
true, but I argue that it's not what really counts.  It's the token 
binding that matters.

Unfortunately, in the same article is the statements "I now recognize 
this approach is a mistake.  I have a number of proposals to fix 
this..."  So maybe version 3 does something completely different; I 
haven't had time to look at v3.

And later:  "By definition, all lexical rules return Token objects 
(ANTLR optimizes away many of these object creations, however), but only 
the Token objects of non-protected rules get pulled out of the lexer 
itself."  I.e. lexer and parser stuff is treated differently?  I'm not 
sure of the exact implications of this, but it seems to me that 
"splicing" captures the same idea (or addresses the same issue).

(I saw your note below about using "tokenizing" in this sense.  I agree, 
it isn't the right term for my meaning.  Until I can think of better 
metalanguage, I'll surrender and say "non-splicing rule" instead of 
"tokenizing rule".  ;)


> I'm not sure what you're referring to with local scope, but if mean that
> a "spliced" rule should be able to access stuff from the scope of the
> "calling" rule, then this is -sorry- pure madness. Macros are evil! A

Right, I agree with that.  The question being "Can an action attached to 
a spliced rule make reference to anything outside of the spliced rule 
itself?", right?  Well now, that's kind of interesting, since ordinary 
macros in other languages don't consist of a pair of (rule, action).  So 
what is the naturally intuitive way to interpret a spliced rule with 
actions attached?  To me it is: splice the rule's grammar production 
syntactically but still restrict the action to the local scope (the one 
in which the action is defined).  In other words, scope things exactly 
the same way as with non-spliced rules, but then "unpack" the list of 
matches and insert them into the splicing ("calling") rule.

>>
>>Internal/external, hidden/exposed, etc. - that's all distinct from the 
>>core issue of splicing v. tokenizing, no?
> 
> Well, I'm arguing that there is no splicing issue, just an
> internal/external issue.
..
> 
> 
>>  Which might be construed more 
>>usefully as syntactic v. semantic splicing.  I suppose one might argue 
>>that the internal/external distinction is itself an irrelevant 
>>implementation detail - what counts is tokenizing.
> 
> 
> Internal vs. External has a huge impact, e.g.
> FOO: "abc" BAR;
> BAR: "def";
> BAZ: "def";
> does not work, as BAR and BAZ are identical.
  Add "protected" or
> "internal" or whatever to BAR, and it will work. The example is a bit
> contrived, but you get the idea.

Ok, agreed.  So as I see it, there are two (orthogonal?) issues: 1) how 
to specify that a rule is not to be included in the top-level nextToken 
logic (ie. is protected/inner/hidden/etc.); and 2) how to indicate that 
a reference to a rule should be either replaced by the rule grammar text 
(spliced), or bound to a structure of tokens (terminology to be determined.)

For (1), I agree we need a decoration of some kind on the name 
definition.  I rather like "hidden", but there might be something 
better.  Note that a "hidden" rule need not be used for splicing. For 
(2), the splice operator allows the client rule to control the 
tokenizing of the referenced rule, i.e. whether it's results are bound 
to the reference name.

In any case, thanks very much for the feedback - you've given me lots to 
think about.  I expect to write up something more formal about all this 
stuff before too long.   There are other aspects of subtemplate 
referencing that I haven't addressed, most obviously passing parameters. 
  That I construe as a renaming operation - function calling without the 
function call; and once you have the logic and syntax for renaming, you 
get very powerful template reuse capabilities.

BTW, don't forget that part of the motivation is to unify the language 
across Antlr grammars and StringTemplate, and part is to remove 
programmer-speak from the language definition.  The notion of splicing 
works quite well in ST, and eliminates the need for method call syntax:

"foo $bar()$ baz" becomes "foo ,bar baz".

And since parse grammars and output templates are fundamentally the same 
animal - grammars - we should be able to use the same operations and 
symbols in each.

cheers,

gregg
From antlr at jazillian.com  Thu Jan 12 07:33:32 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Thu Jan 12 07:33:37 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C57E11.5080007@arabink.com>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com> <43C57E11.5080007@arabink.com>
Message-ID: <43C676CC.4030905@jazillian.com>



Gregg Reynolds wrote:

>
> Ok, syntactically, maybe the backend code is mixed up.  But 
> conceptually?  After all, what is the difference between many-one and 
> many one-one, rilly?

I would say that today, Jazillian is just a single one-to-one. There is 
no real "frontend" that could be switched out to handle a different
input language, or a "backend" where there's an ability to add 
additional backends to produce multiple output languages. I guess the only
way this is pertinent is that I'm taking buying what the StringTemplate 
article seems (to me) to be selling: that StringTemplate
can be an effective "backend". ANTLR may be able to use it that way,  I 
don't think Jazillian could use it to, say, output
C# in addition to Java. Not without major changes to the Jazillian 
engine itself.

>
>>
>>>
>>> So if it is a problem for Antlr, it is the same problem for 
>>> Jazillion or any other code xformer, regardless of implementation 
>>> technique.
>>
>>
>>
>> I do agree that (and I'm not sure if this is your point or not) ANTLR 
>> and Jazillian seem like they should both be designed the same way.
>
>
> Not at all, I'm only trying abstract in order to find the gist nut of 
> the problem.  After all, if you went to the trouble of trying antlr 
> and finding it lacking, there's something there, there.

Just to be clear: I love ANTLR for lexing and parsing, just not 
treewalking. Even for something that treewalking is best at: 
pretty-printing code,
I prefer to walk the tree "by hand" rather than use a treewalker. And 
(here's my whole point) I don't think treewalking is a good match for
something like a C-to-Java translator at all.

>
>
>>
>>> Nobody considers the machine code emitted by a compiler to be a 
>>> "view" of the source code.)
>>
>>
>>
>> Ah, but they do. I do, and  that's exactly what Terence is saying in 
>> the StringTemplate article...that the target Java, python, and bytecode
>> are simple three slightly different "views" of the output. I agree 
>> with that.
>>
>
> Well, you're a special case so we get to remove you from the sample.  ;)
>
> But the article was about a straightforward source to source 
> transformation - not machine code generation (Java byte code is not 
> machine code).  I wonder if you and/or Mr. Parr really think of 
> compiled code - machine code - as a "view" of the source.  Ordinarily 
> I mean - of course one can talk about it that way for special purposes.

Well, I'm the pessimist. I don't think you can even separate "the view" 
in the case of high-level languages. I'm not buying the "StringTemplate lets
you produce Java, C++, and bytecode all from one engine" theme of the 
StringTemplate article. So I obviously don't think it would work
for generating machine code either. Again, it ST great for the simple 
examples given, and so I tried to outline the real-world problems
that ST won't be able to solve. And those real-world problems would 
become huge if you tried to use ST to generate machine code.

>
>>>
>>> The real question is not separation of m v and c, but of the 
>>> *genericity* (adaptability, flexibility, whatever) of the "service": 
>>> given a parser generator, is its backend architecture general enough 
>>> to make it easy to write specialized emitters?  Given a language 
>>> transformer (e.g. Jazillion), is its frontend architecture general 
>>> enough to make it easy to specialize it for a variety of input 
>>> languages?
>>
>>
>>
>> In my case, I haven't cared too much (yet) that the frontend by able 
>> to handle multiple input languages (or that the backend be able
>> to output multiple languages for that matter). Just a single 
>> C-to-Java translator is hard enough, and I've been happy to spend 3 
>> years full time
>> thinking about all the ways to do that really well, rather than 
>> expanding my scope. Having said that, I'm now working on C++ to Java, 
>> though :)
>>
>>>
>>> More specifically:  how hard would it be to write an ML or Haskell 
>>> emitter for Antlr (something I'd like to see)?
>>
>>
>>
>> Good question, and my related question is "will StringTemplate make 
>> that any easier?".
>
>
> For the actual text generation, yes (I think); but that has nothing to 
> do with target v. source driven transformation strategies.

Right, so what I'm trying to say is getting clearer as I read more :)
I have to objections: one is the "target vs. source " (or, I prefer "AST 
walking vs. rule-based") architecture.
The second is the ability for ST to really add value (or scale) beyond 
things like producing C++/Java/C# output for ANTLR.

> [snip]


> Yep.  Although I daresay it depends on which language one is most 
> comfortable with.  In lisp dialects it's pretty straightforward to 
> thing in terms of something more treelike.  Then again, given the 
> mainstream resistance to all those parentheses...

After a year of LISP as an undergrad, I had trouble getting out of the 
LISP mindset.
Just kept thinking "Today is the first day of the rest of my life!"

>
>>
>> Avoiding mental pictures of AST trees altogether is just a HUGE 
>> productivity boost, at least for me.
>> I'd say I'm at least twice as productive in writing rules (both 
>> simple text-replacement ones and
>> complex ones written in Java code), and probably more like 5-10x more 
>> productive
>> by largely ignoring AST structures.
>
>
> That's interesting.  Can't argue with experience.  I suggest we cadge 
> a few million bucks out of the DOD to do a study.

Problem is, we all have different experiences. I think there are 3 major 
things coming into play here.
First is intelligence. Some people are so smart that they don't see the 
uglyness of code that the rest of us do, because
the code looks straightforward to them.
Second is experience. Obviously, someone who knows ANLTR really well is 
not thrown off by a mix of ANTLR and Java code.
Third is mindset.
<rant>
People in the compiler crowd tend to enjoy playing with symbols and 
languages. They enjoy discussing
the merits of various syntax issues and enjoy learning new languages. 
But there are those of us who want to build
real-world apps and use language tools, but just aren't into debating 
whether to use a '[' or a '{' at some point
and aren't smart enough or knowledgable enough to know how to convert a 
a NFA to a DFA. We've got our
BSCS and MSCS degrees and 20 years of development experience - we're not 
newbies. It's just that it can take
some work for us to see the benefits of a tool like ST or an approach 
like treewalking

</rant>
Andy

>
> -gregg
>
From antlr at jazillian.com  Thu Jan 12 07:43:01 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Thu Jan 12 07:43:06 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <54345.127.0.0.1.1137016607.squirrel@taggedtype.net>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com>
	<54345.127.0.0.1.1137016607.squirrel@taggedtype.net>
Message-ID: <43C67905.3060802@jazillian.com>



sohail@taggedtype.net wrote:

>>Gregg Reynolds wrote:
>>
>>    
>>
>>>Andy Tripp wrote:
>>>More specifically:  how hard would it be to write an ML or Haskell
>>>emitter for Antlr (something I'd like to see)?
>>>      
>>>
>>Good question, and my related question is "will StringTemplate make that
>>any easier?".
>>    
>>
>
>Now you're just being mean. This is as big a difference as generating code
>for a stack based machine when your AST assumes a register based machine
>(like gcc). This is an analogy for functional languages and imperative
>languages like C++ or Java. Therefore, you might need to tweak your AST
>(but then again, you might not!)
>  
>
I'm not following you exactly, but I think it's a reasonable question. I 
don't buy that I could, for example,
use StringTemplate to output C# instead of Java, without major changes 
to my code. I don't think
ANTLR could output MS or Haskell (or Lisp) without major changes. ST is 
not fullfilling the
"separate your view from your translation" promise in any cases other 
than the most trivial, contrived cases
(or when the output languages are so similar as C++/Java/C# and the 
domain is so limited as in the case
of all the code that ANTLR spits out).

>  
>
>>>How hard would it be to write an ML or Haskell front-end for
>>>Jazillion?  (I mean relative to a C frontend, not relative to a
>>>backend to Antlr, which would no doubt be easier.)
>>>      
>>>
>>Answer: very hard: the translation rules are all C-specific. To put it
>>bluntly, the Jazillian "front-end" is not in any way separated from the
>>"engine"
>>and "backend". I believe it's impossible to design such a
>>any-language-to-any-language translation engine, despite the fact that
>>Semantic Designs claims to have such a product.
>>    
>>
>
>With some constraints, I think this is possible.
>  
>

OK then, what is the Java equivalent of "memset (111, 222, 333);"?
 I suppose that's a constraint :)

>  
>
>>brain has already tokenized it into a sequence of 5 tokens:
>>int [ ] i ;
>>But given that same chunk of code, our brains to NOT easily form an AST
>>structure:
>>    
>>
>
>I think some people do. Thats why lisp is so easy to read. For those :)
>  
>
I'm not sure if you're joking here or not. I sure hope you are.
If not, try looking at 20 lines of Lisp without "cheating"...without any 
indentation.
Besides, Lisp source maps one-to-one to its AST structure. Barely any 
parser needed.
C, Java, C#, etc. source doesn't look much like it's AST structure at all.
From gcaglar at gmail.com  Thu Jan 12 10:32:50 2006
From: gcaglar at gmail.com (Gokhan Caglar)
Date: Thu Jan 12 10:32:54 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <1137051980.8141.0.camel@localhost.localdomain>
References: <1137051980.8141.0.camel@localhost.localdomain>
Message-ID: <2cc5308c0601121032u2cca53f8nb5e0dc1e270710af@mail.gmail.com>

On 1/11/06, Sohail Somani <sohail@taggedtype.net> wrote:
>
> http://www.gweep.ca/~edmonds/usenet/ml-etiquette.html
>
> :)
>
>
 If this is regarding me, I'm sorry, I didn't mean to be mean.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060112/6ecb902c/attachment.html
From antlr at jazillian.com  Thu Jan 12 10:51:40 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Thu Jan 12 10:51:43 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <2cc5308c0601121032u2cca53f8nb5e0dc1e270710af@mail.gmail.com>
References: <1137051980.8141.0.camel@localhost.localdomain>
	<2cc5308c0601121032u2cca53f8nb5e0dc1e270710af@mail.gmail.com>
Message-ID: <43C6A53C.40808@jazillian.com>

Gokhan Caglar wrote:

>
> On 1/11/06, *Sohail Somani* <sohail@taggedtype.net 
> <mailto:sohail@taggedtype.net>> wrote:
>
>     http://www.gweep.ca/~edmonds/usenet/ml-etiquette.html
>     <http://www.gweep.ca/%7Eedmonds/usenet/ml-etiquette.html>
>
>     :)
>
>
>  If this is regarding me, I'm sorry, I didn't mean to be mean.

No, I think it's directed at me. I finally set up an email client for 
the antlr-interest mailing list,
so my responses should appear in the proper thread now.

Anyone know what cleverness pipermail/mailman is using to figure out 
thread hierarchy?
Must be another one of those things that's obvious to everyone but me :)
Andy

From brannonking at yahoo.com  Thu Jan 12 11:01:10 2006
From: brannonking at yahoo.com (Brannon King)
Date: Thu Jan 12 11:00:48 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <2cc5308c0601121032u2cca53f8nb5e0dc1e270710af@mail.gmail.com>
Message-ID: <000c01c617aa$8e3c1820$8a0a0a0a@starbridgesystems.com>

>>	http://www.gweep.ca/~edmonds/usenet/ml-etiquette.html
> If this is regarding me, I'm sorry, I didn't mean to be mean. 

I think it was referring to the fact that that the post was in html. I made
the same mistake the other day. It's just hard to remember to switch the
email tool to text mode when sending to a newsgroup.

From antlr at fatboycentral.com  Thu Jan 12 11:07:58 2006
From: antlr at fatboycentral.com (Mike Matera)
Date: Thu Jan 12 11:08:03 2006
Subject: [antlr-interest] Problems with x86_64 compile.
Message-ID: <40ddc4e40601121107x6cf483d5g5ab3803fc1c86c25@mail.gmail.com>

Hi,

I have not been able to sucessfully use ANTLR (c++ mode) on my x86_64
machine when it is natively compiled.  A 32-bit binary works fine.  The
symptom is:

Given this lexer rule:

STRING_LIT
  : '"'! ( '"' '"'! | ~('"'|'\n'|'\r') )*
  ( '"'!
  | // nothing -- write error message
  )
  ;

Given this input (quotes are included in the input):

"sleep"

The following error is generated:

(After getting an antlr::TokenStreamRecognitionException)
line 1:18: unexpected char: 's'

After further investigation I discovered that I am not able to use wildcards
at all.  They seem to match nothing.  I suspect this is a 64bit issue.  I
will do further investigation into the cause, but wanted to bring up this
issue in case anyone has seen it before.  Also I'm pretty new to ANTLR (and
love it) so it'll take me some time to slog through the code before I'm able
to make much sense of it.

Cheers
./m
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060112/8dea39ff/attachment.html
From kroepke at dolphin-services.de  Thu Jan 12 11:29:08 2006
From: kroepke at dolphin-services.de (Kay Roepke)
Date: Thu Jan 12 11:29:14 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <000c01c617aa$8e3c1820$8a0a0a0a@starbridgesystems.com>
References: <000c01c617aa$8e3c1820$8a0a0a0a@starbridgesystems.com>
Message-ID: <399FA790-6CE8-4E11-8D69-10A7C862CAD1@dolphin-services.de>


On 12. Jan 2006, at 20:01 Uhr, Brannon King wrote:

> It's just hard to remember to switch the
> email tool to text mode when sending to a newsgroup.

To take this futher off-topic, I'd recommend one (or better yet,  
both) of two things:
1) always send plain-text messages
2) let your mailer automagically choose to display the plain-text  
alternative of the message

Kay
From sohail at taggedtype.net  Thu Jan 12 11:50:08 2006
From: sohail at taggedtype.net (sohail@taggedtype.net)
Date: Thu Jan 12 11:50:18 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C67905.3060802@jazillian.com>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com> 
	<43C557BB.9080706@jazillian.com>
	<54345.127.0.0.1.1137016607.squirrel@taggedtype.net>
	<43C67905.3060802@jazillian.com>
Message-ID: <37207.127.0.0.1.1137095408.squirrel@taggedtype.net>

> OK then, what is the Java equivalent of "memset (111, 222, 333);"?
>  I suppose that's a constraint :)

Your AST would either assume that all targets know about pointers or they
don't. In which case the AST would have a lower level representation.

> I'm not sure if you're joking here or not. I sure hope you are.
> If not, try looking at 20 lines of Lisp without "cheating"...without any
> indentation.

Why? I'm not a compiler. Try looking at 20 lines of C++ without any
indentation or line breaks.
From kroepke at dolphin-services.de  Thu Jan 12 13:39:39 2006
From: kroepke at dolphin-services.de (Kay Roepke)
Date: Thu Jan 12 13:39:48 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C67905.3060802@jazillian.com>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com>
	<54345.127.0.0.1.1137016607.squirrel@taggedtype.net>
	<43C67905.3060802@jazillian.com>
Message-ID: <A1968A5F-8BD3-463C-8A66-9DAC73189B08@dolphin-services.de>


On 12. Jan 2006, at 16:43 Uhr, Andy Tripp wrote:

> I'm not following you exactly, but I think it's a reasonable  
> question. I don't buy that I could, for example,
> use StringTemplate to output C# instead of Java, without major  
> changes to my code. I don't think
> ANTLR could output MS or Haskell (or Lisp) without major changes.  
> ST is not fullfilling the
> "separate your view from your translation" promise in any cases  
> other than the most trivial, contrived cases
> (or when the output languages are so similar as C++/Java/C# and the  
> domain is so limited as in the case
> of all the code that ANTLR spits out).

Chiming in late, but I have one remark to make:
ST isn't the view! It certainly is part of the view, but it's not the  
entire view. The code generator is the view.
ST simply gets rid of all those prints in your code and puts the  
parameterized text into one place. I personally have
used and written template systems (engines, whatever) for a few years  
now, and am very pleased with the approach.
If I understand your approach correctly, it seems to me that your  
"patterns" are some kind of templates, too.
To me they look like mini-grammars (sorry for that ;)) with  
integrated templates (the RHS of the '-->').
The v's and x's are template variables and the rest of the text is  
copied verbatim. Are there any control structures
you use?

Regards,

Kay
From brannonking at yahoo.com  Thu Jan 12 13:56:39 2006
From: brannonking at yahoo.com (Brannon King)
Date: Thu Jan 12 13:56:21 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <43C6A53C.40808@jazillian.com>
Message-ID: <001401c617c3$120029e0$8a0a0a0a@starbridgesystems.com>

The hierarchy uses some headers that not all mail servers support. It didn't
work with my Exchange 2003 service through etgroup.net. However, the Yahoo
SMTP seems to have no problem with it, and I'm accessing that account
through Outlook2003 so I know it's not an Outlook issue.

>Anyone know what cleverness pipermail/mailman is using to figure out thread
hierarchy?
>Must be another one of those things that's obvious to everyone but me :)
Andy

From scott at javadude.com  Thu Jan 12 16:59:04 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Thu Jan 12 16:59:14 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <399FA790-6CE8-4E11-8D69-10A7C862CAD1@dolphin-services.de>
Message-ID: <200601130043.k0D0hEBm007880@s2.eroute.net>

Can't the server just convert html messages to plain text for those who are
current-technology-impaired and insist on using dinosaur tools?

-- Scott

> -----Original Message-----
> From: antlr-interest-bounces@antlr.org 
> [mailto:antlr-interest-bounces@antlr.org] On Behalf Of Kay Roepke
> Sent: Thursday, January 12, 2006 2:29 PM
> To: Brannon King
> Cc: 'antlr-interest'
> Subject: Re: [antlr-interest] Public service announcement
> 
> 
> On 12. Jan 2006, at 20:01 Uhr, Brannon King wrote:
> 
> > It's just hard to remember to switch the email tool to text 
> mode when 
> > sending to a newsgroup.
> 
> To take this futher off-topic, I'd recommend one (or better yet,
> both) of two things:
> 1) always send plain-text messages
> 2) let your mailer automagically choose to display the 
> plain-text alternative of the message
> 
> Kay
> 


From kroepke at dolphin-services.de  Thu Jan 12 17:15:45 2006
From: kroepke at dolphin-services.de (Kay Roepke)
Date: Thu Jan 12 17:15:52 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <200601130043.k0D0hEBm007880@s2.eroute.net>
References: <200601130043.k0D0hEBm007880@s2.eroute.net>
Message-ID: <0ED53AD1-48F3-426A-AA5A-D5FDAD75C93E@dolphin-services.de>


On 13. Jan 2006, at 1:59 Uhr, Scott Stanchfield wrote:

> Can't the server just convert html messages to plain text for those  
> who are
> current-technology-impaired and insist on using dinosaur tools?

I'd rather not want the mail server to mess with my mail's body's...
Surely your 'dinosaur' knows about message-parts? if not you might  
wanna think about
why the dinosaurs are now extinct? ;)

-k
From matthew.ford at forward.com.au  Thu Jan 12 18:05:39 2006
From: matthew.ford at forward.com.au (Matthew Ford)
Date: Thu Jan 12 18:05:46 2006
Subject: [antlr-interest] Public service announcement
References: <200601130043.k0D0hEBm007880@s2.eroute.net>
	<0ED53AD1-48F3-426A-AA5A-D5FDAD75C93E@dolphin-services.de>
Message-ID: <000e01c617e5$da8d49c0$0200a8c0@notebook>

Html is much more dangerous than plain text.

----- Original Message ----- 
From: "Kay Roepke" <kroepke@dolphin-services.de>
To: "Scott Stanchfield" <scott@javadude.com>
Cc: "'antlr-interest'" <antlr-interest@antlr.org>
Sent: Friday, January 13, 2006 12:15 PM
Subject: Re: [antlr-interest] Public service announcement


> 
> On 13. Jan 2006, at 1:59 Uhr, Scott Stanchfield wrote:
> 
> > Can't the server just convert html messages to plain text for those  
> > who are
> > current-technology-impaired and insist on using dinosaur tools?
> 
> I'd rather not want the mail server to mess with my mail's body's...
> Surely your 'dinosaur' knows about message-parts? if not you might  
> wanna think about
> why the dinosaurs are now extinct? ;)
> 
> -k
> 
From kroepke at dolphin-services.de  Thu Jan 12 18:09:12 2006
From: kroepke at dolphin-services.de (Kay Roepke)
Date: Thu Jan 12 18:09:16 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <000e01c617e5$da8d49c0$0200a8c0@notebook>
References: <200601130043.k0D0hEBm007880@s2.eroute.net>
	<0ED53AD1-48F3-426A-AA5A-D5FDAD75C93E@dolphin-services.de>
	<000e01c617e5$da8d49c0$0200a8c0@notebook>
Message-ID: <B13FA550-5E18-476C-81D6-E9CCB9CD9BAE@dolphin-services.de>


On 13. Jan 2006, at 3:05 Uhr, Matthew Ford wrote:

> Html is much more dangerous than plain text.

huh?
From scott at javadude.com  Thu Jan 12 19:56:12 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Thu Jan 12 19:56:25 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <B13FA550-5E18-476C-81D6-E9CCB9CD9BAE@dolphin-services.de>
Message-ID: <200601130340.k0D3eLFC011484@s2.eroute.net>

only if you have a client that doesn't block executables

move out of the stone age, folks
-- Scott 

> -----Original Message-----
> From: antlr-interest-bounces@antlr.org 
> [mailto:antlr-interest-bounces@antlr.org] On Behalf Of Kay Roepke
> Sent: Thursday, January 12, 2006 9:09 PM
> To: Matthew Ford
> Cc: 'antlr-interest'
> Subject: Re: [antlr-interest] Public service announcement
> 
> 
> On 13. Jan 2006, at 3:05 Uhr, Matthew Ford wrote:
> 
> > Html is much more dangerous than plain text.
> 
> huh?
> 


From parrt at cs.usfca.edu  Thu Jan 12 19:59:08 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Thu Jan 12 19:59:11 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <200601130340.k0D3eLFC011484@s2.eroute.net>
References: <200601130340.k0D3eLFC011484@s2.eroute.net>
Message-ID: <C976E15E-A5A4-433A-9CCB-361C68C056FD@cs.usfca.edu>

I hereby request that this thread terminate before it explodes ;)

Ter
From sohail at taggedtype.net  Thu Jan 12 21:09:42 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Thu Jan 12 21:09:50 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <000c01c617aa$8e3c1820$8a0a0a0a@starbridgesystems.com>
References: <000c01c617aa$8e3c1820$8a0a0a0a@starbridgesystems.com>
Message-ID: <1137128983.9169.1.camel@localhost.localdomain>

On Thu, 2006-01-12 at 12:01 -0700, Brannon King wrote:
> >>	http://www.gweep.ca/~edmonds/usenet/ml-etiquette.html
> > If this is regarding me, I'm sorry, I didn't mean to be mean. 
> 
> I think it was referring to the fact that that the post was in html. I made
> the same mistake the other day. It's just hard to remember to switch the
> email tool to text mode when sending to a newsgroup.

Atleast if you're posting in html, don't make it suck. Use proper
colouring for the quoted text or something.

The good thing about plain text is there is no formatting and so it
doesn't look too fugly. Its not about being a dinosaur or whatever else
people have been saying.

From parrt at cs.usfca.edu  Thu Jan 12 21:12:44 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Thu Jan 12 21:12:48 2006
Subject: [antlr-interest] Public service announcement
In-Reply-To: <1137128983.9169.1.camel@localhost.localdomain>
References: <000c01c617aa$8e3c1820$8a0a0a0a@starbridgesystems.com>
	<1137128983.9169.1.camel@localhost.localdomain>
Message-ID: <8ADBEF92-412E-4B3B-AACE-1D961276667D@cs.usfca.edu>

This thread is done me thinks.
Thanks,
Terence
From Oliver.Kowalke at infineon.com  Thu Jan 12 23:07:16 2006
From: Oliver.Kowalke at infineon.com (Oliver.Kowalke@infineon.com)
Date: Thu Jan 12 23:07:20 2006
Subject: [antlr-interest] optimization of output language - reducing
	redundant information?
Message-ID: <7509DD89A305F34E9EF16F1EEDFB80AF0176DE36@drsse401.eu.infineon.com>

Hello,
I have a parse (with AST) which translates from a own-defined language
to SQL (WHERE-clause for a special database model):

'X' :-> A = 1 AND B = 2
'Y' :-> A = 1 AND C = 'abc'

'X && Y' :-> A = 1 AND B = 2 AND A = 1 AND C = 'abc'
'X || Y' :-> A = 1 AND B = 2 OR A = 1 AND C = 'abc'

A = 1 is redundant (occurs two times). After reducing redundant
information the SQL-WHERE-clause would look like:

'X && Y' :-> A = 1 AND B = 2 AND C = 'abc'
'X || Y' :-> A = 1 AND (B = 2 OR C = 'abc')

How can I achieve such a reduction?
Should I use a two-step approach using an intermediate language?

With best regards,
Oliver
From ric.klaren at gmail.com  Fri Jan 13 00:31:57 2006
From: ric.klaren at gmail.com (Ric Klaren)
Date: Fri Jan 13 00:32:02 2006
Subject: [antlr-interest] Problems with x86_64 compile.
In-Reply-To: <40ddc4e40601121107x6cf483d5g5ab3803fc1c86c25@mail.gmail.com>
References: <40ddc4e40601121107x6cf483d5g5ab3803fc1c86c25@mail.gmail.com>
Message-ID: <bc607a4e0601130031p5358dc66k51017e33930ecac1@mail.gmail.com>

Hi,

Didn't run into 64 bit issues with antlr so far (x86_64, fedora 4).
Could you provide some additional information? GCC version and antlr
version ?


On 1/12/06, Mike Matera <antlr@fatboycentral.com> wrote:
> I have not been able to sucessfully use ANTLR (c++ mode) on my x86_64
> machine when it is natively compiled.  A 32-bit binary works fine.  The
> symptom is:
>
> Given this lexer rule:
>
> STRING_LIT
>   : '"'! ( '"' '"'! | ~('"'|'\n'|'\r') )*
>   ( '"'!
>   | // nothing -- write error message
>   )
>   ;
>
> Given this input (quotes are included in the input):
>
> "sleep"
>
> The following error is generated:
>
> (After getting an antlr::TokenStreamRecognitionException)
> line 1:18: unexpected char: 's'

You have set the charVocabulary option?
http://www.antlr.org/doc/options.html#_bb14

Without it the ~ operator does not work as expected.

Cheers,

Ric
From gabriel.adrian.radu at googlemail.com  Fri Jan 13 02:51:51 2006
From: gabriel.adrian.radu at googlemail.com (Gabriel Radu)
Date: Fri Jan 13 02:51:54 2006
Subject: [antlr-interest] Lexical nondeterminism
In-Reply-To: <E1EwkWm-0000ZQ-00@gecko>
References: <67e2ed240601110617l76a741cg@mail.gmail.com>
	<E1EwkWm-0000ZQ-00@gecko>
Message-ID: <67e2ed240601130251u6a7d41dw@mail.gmail.com>

Dear John,


What you suggested worked just fine apart form
"WS_ : (' ' | '\t') { $setType(SKIP); } ;" where when generating a C++
parser SKIP needs to be preceded by it's namespaces.

Thank you for your help!



Kind regards,
Gabriel



On 11/01/06, John B. Brodie <jbb@acm.org> wrote:
>
> Gabriel Radu asked:
> >I am trying to write a antler grammar and I am getting a following result:
> >
> >ANTLR Parser Generator   Version 2.7.5 (20050128)   1989-2005 jGuru.com
> >ServiceCompiler.g: warning:lexical nondeterminism between rules
> >INT_or_FLOAT_or_MACADR_or_VERSIONSTRING and DEFAULT upon
> >AuvitranServiceCompiler.g:     k==1:'D','d'
> >AuvitranServiceCompiler.g:     k==2:'E','e'
> >AuvitranServiceCompiler.g:     k==3:'F','f'
> >AuvitranServiceCompiler.g:     k==4:'A','a'
> >AuvitranServiceCompiler.g:     k==5:'U','u'
> >AuvitranServiceCompiler.g:     k==6:'L','l'
> >AuvitranServiceCompiler.g:     k==7:'T','t'
> >AuvitranServiceCompiler.g:     k==8:<end-of-token>
> >AuvitranServiceCompiler.g:     k==9:<end-of-token>
> >AuvitranServiceCompiler.g:     k==10:<end-of-token>
> >
> >The interesting parts of the lexer are:
> >
> >...lots of informative stuff snipped...
>
> You have:
>
> >protected INT
> >  :    (HEXDIG)+
> >;
>
> and
>
> >protected VERSIONSTRING_L
> >  : ( DIGIT )+ DOT ( DIGIT )+ DOT ( DIGIT )+ ('A'..'Z'|'a'..'z')?
> >;
> >
> >protected VERSIONSTRING_S
> >  : ( DIGIT )+ DOT ( DIGIT )+ ('A'..'Z'|'a'..'z')
> >;
> >
> >protected VERSIONSTRING : ;
> >
> >INT_or_FLOAT_or_MACADR_or_VERSIONSTRING
> >
> >   : ( DIGIT (DIGIT)? DOT DIGIT ( DIGIT (DIGIT)? )? DOT )
> >          => VERSIONSTRING_L { $setType( VERSIONSTRING ); }
> >
> >   | ( DIGIT (DIGIT)? DOT DIGIT ( DIGIT (DIGIT)? )? ('A'..'Z'|'a'..'z') )
> >          => VERSIONSTRING_S { $setType( VERSIONSTRING ); }
> >
> >   | ( ( DIGIT )+ DOT ) => FLOAT { $setType( FLOAT ); }
> >
> >   | ( HEXDIG HEXDIG MACADRSEPARATOR ) => MACADR { $setType( MACADR ); }
> >
> >   | ( ( DIGIT )+ ) => INT { $setType( INT ); }
> >
> >;
>
> and
>
> >DEFAULT:
> >    ('D' | 'd')
> >    ('E' | 'e')
> >    ('F' | 'f')
> >    ('A' | 'a')
> >    ('U' | 'u')
> >    ('L' | 'l')
> >    ('T' | 't')
> >;
>
> i believe that your ambiguity arises from INT being a sequence of
> HEXDIG (dispite the predicate in the INT_or_FLOAT_...whatever rule).
>
> thus the intput string `default` could be a DEFAULT or an INT followed
> by NONTOCLITs.
>
> while your k=10 lookahead would seem to be plenty to disambiguate this
> (just need to look at the first 5 symbols); it has been my
> exprience that lookahead is not considered when one of the items being
> considered is expressed as a loop (e.g. either ()+ or ()*). that is, Antlr
> will not try to do the 5 symbol lookahead before entering the INT loop.
>
> so if an INT really is a sequence of HEXDIG then you will need to add
> another predicated alternative to your INT_or_...whatever rule.
>
> on the other hand if an INT is really a sequence of DIGIT then just
> fix the protected INT rule and set the k=3 and (I think, not tested)
> and you will have fixed this ambiguity.
>
>
> on another issue which you did not (yet) ask about. you should be
> really careful with your syntax predicates. consider the input string
> "11.22.33.44.55.66". it would seem that this should scan as a MACADR,
> yet your predicate for VERSIONSTRING_L will match this string and you
> will end up scanning it as a VERSIONSTRING ("11.22.33") followed by DOT
> followed by another VERSIONSTRING (i think).
>
> attached is a version of your scanner that addresses this issue.
>
> hope this helps...
>
> //--------------------------begin attachment--------------------------
>
> //----------------------------------------------------------------------
> // Lexer
> //----------------------------------------------------------------------
>
> class ServiceLexer extends Lexer;
>
> //----------------------------------------------------------------------
> // White speace:
>
> WS_ : (' ' | '\t') { $setType(SKIP); } ;
>
> NEWLINE
>     : '\n' ( '\r' )?
>     | '\r' ( '\n' )?
> ;
>
>
> //----------------------------------------------------------------------
> // Chars:
>
> NONTOCLIT
>     :   'g'..'u' | 'x'..'z'
>     |   'G'..'U' | 'X'..'Z'
> ;
>
> protected LETTER : 'A'..'Z' | 'a'..'z' ;
>
>
>
> //----------------------------------------------------------------------
> // Numbers:
>
> protected DIGIT
>         :       '0'..'9'
> ;
>
> protected HEXLIT
>   : 'a'..'f' | 'A'..'F'
> ;
>
> protected HEXDIG
>   : ( DIGIT | HEXLIT )
> ;
>
> protected INT
>   :     ( HEXDIG )+
> ;
>
> protected FLOAT
>   : ( DIGIT )+ DOT ( DIGIT )+
> ;
>
> protected MACADRSEPARATOR
>   : DOT
> ;
>
> protected MACADR
>   :
>     HEXDIG HEXDIG MACADRSEPARATOR
>     HEXDIG HEXDIG MACADRSEPARATOR
>     HEXDIG HEXDIG MACADRSEPARATOR
>     HEXDIG HEXDIG MACADRSEPARATOR
>     HEXDIG HEXDIG MACADRSEPARATOR
>     HEXDIG HEXDIG
> ;
>
> protected VERSIONSTRING
>   : ( DIGIT )+ DOT ( DIGIT )+ ( ( DOT ( DIGIT )+ ( LETTER )? ) | LETTER )
> ;
>
> INT_or_FLOAT_or_MACADR_or_VERSIONSTRING_or_DEFAULT
>     : ( DEFAULT ) => ( DEFAULT { $setType( DEFAULT ); } )
>     | ( MACADR ) => ( MACADR { $setType( MACADR ); } )
>     | ( VERSIONSTRING ) => ( VERSIONSTRING { $setType( VERSIONSTRING ); } )
>     | ( FLOAT ) => ( FLOAT { $setType( FLOAT ); } )
>     | ( INT ) => ( INT { $setType( INT ); } )
> ;
>
>
>
> //----------------------------------------------------------------------
> // Punctuation:
>
> DOT:    '.' ;
>
> COMMA:  ',' ;
>
> COLON:  ':' ;
>
> SCOLON: ';' ;
>
>
>
> //[ some more text]
>
>
>
> //----------------------------------------------------------------------
> protected DEFAULT:
>     ('D' | 'd')
>     ('E' | 'e')
>     ('F' | 'f')
>     ('A' | 'a')
>     ('U' | 'u')
>     ('L' | 'l')
>     ('T' | 't')
> ;
>
>
> //---------------------------end attachment---------------------------
>
>
>
From priya.uky at gmail.com  Fri Jan 13 12:49:46 2006
From: priya.uky at gmail.com (Priya)
Date: Fri Jan 13 12:49:49 2006
Subject: [antlr-interest] How to draw information from a returned AST
Message-ID: <2b8e23150601131249g355abc9bp616436f6562a3656@mail.gmail.com>

Hello all,
         I'm a newbie to antlr. I am currently working on an ANTLR-C++
compiler that parses a subset of C syntax.
Shown below is a portion of my parser grammar.

function_arg:
( !(COMMA!)? t1:type ( n:Name (l:LSQB d:Decimal_Number RSQB!)?)?);

type :(
    d1:"char"^  COLON! de:Decimal_Number  {#type=#(#d1,#(de));  }

    | d:"char"^ { #type=#(#d,#[Nint,"4"]);}

    | i2:"int"^ COLON! de1:Decimal_Number {#type=#(#i2,#(de1));}

    | i1:"int"^ {#type=#(#i1,#[Nint,"8"]);}

    | "void"!  { #type=#(#[Nint,"int"],#[Nint,"0"]);})
    ) ;

ex:
(int:3 a,int:4 b[5])
int:3 is the notation i'm using to declare 3 bit integer.
for int:3 ,type will return an AST like
int
|
|
3

to the call from function_arg rule. In function_arg rule ,how can I
operate on the returned tree to record the datatype and bit precision
information ?

Thanks in advance
Priya
From parrt at cs.usfca.edu  Sat Jan 14 11:30:12 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan 14 11:30:18 2006
Subject: [antlr-interest] New article on StringTemplates and Treewalkers
In-Reply-To: <43C67905.3060802@jazillian.com>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com>
	<54345.127.0.0.1.1137016607.squirrel@taggedtype.net>
	<43C67905.3060802@jazillian.com>
Message-ID: <1CFBE880-1513-4E22-A583-D868CDE385E0@cs.usfca.edu>


On Jan 12, 2006, at 7:43 AM, Andy Tripp wrote:
> I'm not following you exactly, but I think it's a reasonable  
> question. I don't buy that I could, for example,
> use StringTemplate to output C# instead of Java, without major  
> changes to my code.

I believe you have the controller and view entangled so it would be  
hard.  I have separated things with ST.  All declarative systems seem  
to have pattern->pattern which necessarily tangles things; you'd have  
to cut-paste all of your this->that patterns to change the that.   
icky code duplication I'd argue. ;)

ANTLR v3 is doing very well at separation so far I feel.  I have  
people working on or potentially will work on targets as follows:

Java: uncle T
C++: Ric
C#: Michael / Kunle??
C: Jim Idle
Objective-C: Kay Roepke
Python: Marq Kole?, Wolfgang Hafelinger?
Ruby: Martin Traverso;
LISP: somebody is exploring this at the moment
Parrot vm compiler: Bernhard Schmalhofer
PhP: Ryan King

Note that I had bytecodes generated for the cyclic DFA for a while.   
Also note that C and Obj-C targets are very far along as far as I can  
tell.  C has a lot more work to do than Java, trust me.  So far no  
one has asked for anything to be done to code generator minus some  
attributes I forgot to push in.

> I don't think
> ANTLR could output MS or Haskell (or Lisp) without major changes.  
> ST is not fullfilling the
> "separate your view from your translation" promise in any cases  
> other than the most trivial, contrived cases

While I've not done Lisp yet, I'm pretty sure my experience and  
intuition should count for something when I say I'm certain I could  
make this work.  What do you base your assertion on?  It *seems* like  
it would be hard?  Because the order of the way you define things is  
different?  Until I find a construct that I couldn't generate with my  
code generator in multiple back-ends, I must assume it simply  
*appears* to be very difficult. No offense.  :)

If I knew lisp well, i'd just go build it ;)

> (or when the output languages are so similar as C++/Java/C# and the  
> domain is so limited as in the case
> of all the code that ANTLR spits out).

This limitation you speak of is speculation until either we get a  
lisp or other weird target or you provide an example that cannot be  
done to save us the trouble. ;)

>> With some constraints, I think this is possible.
>>
>
> OK then, what is the Java equivalent of "memset (111, 222, 333);"?
> I suppose that's a constraint :)

Depends on how natural you want the translation as I think you  
correctly pointed out ;)

Ter
From antlr at fatboycentral.com  Sat Jan 14 12:02:24 2006
From: antlr at fatboycentral.com (Mike Matera)
Date: Sat Jan 14 12:02:27 2006
Subject: [antlr-interest] Problems with x86_64 compile.
In-Reply-To: <bc607a4e0601130031p5358dc66k51017e33930ecac1@mail.gmail.com>
References: <40ddc4e40601121107x6cf483d5g5ab3803fc1c86c25@mail.gmail.com>
	<bc607a4e0601130031p5358dc66k51017e33930ecac1@mail.gmail.com>
Message-ID: <40ddc4e40601141202w2171678fr1394b2e3c5ee68c1@mail.gmail.com>

My bad!

Here's what I did wrong:

Using 64bit gcc, I built and installed ANTLR from source into my own
directory.  In my build flow I used the antlr executable that comes standard
with FC4 (version 2.7.4 release 2jpp_1fc).  This antlr executable produced
the code that caused errors in 64bit executables but not 32bit executables.
When I used the antlr executable that I built with my download the problem
went away.

I hope this saves someone a headache!

Cheers
./m

On 1/13/06, Ric Klaren <ric.klaren@gmail.com> wrote:
>
> Hi,
>
> Didn't run into 64 bit issues with antlr so far (x86_64, fedora 4).
> Could you provide some additional information? GCC version and antlr
> version ?
>
>
> On 1/12/06, Mike Matera <antlr@fatboycentral.com> wrote:
> > I have not been able to sucessfully use ANTLR (c++ mode) on my x86_64
> > machine when it is natively compiled.  A 32-bit binary works fine.  The
> > symptom is:
> >
> > Given this lexer rule:
> >
> > STRING_LIT
> >   : '"'! ( '"' '"'! | ~('"'|'\n'|'\r') )*
> >   ( '"'!
> >   | // nothing -- write error message
> >   )
> >   ;
> >
> > Given this input (quotes are included in the input):
> >
> > "sleep"
> >
> > The following error is generated:
> >
> > (After getting an antlr::TokenStreamRecognitionException)
> > line 1:18: unexpected char: 's'
>
> You have set the charVocabulary option?
> http://www.antlr.org/doc/options.html#_bb14
>
> Without it the ~ operator does not work as expected.
>
> Cheers,
>
> Ric
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060114/535e6033/attachment.html
From sohail at taggedtype.net  Sat Jan 14 12:05:20 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Sat Jan 14 12:05:26 2006
Subject: [antlr-interest] Antlrv3 docs (was New article on StringTemplates
	and Treewalkers)
In-Reply-To: <1CFBE880-1513-4E22-A583-D868CDE385E0@cs.usfca.edu>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com>
	<54345.127.0.0.1.1137016607.squirrel@taggedtype.net>
	<43C67905.3060802@jazillian.com>
	<1CFBE880-1513-4E22-A583-D868CDE385E0@cs.usfca.edu>
Message-ID: <1137269121.10086.1.camel@localhost.localdomain>

On Sat, 2006-01-14 at 11:30 -0800, Terence Parr wrote:
> ANTLR v3 is doing very well at separation so far I feel.  I have  
> people working on or potentially will work on targets as follows:
> 
> Java: uncle T
> C++: Ric
> C#: Michael / Kunle??
> C: Jim Idle
> Objective-C: Kay Roepke
> Python: Marq Kole?, Wolfgang Hafelinger?
> Ruby: Martin Traverso;
> LISP: somebody is exploring this at the moment
> Parrot vm compiler: Bernhard Schmalhofer
> PhP: Ryan King

Sweet. Are there any docs about antlrv3 yet?

From parrt at cs.usfca.edu  Sat Jan 14 12:12:05 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan 14 12:12:12 2006
Subject: [antlr-interest] recursive-descent Lisp example
Message-ID: <1D81C349-80C1-4731-B891-220CA53A2A8B@cs.usfca.edu>

Howdy.  Henry Baker has a nice example:

(defun parse-int (&aux (s +1) d (n 0))
  (and
   (and (or (match #\+)
            (and (match #\-) (setq s -1))
            (and))
        (match-type digit d) (setq n (ctoi d))
        (not (do () ((not (and (match-type digit d)
                               (setq n (+ (* n 10) (ctoi d)))))))))
   (* s n)))

from

http://home.pipeline.com/~hbaker1/Prag-Parse.html

this parses signed integers and returns the integer.  I'm no Lisp  
expert but I'm pretty sure that since "the operations [], {} and $  
correspond to the Common Lisp control structures AND, OR, and DO", I  
could go from rule to Lisp defun rather easily.

Rules are just pure-functional functions that return attributes; we  
use methods instead in OO languages but Lisp is the king of this sort  
of stuff.  My paper on ST by the way is called "A Pure Functional  
Language for Generating Structured Text".  I harp on how the nature  
of code gen and enforcing model-view separation tightly brackets the  
solution to a pure functional language (with lazy eval)....that is ST :)

Ter
From parrt at cs.usfca.edu  Sat Jan 14 12:15:29 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan 14 12:15:31 2006
Subject: [antlr-interest] Antlrv3 docs (was New article on StringTemplates
	and Treewalkers)
In-Reply-To: <1137269121.10086.1.camel@localhost.localdomain>
References: <43C3EB3F.8010503@jazillian.com> <43C5419A.9070507@arabink.com>
	<43C557BB.9080706@jazillian.com>
	<54345.127.0.0.1.1137016607.squirrel@taggedtype.net>
	<43C67905.3060802@jazillian.com>
	<1CFBE880-1513-4E22-A583-D868CDE385E0@cs.usfca.edu>
	<1137269121.10086.1.camel@localhost.localdomain>
Message-ID: <4EE8F7A6-7B51-4180-9A33-7E1C9825AEB3@cs.usfca.edu>


On Jan 14, 2006, at 12:05 PM, Sohail Somani wrote:

> On Sat, 2006-01-14 at 11:30 -0800, Terence Parr wrote:
>> ANTLR v3 is doing very well at separation so far I feel.  I have
>> people working on or potentially will work on targets as follows:
>>
>> Java: uncle T
>> C++: Ric
>> C#: Michael / Kunle??
>> C: Jim Idle
>> Objective-C: Kay Roepke
>> Python: Marq Kole?, Wolfgang Hafelinger?
>> Ruby: Martin Traverso;
>> LISP: somebody is exploring this at the moment
>> Parrot vm compiler: Bernhard Schmalhofer
>> PhP: Ryan King
>
> Sweet. Are there any docs about antlrv3 yet?

Not yet, just a bunch of examples. :(  I am *almost* ready to freeze  
features and then go for fault tolerance (to bad input grammars).   
Then a v2 -> v3 translator.  Then doc.  Academic papers at same  
time.  Then o'reilly book.  Then more papers then big translation  
book...all the while soaking my tendonitis-ridden hands at nice in  
ice water ;)

With lunch, early Summer I go 3.0beta with some basic doc.

Ter
From parrt at cs.usfca.edu  Sat Jan 14 15:15:11 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan 14 15:15:15 2006
Subject: [antlr-interest] added action shortcuts for templates
Message-ID: <7EAA03F3-AA21-4C40-949E-71F4AA557C67@cs.usfca.edu>

Howdy,

For ANTLR v3 added these shortcuts:

	 *    %foo(a={},b={},...) ctor (even shorter than $templates::foo(...))
	 *    %({name-expr})(a={},...) indirect template ctor reference
	 *
	 *    The above are parsed by antlr.g and translated by codegen.g
	 *    The following are parsed manually here:
	 *
	 *    %{string-expr} anonymous template from string expr
	 *    %{expr}.y = z; template attribute y of StringTemplate-typed  
expr to z
	 *    %x.y = z; set template attribute y of x (always set never get  
attr)
	 *              to z [languages like python without ';' must still  
use the
	 *              ';' which the code generator is free to remove  
during code gen]

Note that I added

-> ({name-expr})(a={},...)

also as a rewrite.

i expect another early access release shortly.

Ter
From nbsherid at secsme.org.au  Sat Jan 14 15:40:15 2006
From: nbsherid at secsme.org.au (Nigel Sheridan-Smith)
Date: Sat Jan 14 15:40:10 2006
Subject: [antlr-interest] RE: antlr-interest Digest, Vol 14, Issue 17
In-Reply-To: <20060111181716.2C97DDCE1A@www.antlr.org>
Message-ID: <000a01c61963$decea860$0500a8c0@nigel>


> 
> Message: 4
> Date: Wed, 11 Jan 2006 12:19:02 -0500
> From: Andy Tripp <antlr@jazillian.com>
> Subject: [antlr-interest] Re: Source-driven v. Target-driven xforms
> 	(was Re: New article on StringTemplates and Treewalkers)
> To: Gregg Reynolds <gar@arabink.com>
> Cc: antlr-interest@antlr.org
> Message-ID: <43C53E06.4090700@jazillian.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> On one hand, when Terence says "your pattern matcher may never
> terminate", I can't help but assume he's right
> and I just haven't yet noticed some fatal flaw. But on the other hand,
> an expert in computation complexity will
> tell you "your traveling salesman algorithm may take forever", and you
> know right away that he's talking
> about *in theory*, but you know full well that it works just fine *in
> practice*.
> 


The non-termination of rule-based algorithms is fairly well established,
particularly if you are applying back-tracking or goal-searching.

Pick up a book on language design and check out the description of Prolog -
particular combinations of rules and facts in particular orders will not
terminate. E.g. Ghezzi and Jazayeri "Programming Language Concepts" 1987 p
304 states "Both the order in which facts and rules are listed ... and the
order in which subgoals are listed are significant. There are programs that
behaviour correctly ... but enter an infinite loop or generate a run-time
error if the order changes".

So the order that you apply the rules and the size of the rule-set will
affect the efficiency of the algorithm and whether it terminates. If you are
applying those rules sequentially, and they are not cyclical, then you might
be okay as long as you have a good idea of when to terminate the rule
search. Prolog has the "cut" operator to limit back-tracking and increase
efficiency. Sebesta "Concepts of programming languages" 1999 p 629 has a
good example of infinite recursion in Prolog.

It seems that Andy's approach gives more granularity of control over
particular pattern matching and manipulation - things that would have to be
coded as an action in an ANTLR tree-walker. However, the disadvantage is
that it requires somebody to write such a rule engine to process the 200 or
so rules that you have written. It does sound like it would be more
intuitive to write these rules in certain circumstances, depending on what
patterns were acceptable.

Nigel

--
Nigel Sheridan-Smith
PhD research student

Faculty of Engineering
University of Technology, Sydney
Phone: 02 9514 7946
Fax: 02 9514 2435
 


From parrt at cs.usfca.edu  Sat Jan 14 15:59:07 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan 14 15:59:10 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <000a01c61963$decea860$0500a8c0@nigel>
References: <000a01c61963$decea860$0500a8c0@nigel>
Message-ID: <788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>

On Jan 14, 2006, at 3:40 PM, Nigel Sheridan-Smith wrote:
> It seems that Andy's approach gives more granularity of control over
> particular pattern matching and manipulation - things that would  
> have to be
> coded as an action in an ANTLR tree-walker. However, the  
> disadvantage is
> that it requires somebody to write such a rule engine to process  
> the 200 or
> so rules that you have written. It does sound like it would be more
> intuitive to write these rules in certain circumstances, depending  
> on what
> patterns were acceptable.

Perhaps we can have the ease of specification of Andy's solution  
without having to handbuild a specific pattern engine...well, if  
we're going to only do a single linear check for a match, apply rule,  
and repeat.  Imagine a pattern engine like this:

<expr>+0 -> <expr>
<expr>*0 -> 0

Can't we auto convert this to:

rules returns [String result]
       :       => expr '+' INT {$INT.text.equals("0")}? {$result =  
$expr.text;}
       |       => expr '*' INT {$INT.text.equals("0")}? {$result =  
$INT.text;}
       ;

where assume for the moment that => on the front is a shorthand for  
back on this alt.

rule 'rules' would be checked against every char in the input stream  
until it found a match etc...  Very much like the fuzzy java parser I  
just built that scans incomplete or semi-bogus java code looking for  
recognizable stuff.

Would thing kind of thing be useful?  Best of both worlds?  For many  
applications, this would be great!

Ter
From jigang.sun at ntlworld.com  Sat Jan 14 17:01:17 2006
From: jigang.sun at ntlworld.com (jigang.sun@ntlworld.com)
Date: Sat Jan 14 17:01:20 2006
Subject: [antlr-interest] Could anyone give me C# Main method for the
	cut-n-paste example 
Message-ID: <20060115010117.FSK20369.aamta12-winn.ispmail.ntl.com@smtp.ntlworld.com>

Hi there,

Could anyone give me C# Main method for the cut-n-paste example on http://www.antlr.org/article/cutpaste/index.html to test lexer and parser generated in C#?  

Thanks.

J Sun

-----------------------------------------
Email sent from www.ntlworld.com
Virus-checked using McAfee(R) Software 
Visit www.ntlworld.com/security for more information

From jbarnesweb at yahoo.com  Sat Jan 14 19:48:40 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Sat Jan 14 19:48:43 2006
Subject: [antlr-interest] State Machines Galore
Message-ID: <20060115034840.30147.qmail@web54505.mail.yahoo.com>

>> Where can I find more info about constructing
NFA's?
>>
> Well, lots of courses have info on constructing
them, but you 
> don't see a lot of code to do so...i can't give out
the course 
> solution  unfortunately  ;)

I just started reading a good book that's looks like a
good introduction for someone who was a music major in
college (me): Introduction to Automata Theory,
Languages, and Computation by Hopcroft et al.
http://www.amazon.com/gp/product/0201441241/ref=pd_ys_iyr1/002-9677772-2866464?%5Fencoding=UTF8&v=glance&n=283155

The book gently introduces you to the theory, proof,
protocol and application of Finite Automata. 

Hope this helps someone else.

Jeff


From sohail at taggedtype.net  Sat Jan 14 20:02:19 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Sat Jan 14 20:02:30 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
References: <000a01c61963$decea860$0500a8c0@nigel>
	<788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
Message-ID: <1137297740.8196.0.camel@localhost.localdomain>

On Sat, 2006-01-14 at 15:59 -0800, Terence Parr wrote:
> Would thing kind of thing be useful?  Best of both worlds?  For many  
> applications, this would be great!

Heck yes :)

From sohail at taggedtype.net  Sat Jan 14 20:09:51 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Sat Jan 14 20:09:59 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
References: <000a01c61963$decea860$0500a8c0@nigel>
	<788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
Message-ID: <1137298191.8196.7.camel@localhost.localdomain>

On Sat, 2006-01-14 at 15:59 -0800, Terence Parr wrote:
> Perhaps we can have the ease of specification of Andy's solution  
> without having to handbuild a specific pattern engine...well, if  
> we're going to only do a single linear check for a match, apply rule,  
> and repeat.  Imagine a pattern engine like this:
> 
> <expr>+0 -> <expr>
> <expr>*0 -> 0
> 
> Can't we auto convert this to:
> 
> rules returns [String result]
>        :       => expr '+' INT {$INT.text.equals("0")}? {$result =  
> $expr.text;}
>        |       => expr '*' INT {$INT.text.equals("0")}? {$result =  
> $INT.text;}
>        ;

After some more thought, doesn't it seem like just a more concise way to
specify tree parsing? What would the differences be?

From nbsherid at secsme.org.au  Sat Jan 14 20:18:55 2006
From: nbsherid at secsme.org.au (Nigel Sheridan-Smith)
Date: Sat Jan 14 20:18:57 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <20060115040231.5BA86DCF4E@www.antlr.org>
Message-ID: <000601c6198a$ccef1680$0200a8c0@nigelnote>

 
> Message: 7
> Date: Sat, 14 Jan 2006 15:59:07 -0800
> From: Terence Parr <parrt@cs.usfca.edu>
> Subject: [antlr-interest] single-pass pattern matching "for free"?
> To: ANTLR Interest <antlr-interest@antlr.org>
> Message-ID: <788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
> Content-Type: text/plain; charset=US-ASCII; delsp=yes; format=flowed
> 
> On Jan 14, 2006, at 3:40 PM, Nigel Sheridan-Smith wrote:
> > It seems that Andy's approach gives more granularity of control over
> > particular pattern matching and manipulation - things that would
> > have to be
> > coded as an action in an ANTLR tree-walker. However, the
> > disadvantage is
> > that it requires somebody to write such a rule engine to process
> > the 200 or
> > so rules that you have written. It does sound like it would be more
> > intuitive to write these rules in certain circumstances, depending
> > on what
> > patterns were acceptable.
> 
> Perhaps we can have the ease of specification of Andy's solution
> without having to handbuild a specific pattern engine...well, if
> we're going to only do a single linear check for a match, apply rule,
> and repeat.  Imagine a pattern engine like this:
> 
> <expr>+0 -> <expr>
> <expr>*0 -> 0
> 
> Can't we auto convert this to:
> 
> rules returns [String result]
>        :       => expr '+' INT {$INT.text.equals("0")}? {$result =
> $expr.text;}
>        |       => expr '*' INT {$INT.text.equals("0")}? {$result =
> $INT.text;}
>        ;
> 
> where assume for the moment that => on the front is a shorthand for
> back on this alt.
> 
> rule 'rules' would be checked against every char in the input stream
> until it found a match etc...  Very much like the fuzzy java parser I
> just built that scans incomplete or semi-bogus java code looking for
> recognizable stuff.
> 
> Would thing kind of thing be useful?  Best of both worlds?  For many
> applications, this would be great!
> 

Sounds good to me! But I think one of Andy's points was that not everything
in translation can be applied at the AST node level. You sometimes need to
look deeper (e.g. within strings), or broader (e.g. multiple lines of code).

Didn't Loring Craymer has some tree-rewriting syntax for ANTLR 2.8 (with the
special JPL/Caltech license)? How similar is that concept to this one? My
memory is pretty vague :-/

Nigel

--
Nigel Sheridan-Smith
PhD research student

Faculty of Engineering
University of Technology, Sydney
Phone: 02 9514 7946
Fax: 02 9514 2435

From parrt at cs.usfca.edu  Sun Jan 15 11:39:37 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sun Jan 15 11:39:40 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <1137298191.8196.7.camel@localhost.localdomain>
References: <000a01c61963$decea860$0500a8c0@nigel>
	<788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
	<1137298191.8196.7.camel@localhost.localdomain>
Message-ID: <671B4A6F-208D-4125-B02B-B0A81955E39C@cs.usfca.edu>


On Jan 14, 2006, at 8:09 PM, Sohail Somani wrote:

> On Sat, 2006-01-14 at 15:59 -0800, Terence Parr wrote:
>> Perhaps we can have the ease of specification of Andy's solution
>> without having to handbuild a specific pattern engine...well, if
>> we're going to only do a single linear check for a match, apply rule,
>> and repeat.  Imagine a pattern engine like this:
>>
>> <expr>+0 -> <expr>
>> <expr>*0 -> 0
>>
>> Can't we auto convert this to:
>>
>> rules returns [String result]
>>        :       => expr '+' INT {$INT.text.equals("0")}? {$result =
>> $expr.text;}
>>        |       => expr '*' INT {$INT.text.equals("0")}? {$result =
>> $INT.text;}
>>        ;
>
> After some more thought, doesn't it seem like just a more concise  
> way to
> specify tree parsing? What would the differences be?

And that is the most important question of all!  The answer is:

1. just listing a bunch of patterns is easier until you get a huge  
number of them, when it becomes hard to find bugs in rule applications.
2. patterns have no guarantee of coverage whereas a tree grammar does.
3. patterns are floating in space w/o context; a grammar knows that  
expressions cannot occur outside of a method or var  
initialization...patterns could specify context, however, but it is  
not as clear as a grammar.  want an action to execute when you see  
the '}' of a function, just stick an action after the '}' in the  
appropriate spot in the grammar.

The translation of a pattern -> replacement system would be trivial  
for a simple system; just translate to ANTLR.  Further, to separate  
the view from the controller, one could use templates on the right:

"<a:expr>+<b:expr>" -> add(left=a,right=b)

or some such just like an antlr grammar.  The idea would be really  
groovy.  You give me a grammar and then a list of patterns and I  
generate a combined new grammar that does exactly what you want,  
yanking in all the required tokens/rules.  Now where is a grad  
student when I need some cheap smart labor! ;)  Actually, that would  
make a damn fine paper and system.

Ter
From parrt at cs.usfca.edu  Sun Jan 15 11:44:06 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sun Jan 15 11:44:12 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <000601c6198a$ccef1680$0200a8c0@nigelnote>
References: <000601c6198a$ccef1680$0200a8c0@nigelnote>
Message-ID: <95659F6F-E367-4915-A8E0-8513FBC9E251@cs.usfca.edu>


On Jan 14, 2006, at 8:18 PM, Nigel Sheridan-Smith wrote:
>> Would thing kind of thing be useful?  Best of both worlds?  For many
>> applications, this would be great!
>>
>
> Sounds good to me! But I think one of Andy's points was that not  
> everything
> in translation can be applied at the AST node level. You sometimes  
> need to
> look deeper (e.g. within strings), or broader (e.g. multiple lines  
> of code).

Correct.  Andy's experience in this would be gold!  perhaps he would  
like to help build this generic pattern engine...

Yes, we could do patterns on two levels: char and token I should think.

1. by char.  This is how I do fuzzy parsing (filter=true mode).  Try  
to match one of a set of rules against the input stream at position  
p.  If none matches, advance to p+1 and try again.  This would allow  
you to see inside strings.  The stuff in <...>  could only be token  
refs like <ID>

2. by token.  This would be the normal mode probably and much  
faster.  You could specify grammatical structures like <expr> and  
<stat>.  you could only see properly tokenized input.  The tool would  
tokenize via the grammar's lexer you provide separately and then  
generate a parser that would apply the rules and do replacement.

Make sense?

Ter

From sohail at taggedtype.net  Sun Jan 15 12:50:35 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Sun Jan 15 12:50:43 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <671B4A6F-208D-4125-B02B-B0A81955E39C@cs.usfca.edu>
References: <000a01c61963$decea860$0500a8c0@nigel>
	<788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
	<1137298191.8196.7.camel@localhost.localdomain>
	<671B4A6F-208D-4125-B02B-B0A81955E39C@cs.usfca.edu>
Message-ID: <1137358236.13679.15.camel@localhost.localdomain>

On Sun, 2006-01-15 at 11:39 -0800, Terence Parr wrote:
> On Jan 14, 2006, at 8:09 PM, Sohail Somani wrote:
> > After some more thought, doesn't it seem like just a more concise  
> > way to
> > specify tree parsing? What would the differences be?
> 
> And that is the most important question of all!  The answer is:
> 
> 1. just listing a bunch of patterns is easier until you get a huge  
> number of them, when it becomes hard to find bugs in rule applications.

Yes, I remember having to use Prolog. Which was the coolest thing, but
you really had to consciously keep the number of rules low.

> 2. patterns have no guarantee of coverage whereas a tree grammar does.

What does this mean?

> 3. patterns are floating in space w/o context; a grammar knows that  
> expressions cannot occur outside of a method or var  
> initialization...patterns could specify context, however, but it is  
> not as clear as a grammar.  want an action to execute when you see  
> the '}' of a function, just stick an action after the '}' in the  
> appropriate spot in the grammar.

This is probably the biggest reason. I guess rule-based translation
makes sense for simple translations but I can't see it working for full
translations.

> The translation of a pattern -> replacement system would be trivial  
> for a simple system; just translate to ANTLR.  Further, to separate  
> the view from the controller, one could use templates on the right:
> 
> "<a:expr>+<b:expr>" -> add(left=a,right=b)

or the equivalent in ST:

add(lexpr,rexpr)::<<
(<lexpr>) + (<rexpr>)
>>

Still haven't figured out how to get rid of 
((((((((5))))))) + ((((((3)))))))) but it would probably require a
change in the grammar rules, is all.

I think this whole thread will converge to say: "Hey wait, what we got
is the best way".

> or some such just like an antlr grammar.  The idea would be really  
> groovy.  You give me a grammar and then a list of patterns and I  
> generate a combined new grammar that does exactly what you want,  
> yanking in all the required tokens/rules.  Now where is a grad  
> student when I need some cheap smart labor! ;)  Actually, that would  
> make a damn fine paper and system.

Academia... shudder... (its ok, they feel the same way about me :D)

From sohail at taggedtype.net  Sun Jan 15 13:01:06 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Sun Jan 15 13:01:14 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <1137358236.13679.15.camel@localhost.localdomain>
References: <000a01c61963$decea860$0500a8c0@nigel>
	<788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
	<1137298191.8196.7.camel@localhost.localdomain>
	<671B4A6F-208D-4125-B02B-B0A81955E39C@cs.usfca.edu>
	<1137358236.13679.15.camel@localhost.localdomain>
Message-ID: <1137358866.13679.16.camel@localhost.localdomain>

On Sun, 2006-01-15 at 12:50 -0800, Sohail Somani wrote:
> > The translation of a pattern -> replacement system would be trivial  
> > for a simple system; just translate to ANTLR.  Further, to separate  
> > the view from the controller, one could use templates on the right:
> > 
> > "<a:expr>+<b:expr>" -> add(left=a,right=b)
> 
> or the equivalent in ST:
> 
> add(lexpr,rexpr)::<<
> (<lexpr>) + (<rexpr>)
> >>

I have no idea why I wrote this

From tdjastrzebski at yahoo.com  Mon Jan 16 01:03:26 2006
From: tdjastrzebski at yahoo.com (Tomasz Jastrzebski)
Date: Mon Jan 16 01:03:28 2006
Subject: [antlr-interest] EOF in Lexer- how to?
Message-ID: <20060116090326.24185.qmail@web52108.mail.yahoo.com>

Hi Everybody,
   
  Is it possible to recognize EOF in the lexer?
   
  Ok, why would someone wanted to do it in the first place?
  Lets suppose I want my lexer to recognize a SingleLineComment, let's say Java "// comment" style. My lexer rules should look more or less like this:
  NewLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' ) ;
  SingleLineComment :"//" ( ~('\r' | '\n') )* NewLine ;
   
  But there is a problem here. What if my input stream consists of only single comment and no NewLine? E.g.
  // comment text <EOF>
  This lexer will not recognize such an input correctly.
  That is why I want my lexer to be able to treat EOF as NewLine.
   
  However it seems like I can not use or define EOF token within Lexer. An attempt to use '\uFFFF' within the NewLine rule seems to block the lexer and lead to unpredictable results.
   
  I would appreciate any help.

			
---------------------------------
Yahoo! Photos
 Got holiday prints? See all the ways to get quality prints in your hands ASAP.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060116/0fb26e84/attachment.html
From ewbank at gmail.com  Mon Jan 16 01:57:08 2006
From: ewbank at gmail.com (Bryan Ewbank)
Date: Mon Jan 16 01:57:10 2006
Subject: [antlr-interest] EOF in Lexer- how to?
In-Reply-To: <20060116090326.24185.qmail@web52108.mail.yahoo.com>
References: <20060116090326.24185.qmail@web52108.mail.yahoo.com>
Message-ID: <dd3a065f0601160157m3191c330gc229da8b58b81049@mail.gmail.com>

Hi,

It does not directly address your question, but I think the "//"
comment is defined to terminate at the next newline character;
therefore, the situation you describe means that the comment flows
into the next file.

Of course, the user might like to know if that happens, but it's not
quite the same as the situation you describe.

- Bryan

On 1/16/06, Tomasz Jastrzebski <tdjastrzebski@yahoo.com> wrote:
> Is it possible to recognize EOF in the lexer?
>
> Ok, why would someone wanted to do it in the first place?
> Lets suppose I want my lexer to recognize a SingleLineComment, let's say
> Java "// com  ment"  style. My lexer rules should look more or less like this:
> NewLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' ) ;
> SingleLineComment :"//" ( ~('\r' | '\n') )* NewLine ;
>
> But there is a problem here. What if my input stream consists of only single
> comment and no NewLine? E.g.
> // comment text <EOF>
> This lexer will not recognize such an input correctly.
> That is why I w  ant my  lexer to be able to treat EOF as NewLine.
From demakov at ispras.ru  Mon Jan 16 02:02:14 2006
From: demakov at ispras.ru (Alexey Demakov)
Date: Mon Jan 16 02:02:44 2006
Subject: [antlr-interest] EOF in Lexer- how to?
References: <20060116090326.24185.qmail@web52108.mail.yahoo.com>
Message-ID: <00c801c61a83$ed12ad60$8cc79553@marlboro>

Make NewLine at the end of single line comment optional:

SingleLineComment :"//" ( ~('\r' | '\n') )* ( NewLine )? ;

It will match NewLine everywhere except

// comment text <EOF>

Regards,
Alexey

-----
Alexey Demakov
TreeDL: Tree Description Language: http://treedl.sourceforge.net
RedVerst Group: http://www.unitesk.com


----- Original Message ----- 
From: Tomasz Jastrzebski
To: antlr-interest@antlr.org
Sent: Monday, January 16, 2006 12:03 PM
Subject: [antlr-interest] EOF in Lexer- how to?


Hi Everybody,

Is it possible to recognize EOF in the lexer?

Ok, why would someone wanted to do it in the first place?
Lets suppose I want my lexer to recognize a SingleLineComment, let's say Java "// com ment" style. My lexer rules should look more 
or less like this:
NewLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' ) ;
SingleLineComment :"//" ( ~('\r' | '\n') )* NewLine ;

But there is a problem here. What if my input stream consists of only single comment and no NewLine? E.g.
// comment text <EOF>
This lexer will not recognize such an input correctly.
That is why I w ant my lexer to be able to treat EOF as NewLine.

However it seems like I can not use or define EOF token within Lexer. An attempt to use '\uFFFF' within the NewLine rule seems to 
block the lexer and lead to unpredictable results.

I would appreciate any help.


From tdjastrzebski at yahoo.com  Mon Jan 16 08:18:37 2006
From: tdjastrzebski at yahoo.com (Tomasz Jastrzebski)
Date: Mon Jan 16 08:18:39 2006
Subject: [antlr-interest] EOF in Lexer- how to?
In-Reply-To: <dd3a065f0601160157m3191c330gc229da8b58b81049@mail.gmail.com>
Message-ID: <20060116161837.86144.qmail@web52104.mail.yahoo.com>

  Hi,
   
  You are 100% right.
  What I described is the problem I need a solution for.
  That is; I want SingleLineComment to terminate either at the NewLine or <EOF>.
  In another words: I would like to be able to define NewLine as:
  NewLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' )  | EOF;
but I do not how to do it - the above definition will not work.
   
-Tomasz

Bryan Ewbank <ewbank@gmail.com> wrote:  Hi,

It does not directly address your question, but I think the "//"
comment is defined to terminate at the next newline character;
therefore, the situation you describe means that the comment flows
into the next file.

Of course, the user might like to know if that happens, but it's not
quite the same as the situation you describe.

- Bryan

On 1/16/06, Tomasz Jastrzebski wrote:
> Is it possible to recognize EOF in the lexer?
>
> Ok, why would someone wanted to do it in the first place?
> Lets suppose I want my lexer to recognize a SingleLineComment, let's say
> Java "// com ment" style. My lexer rules should look more or less like this:
> NewLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' ) ;
> SingleLineComment :"//" ( ~('\r' | '\n') )* NewLine ;
>
> But there is a problem here. What if my input stream consists of only single
> comment and no NewLine? E.g.
> // comment text 
> This lexer will not recognize such an input correctly.
> That is why I w ant my lexer to be able to treat EOF as NewLine.



		
---------------------------------
Yahoo! Photos
 Ring in the New Year with Photo Calendars. Add photos, events, holidays, whatever.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060116/9fa709a0/attachment.html
From tdjastrzebski at yahoo.com  Mon Jan 16 08:31:28 2006
From: tdjastrzebski at yahoo.com (Tomasz Jastrzebski)
Date: Mon Jan 16 08:31:31 2006
Subject: [antlr-interest] EOF in Lexer- how to?
In-Reply-To: <00c801c61a83$ed12ad60$8cc79553@marlboro>
Message-ID: <20060116163128.47894.qmail@web52109.mail.yahoo.com>

  Thank you Alexy, but what I want is to solve EXACTLY this problem.
  That is; I need to be able to match:
  // comment text <EOF>
  In another words: I would like to be able to define NewLine, or better yet, EndOfLine as:   EndOfLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' )  | EOF;
  but I can no, the above definition obviously would not work.
  -Tomasz
  
Alexey Demakov <demakov@ispras.ru> wrote:

  Make NewLine at the end of single line comment optional:

SingleLineComment :"//" ( ~('\r' | '\n') )* ( NewLine )? ;

It will match NewLine everywhere except

// comment text <EOF>

Regards,
Alexey

-----
Alexey Demakov
TreeDL: Tree Description Language: http://treedl.sourceforge.net
RedVerst Group: http://www.unitesk.com


----- Original Message ----- 
From: Tomasz Jastrzebski
To: antlr-interest@antlr.org
Sent: Monday, January 16, 2006 12:03 PM
Subject: [antlr-interest] EOF in Lexer- how to?


Hi Everybody,

Is it possible to recognize EOF in the lexer?

Ok, why would someone wanted to do it in the first place?
Lets suppose I want my lexer to recognize a SingleLineComment, let's say Java "// com ment" style. My lexer rules should look more 
or less like this:
NewLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' ) ;
SingleLineComment :"//" ( ~('\r' | '\n') )* NewLine ;

But there is a problem here. What if my input stream consists of only single comment and no NewLine? E.g.
// comment text 
This lexer will not recognize such an input correctly.
That is why I w ant my lexer to be able to treat EOF as NewLine.

However it seems like I can not use or define EOF token within Lexer. An attempt to use '\uFFFF' within the NewLine rule seems to 
block the lexer and lead to unpredictable results.

I would appreciate any help.





		
---------------------------------
Yahoo! Photos ? Showcase holiday pictures in hardcover
 Photo Books. You design it and we?ll bind it!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060116/d2b0cf88/attachment-0001.html
From gudnabrsam at yahoo.com  Mon Jan 16 10:11:48 2006
From: gudnabrsam at yahoo.com (Matt Benson)
Date: Mon Jan 16 10:11:51 2006
Subject: [antlr-interest] Antlrv3 docs (was New article on StringTemplates
	and Treewalkers)
In-Reply-To: <4EE8F7A6-7B51-4180-9A33-7E1C9825AEB3@cs.usfca.edu>
Message-ID: <20060116181148.85775.qmail@web30909.mail.mud.yahoo.com>

--- Terence Parr <parrt@cs.usfca.edu> wrote:
[SNIP]
> 
> With lunch, early Summer I go 3.0beta with some
> basic doc.
> 
> Ter
> 
With lunch?!  Was that supposed to be "luck"?  ;) 
Hope you got something to cure that Freudian hunger
soon thereafter...

-Matt

__________________________________________________
Do You Yahoo!?
Tired of spam?  Yahoo! Mail has the best spam protection around 
http://mail.yahoo.com 
From parrt at cs.usfca.edu  Mon Jan 16 11:58:02 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan 16 11:58:08 2006
Subject: [antlr-interest] single-pass pattern matching "for free"?
In-Reply-To: <1137358236.13679.15.camel@localhost.localdomain>
References: <000a01c61963$decea860$0500a8c0@nigel>
	<788FA521-8491-499D-B770-53A1FC0C925E@cs.usfca.edu>
	<1137298191.8196.7.camel@localhost.localdomain>
	<671B4A6F-208D-4125-B02B-B0A81955E39C@cs.usfca.edu>
	<1137358236.13679.15.camel@localhost.localdomain>
Message-ID: <9DA751AD-FCC0-4743-B126-8D41AEBC217C@cs.usfca.edu>


On Jan 15, 2006, at 12:50 PM, Sohail Somani wrote:
>> 2. patterns have no guarantee of coverage whereas a tree grammar  
>> does.
>
> What does this mean?

It means that there may be whole sections of syntax you have not  
dealt with in your list of translation rules.  A tree grammar on the  
other hand specifies the entire syntax of the tree and you know  
you've missed something when a rule has no translation actions.

Ter
From parrt at cs.usfca.edu  Mon Jan 16 11:58:24 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan 16 11:58:32 2006
Subject: [antlr-interest] Antlrv3 docs (was New article on StringTemplates
	and Treewalkers)
In-Reply-To: <20060116181148.85775.qmail@web30909.mail.mud.yahoo.com>
References: <20060116181148.85775.qmail@web30909.mail.mud.yahoo.com>
Message-ID: <A092DBFB-248C-4278-8088-13508F86843A@cs.usfca.edu>


On Jan 16, 2006, at 10:11 AM, Matt Benson wrote:

> --- Terence Parr <parrt@cs.usfca.edu> wrote:
> [SNIP]
>>
>> With lunch, early Summer I go 3.0beta with some
>> basic doc.
>>
>> Ter
>>
> With lunch?!  Was that supposed to be "luck"?  ;)
> Hope you got something to cure that Freudian hunger
> soon thereafter...

With luck *and* lunch I should have said ;)

Ter
From stuart.dootson at gmail.com  Tue Jan 17 00:32:10 2006
From: stuart.dootson at gmail.com (Stuart Dootson)
Date: Tue Jan 17 00:32:13 2006
Subject: [antlr-interest] Lecture Notes
Message-ID: <8b56cad40601170032n34e2acbdu920127f7376e9e05@mail.gmail.com>

Ter - I'm getting 404's when I try & access the lecture notes @
http://www.cs.usfca.edu/~parrt/course/652/index.html - in fact,
http://www.cs.usfca.edu/~parrt/ appears to be missing - is this likely
to come back at any point? ...or are the university trying to tell you
something :-)

Stuart Dootson
From demakov at ispras.ru  Tue Jan 17 00:38:18 2006
From: demakov at ispras.ru (Alexey Demakov)
Date: Tue Jan 17 00:38:43 2006
Subject: [antlr-interest] EOF in Lexer- how to?
References: <20060116163128.47894.qmail@web52109.mail.yahoo.com>
Message-ID: <006201c61b41$5da81ac0$8cc79553@marlboro>

As far as I understand, the cause why you need to define EOF in lexer
is that you need to handle single line comments possibly not followed by NewLine.
My definition of SinelLinComment handles both cases - if comment is followed
by NewLine, this NewLine will be included in comment. If comment is followed
by EOF, comment still will be recognized but without NewLine.

It works, what else we need?

Btw, EOF can not be included in EndOfLine, especially when
whitespaces are skipped :)

Regards,
Alexey

-----
Alexey Demakov
TreeDL: Tree Description Language: http://treedl.sourceforge.net
RedVerst Group: http://www.unitesk.com



----- Original Message ----- 
From: Tomasz Jastrzebski 
To: antlr-interest@antlr.org 
Sent: Monday, January 16, 2006 7:31 PM
Subject: Re: [antlr-interest] EOF in Lexer- how to?


Thank you Alexy, but what I want is to solve EXACTLY this problem.
That is; I need to be able to match:
// comment text <EOF>
In another words: I would like to be able to define NewLine, or better yet, EndOfLine as: 
EndOfLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' )  | EOF;
but I can no, the above definition obviously would not work.
-Tomasz

Alexey Demakov <demakov@ispras.ru> wrote:
Make NewLine at the end of single line comment optional:

SingleLineComment :"//" ( ~('\r' | '\n') )* ( NewLine )? ;

It will match NewLine everywhere except

// comment text <EOF>

Regards,
Alexey

-----
Alexey Demakov
TreeDL: Tree Description Language: http://treedl.sourceforge.net
RedVerst Group: http://www.unitesk.com


----- Original Message ----- 
From: Tomasz Jastrzebski
To: antlr-interest@antlr.org
Sent: Monday, January 16, 2006 12:03 PM
Subject: [antlr-interest] EOF in Lexer- how to?


Hi Everybody,

Is it possible to recognize EOF in the lexer?

Ok, why would someone wanted to do it in the first place?
Lets suppose I want my lexer to recognize a SingleLineComment, let's say Java "// com ment" style. My lexer rules should look more 
or less like this:
NewLine :(options{greedy=true;}:"\r\n" | '\r' | '\n' ) ;
SingleLineComment :"//" ( ~('\r' | '\n') )* NewLine ;

But there is a problem here. What if my input stream consists of only single comment and no NewLine? E.g.
// comment text 
This lexer will not recognize such an input correctly.
That is why I w ant my lexer to be able to treat EOF as NewLine.

However it seems like I can not use or define EOF token within Lexer. An attempt to use '\uFFFF' within the NewLine rule seems to 
block the lexer and lead to unpredictable results.

I would appreciate any help.







Yahoo! Photos - Showcase holiday pictures in hardcover
Photo Books. You design it and we'll bind it!

From paubengero at yahoo.com  Tue Jan 17 08:26:59 2006
From: paubengero at yahoo.com (Paulo Bengero)
Date: Tue Jan 17 08:27:01 2006
Subject: [antlr-interest] Language Translator 
Message-ID: <20060117162659.4472.qmail@web60414.mail.yahoo.com>

Hi guys! I'm new here. Its my first time to post. I was able to discover this mailing list because im working on my project which is a english to japanese language translator (vice versa). At the same time, I would need to do grammar checking using CFG(Context Free Grammar). I was asked to do this using java. Honestly, I'm quite comfortable in Java, but I'm having a problem interpreting what CFG is all about and how I will be able to relate CFG with the actual grammar checking? Can anyone provide some inputs as to where I can start? I sure hope that I posted in the right mailing list. Thanks!

		
---------------------------------
Yahoo! Photos
 Ring in the New Year with Photo Calendars. Add photos, events, holidays, whatever.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060117/c490df75/attachment.html
From parrt at cs.usfca.edu  Tue Jan 17 08:43:29 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 17 08:43:34 2006
Subject: [antlr-interest] Lecture Notes
In-Reply-To: <8b56cad40601170032n34e2acbdu920127f7376e9e05@mail.gmail.com>
References: <8b56cad40601170032n34e2acbdu920127f7376e9e05@mail.gmail.com>
Message-ID: <B67A2CEF-4903-40A6-AA08-1D15DB33BAD6@cs.usfca.edu>

Hi Stuart, are you on mac os x?  They switched IPs or something  
yesterday and apparently os x refuses to see the new addresses  
without a reboot; very un-os-x-like...linux liked it; don't know  
about PCs.  must be more than IP change; route change?  I've passed  
along to sysadmins.

Thanks,
ter

On Jan 17, 2006, at 12:32 AM, Stuart Dootson wrote:

> Ter - I'm getting 404's when I try & access the lecture notes @
> http://www.cs.usfca.edu/~parrt/course/652/index.html - in fact,
> http://www.cs.usfca.edu/~parrt/ appears to be missing - is this likely
> to come back at any point? ...or are the university trying to tell you
> something :-)
>
> Stuart Dootson

From mail at martin-probst.com  Tue Jan 17 09:08:24 2006
From: mail at martin-probst.com (Martin Probst)
Date: Tue Jan 17 09:08:30 2006
Subject: [antlr-interest] Language Translator
In-Reply-To: <20060117162659.4472.qmail@web60414.mail.yahoo.com>
References: <20060117162659.4472.qmail@web60414.mail.yahoo.com>
Message-ID: <1137517704.7801.14.camel@siau.xhive.archipel>

Hi,
it's not exactly about translation of natural language, but the terms
Context Free Grammar, and how to go about all this parsing stuff are
explained very well here:

> Compilers (Hardcover)
> by Alfred V. Aho, Ravi Sethi, Jeffrey D. Ullman

http://www.amazon.com/gp/product/0201100886/102-9776855-2396903?v=glance&n=283155

Also known as "The (Red) Dragon Book". Generally accepted as _the_ book
about compilers, grammars, language translation etc.

Martin

From priya.uky at gmail.com  Tue Jan 17 13:21:57 2006
From: priya.uky at gmail.com (Priya)
Date: Tue Jan 17 13:22:00 2006
Subject: [antlr-interest] Symbol table
Message-ID: <2b8e23150601171321l988a454ie5ee6e20a70d3a70@mail.gmail.com>

Hi All,
Yet another newbie question...
Is there an in-built way in ANTLR for building symbol tables or
should a symbol table be manually built using actions.

Priya
From antlr at shmuelhome.mine.nu  Tue Jan 17 13:52:55 2006
From: antlr at shmuelhome.mine.nu (shmuel siegel)
Date: Tue Jan 17 13:53:27 2006
Subject: [antlr-interest] Regular expressions
Message-ID: <43CD6737.2060809@shmuelhome.mine.nu>

Do antlr grammars exist for posix regular expressions and perl regular 
expression.

Thanks

Shmuel


-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.371 / Virus Database: 267.14.18/230 - Release Date: 1/14/2006



-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.371 / Virus Database: 267.14.18/230 - Release Date: 1/14/2006

From parrt at cs.usfca.edu  Tue Jan 17 15:06:07 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 17 15:06:11 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
Message-ID: <A5704556-1BB6-433F-8FA1-0983B7CD51BD@cs.usfca.edu>

Howdy, i'm working on tree parser error recovery over next few  
days...my efforts are hampered by my earlier decision to not require  
nodes to answer any interface...i use an adaptor for construction and  
navigation.  No biggie.  However, it sure would be nice to say "all  
antlr trees satisfy the Tree" interface.  This is what v2 does (AST  
interface).  Was this a huge problem for anyone?

Ter
From gcaglar at gmail.com  Tue Jan 17 16:12:10 2006
From: gcaglar at gmail.com (Gokhan Caglar)
Date: Tue Jan 17 16:12:12 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <A5704556-1BB6-433F-8FA1-0983B7CD51BD@cs.usfca.edu>
References: <A5704556-1BB6-433F-8FA1-0983B7CD51BD@cs.usfca.edu>
Message-ID: <2cc5308c0601171612w4a357681yd7f3d1e2b0c79eac@mail.gmail.com>

I would prefer if the AST could be derived from classes that are not in the
antlr namespace, Interface or abstract base class...
Gokhan



On 1/17/06, Terence Parr <parrt@cs.usfca.edu> wrote:
>
> Howdy, i'm working on tree parser error recovery over next few
> days...my efforts are hampered by my earlier decision to not require
> nodes to answer any interface...i use an adaptor for construction and
> navigation.  No biggie.  However, it sure would be nice to say "all
> antlr trees satisfy the Tree" interface.  This is what v2 does (AST
> interface).  Was this a huge problem for anyone?
>
> Ter
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060117/ec5e2a10/attachment.html
From prashant.deva at gmail.com  Tue Jan 17 17:06:07 2006
From: prashant.deva at gmail.com (Prashant Deva)
Date: Tue Jan 17 17:06:15 2006
Subject: [antlr-interest] Symbol table
In-Reply-To: <2b8e23150601171321l988a454ie5ee6e20a70d3a70@mail.gmail.com>
References: <2b8e23150601171321l988a454ie5ee6e20a70d3a70@mail.gmail.com>
Message-ID: <41fed8f80601171706r4a63e54ct4103f2679ef4d02a@mail.gmail.com>

Hi Priya,
You gotta manually build it.

--
Prashant Deva
Creator, ANTLR Studio
Founder, Placid Systems, www.placidsystems.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060118/b4153363/attachment.html
From rhill03 at eds.com  Wed Jan 18 05:34:49 2006
From: rhill03 at eds.com (Hill, Robert)
Date: Wed Jan 18 05:40:11 2006
Subject: [antlr-interest] Lecture Notes
Message-ID: <2E909902FD3A03419E3A905908AE3DD40185B761@UKNSM201.emea.corp.eds.com>

Its fine from Windoze.
:)



--
Rob Hill
EDS - Hallamshire Business Park
F1E/087
Sheffield	
T:	+44 (0) 114 291 1928
M:	+44 (0) 791 732 1227
E:	rhill03@eds.com

 

>-----Original Message-----
>From: antlr-interest-bounces@antlr.org 
>[mailto:antlr-interest-bounces@antlr.org] On Behalf Of Terence Parr
>Sent: 17 January 2006 16:43
>To: antlr-interest Interest
>Subject: Re: [antlr-interest] Lecture Notes
>
>Hi Stuart, are you on mac os x?  They switched IPs or 
>something yesterday and apparently os x refuses to see the new 
>addresses without a reboot; very un-os-x-like...linux liked 
>it; don't know about PCs.  must be more than IP change; route 
>change?  I've passed along to sysadmins.
>
>Thanks,
>ter
>
>On Jan 17, 2006, at 12:32 AM, Stuart Dootson wrote:
>
>> Ter - I'm getting 404's when I try & access the lecture notes @
>> http://www.cs.usfca.edu/~parrt/course/652/index.html - in fact,
>> http://www.cs.usfca.edu/~parrt/ appears to be missing - is 
>this likely
>> to come back at any point? ...or are the university trying 
>to tell you
>> something :-)
>>
>> Stuart Dootson
>
>
From admytren at engin.umich.edu  Wed Jan 18 14:34:19 2006
From: admytren at engin.umich.edu (Artem Dmytrenko)
Date: Wed Jan 18 14:34:22 2006
Subject: [antlr-interest] Can lexer take hints
Message-ID: <Pine.GSO.4.63.0601181731230.24649@alumni.engin.umich.edu>

Hello Antlr experts.

I'm an antlr newbie struggling with all these pesky nondeterminism 
warnings. I'm trying to implement a parser for ABNF grammar that has 
overlaping tokens and matching rules. For example, it may have a token 
"media" as well as matching rules a="a..z" and b="a..z0..9". Essentially 
token "media" will match rule a and rule b, while a string like "blah" 
will match rule a and rule b. To make it even worse, tokens have a long 
and short term notation (e.g. "media" and "m" mean the same thing).

My question is if it's possible for parser to instruct lexer to use only a 
subset of tokens. For example, let's say I have the following tokens 
defined in lexer:

ID1: (ALPHA)+;
ID2: (DIGIT)+;
ID3: (ALPHA | DIGIT)+;
TOKEN: "MY_TOKEN";

Now I know in parser that at a particular point of time I only expect ID2 
or TOKEN and ask it not to match ID1 and ID2. For example:

messageStart:
   (ID2 | TOKEN)
   { System.out.println("Detected message start"); }
   ;

When I compile code similar to the one above lexer matches all 4 (ID1, 
ID2, ID3, TOKEN) giving me unexpected results. So I don't think it works.

Essentially what I'm trying to do is create a list of all possible lexer 
tokens and then specify in parser which ones to expect at any particular 
time. Is it possible to do with some sort of custom lexer/parser? If not, 
what would be the best approach to implementing this? I suspect that 
states is the only way - but they look very messy and I'm afraid they will 
cause the grammar to depart even further from original ABNF syntax and 
make it difficult to read.

Thank you in advance for any help/pointers/examples on this topic.

Similar questions must have been posted a million times on this forum, I 
apologize if mine is not much different (although it appears so to me!).

Art.
From priya.uky at gmail.com  Wed Jan 18 15:37:28 2006
From: priya.uky at gmail.com (Priya)
Date: Wed Jan 18 15:37:31 2006
Subject: [antlr-interest] Storing variable datatypes in a symbol table
Message-ID: <2b8e23150601181537h526d1376m8a522c2173fee595@mail.gmail.com>

Hi Everyone ,

I'm trying to build a symbol table for my compiler designed using ANTLR .
I have seen in the <lexername>.cpp code that  each token is assigned a
unique token number in the initLiterals() function... as in :

literals["int"]=19;
literals["float"]=20 ; etc in my case .

I am currently using these token type numbers to distinguish between
variables of different datatypes and storing the same in my symbol
table .

Using this stored datatype information i intend to check the variables
on either side of a given expression to be of the same datatype.

Is this thestandard way of storing datatypes in a symbol table ? or is
there another way to do it ?
Thanks in advance
Priya
From gabriel.adrian.radu at googlemail.com  Thu Jan 19 03:57:38 2006
From: gabriel.adrian.radu at googlemail.com (Gabriel Radu)
Date: Thu Jan 19 03:57:42 2006
Subject: [antlr-interest] Can lexer take hints
In-Reply-To: <Pine.GSO.4.63.0601181731230.24649@alumni.engin.umich.edu>
References: <Pine.GSO.4.63.0601181731230.24649@alumni.engin.umich.edu>
Message-ID: <67e2ed240601190357m1a50222bw@mail.gmail.com>

I think your best bet will be to declare your lexer rules as protected
and use syntactic predicates in a "main" rule as follows:

protected ALPHA : 'a'..'z' | 'A'..'Z';
protected DIGIT : '0'..'9';

protected ID1: (ALPHA)+;
protected ID2: (DIGIT)+;
protected ID3: (ALPHA | DIGIT)+;

protected TOKEN: "MY_TOKEN";

ID_or_TOKEN // This is the "main" rule
  : ( ID3 ) => ( ID3 { $setType( ID3 ); } )
  | ( ID1 ) => ( ID1 { $setType( ID1 ); } )
  | ( ID2 ) => ( ID2 { $setType( ID2 ); } )
  | ( TOKEN ) => ( ID2 { $setType( TOKEN ); } )
;

So if you try to parse a string like "test1 test2 testtree 44
MY_TOKEN", the lexer will match this to "ID3 ID3 ID1 ID2 TOKEN".

Note that the first production in the ID_or_TOKEN rule is ID3. This is
because otherwise tokens of (ALPHA | DIGIT)+ type will never be
matched.

I hope that this was what you was after. If not or have other
questions let me know.


Kind regards,
Gabriel


On 18/01/06, Artem Dmytrenko <admytren@engin.umich.edu> wrote:
> Hello Antlr experts.
>
> I'm an antlr newbie struggling with all these pesky nondeterminism
> warnings. I'm trying to implement a parser for ABNF grammar that has
> overlaping tokens and matching rules. For example, it may have a token
> "media" as well as matching rules a="a..z" and b="a..z0..9". Essentially
> token "media" will match rule a and rule b, while a string like "blah"
> will match rule a and rule b. To make it even worse, tokens have a long
> and short term notation (e.g. "media" and "m" mean the same thing).
>
> My question is if it's possible for parser to instruct lexer to use only a
> subset of tokens. For example, let's say I have the following tokens
> defined in lexer:
>
> ID1: (ALPHA)+;
> ID2: (DIGIT)+;
> ID3: (ALPHA | DIGIT)+;
> TOKEN: "MY_TOKEN";
>
> Now I know in parser that at a particular point of time I only expect ID2
> or TOKEN and ask it not to match ID1 and ID2. For example:
>
> messageStart:
>    (ID2 | TOKEN)
>    { System.out.println("Detected message start"); }
>    ;
>
> When I compile code similar to the one above lexer matches all 4 (ID1,
> ID2, ID3, TOKEN) giving me unexpected results. So I don't think it works.
>
> Essentially what I'm trying to do is create a list of all possible lexer
> tokens and then specify in parser which ones to expect at any particular
> time. Is it possible to do with some sort of custom lexer/parser? If not,
> what would be the best approach to implementing this? I suspect that
> states is the only way - but they look very messy and I'm afraid they will
> cause the grammar to depart even further from original ABNF syntax and
> make it difficult to read.
>
> Thank you in advance for any help/pointers/examples on this topic.
>
> Similar questions must have been posted a million times on this forum, I
> apologize if mine is not much different (although it appears so to me!).
>
> Art.
>
From mabuehle at student.ethz.ch  Thu Jan 19 06:39:40 2006
From: mabuehle at student.ethz.ch (=?ISO-8859-1?Q?Marc_B=FChler?=)
Date: Thu Jan 19 06:39:38 2006
Subject: [antlr-interest] Standalone Parser?
Message-ID: <43CFA4AC.3090309@student.ethz.ch>

Hi!

I'm relatively new to antlr. I successfully generated a lexer and parser for propositional calculus.
When i generate my parser i usually use: java antlr.Tool pc.g
Is there an option to create a standalone parser? Standalone means, i don't want to include 
antlr.jar in my project because i don't need the treeparser, etc. I'd like to have as less classes 
as possible.

Thanks for an answer, greetings

Marc

-- 
Marc B?hler
mabuehle@student.ethz.ch
From Mark.Pollack at codestreet.com  Thu Jan 19 07:06:07 2006
From: Mark.Pollack at codestreet.com (Mark Pollack)
Date: Thu Jan 19 07:06:35 2006
Subject: [antlr-interest] Request for strongly signed antlr.runtime.dl
Message-ID: <D3C246B7AC76FD4CAF61B51A6598E3F40FDC3D@MI8NYCMAIL11.Mi8.com>

Hi,

Before getting to the meat of the email I'd just like to thank you for
the great work on the C# code generator and ANTLR in general.  I'm one
of the leads for the open source project, Spring.NET,
(www.springframework.net).  Aleks Seovic has contributed to Spring.NET
ANTLR based functionality that supports object graph
navigation/evaluation along the lines of what you find in OGNL
(www.ognl.org).  We are planning to incorporate antlr.runtime.dll into
our next release which contains strongly signed assemblies.  As such we
need to have a strongly signed antlr.runtime.dll assembly.  Can you
provide downloads of such an assembly for version 2.7.5.2?  

Cheers,
Mark
 

P.S. I'd be more than happy to help out.  The recipe I use with NAnt is
to copy the keys into the output directory and have a conditional
statement like this in AssemblyInfo.cs that get executed when making a
release build.

#if STRONG
[assembly: AssemblyDelaySign(false)]
[assembly: AssemblyKeyFile("Spring.Net.snk")]
#endif


From antlr at jazillian.com  Thu Jan 19 07:53:51 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Thu Jan 19 07:53:49 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <A5704556-1BB6-433F-8FA1-0983B7CD51BD@cs.usfca.edu>
References: <A5704556-1BB6-433F-8FA1-0983B7CD51BD@cs.usfca.edu>
Message-ID: <43CFB60F.1060908@jazillian.com>

Terence Parr wrote:

> Howdy, i'm working on tree parser error recovery over next few  
> days...my efforts are hampered by my earlier decision to not require  
> nodes to answer any interface...i use an adaptor for construction and  
> navigation.  No biggie.  However, it sure would be nice to say "all  
> antlr trees satisfy the Tree" interface.  This is what v2 does (AST  
> interface).  Was this a huge problem for anyone?
>
> Ter
>
Not sure if this is on-topic, but...

There was that guy who had the complaint about the way the AST hierarchy is
currently structured. IIRC, his complaint was that BaseAST, as an 
abstract class,
should not declare variables "down" and "right". He's prefer if you had 
declared
abstract getDown() and getRight() methods in BaseAST, and implement 
those methods
in CommonAST. He had ASTs that were huge, and he had some other 
mechanism to
use lazy evaluation rather than allocate "down" and "right" for every 
AST. But he couldn't
extend BaseAST and reuse its other functionality, he basically had to 
modify BaseAST.

Also, I'd get rid of all the antlr.collections stuff and ASTIterator and 
ASTPair and use
use the standard collections and generics.
From antlr at jazillian.com  Thu Jan 19 08:00:49 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Thu Jan 19 08:00:46 2006
Subject: [antlr-interest] Language Translator
In-Reply-To: <20060117162659.4472.qmail@web60414.mail.yahoo.com>
References: <20060117162659.4472.qmail@web60414.mail.yahoo.com>
Message-ID: <43CFB7B1.3020005@jazillian.com>

Paulo Bengero wrote:

> Hi guys! I'm new here. Its my first time to post. I was able to 
> discover this mailing list because im working on my project which is a 
> english to japanese language translator (vice versa). At the same 
> time, I would need to do grammar checking using CFG(Context Free 
> Grammar). I was asked to do this using java. Honestly, I'm quite 
> comfortable in Java, but I'm having a problem interpreting what CFG is 
> all about and how I will be able to relate CFG with the actual grammar 
> checking? Can anyone provide some inputs as to where I can start? I 
> sure hope that I posted in the right mailing list. Thanks!
>
> ------------------------------------------------------------------------
> Yahoo! Photos
> Ring in the New Year with Photo Calendars 
> <http://us.rd.yahoo.com/mail_us/taglines/photos/*http://pa.yahoo.com/*http://us.rd.yahoo.com/mail_us/taglines/photos/evt=38087/*http://pg.photos.yahoo.com/ph//page?.file=calendar_splash.html&.dir=>. 
> Add photos, events, holidays, whatever.

Paulo,

Keep in mind that natural language translation and programming language 
translation are two completely
separate fields, each with their own set of tools and techniques. I had 
spent some time
investigating whether it would be possible to use NLP tools to translate 
between programming
languages. Sounds like maybe you're thinking of going the other way. My 
general feeling is that
you'd have a very difficult time using the very strict "compiler-type" 
tools like ANTLR to process
natural language. Better to use the NLP tools out there. They have a 
completely different approach.

Andy

From seclib at seclib.com  Thu Jan 19 08:13:12 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Thu Jan 19 08:14:51 2006
Subject: [antlr-interest] Re: Standalone Parser?
In-Reply-To: <43CFA4AC.3090309@student.ethz.ch>
References: <43CFA4AC.3090309@student.ethz.ch>
Message-ID: <dqodqo$vbg$1@sea.gmane.org>

Marc B?hler wrote:
> Hi!
> 
> I'm relatively new to antlr. I successfully generated a lexer and parser 
> for propositional calculus.
> When i generate my parser i usually use: java antlr.Tool pc.g
> Is there an option to create a standalone parser? Standalone means, i 
> don't want to include antlr.jar in my project because i don't need the 
> treeparser, etc. I'd like to have as less classes as possible.
> 
> Thanks for an answer, greetings
> 
> Marc
> 

Even the lexer/parser requires(inheritance) codes from antlr.jar. You 
can definately take them out and build your own jar, but this is not out 
of box for antlr 2.7.6.
Antlr 3.0 will be more modular, as Tool, Runtime being seperated.

-- 
Xue Yong Zhi
http://seclib.blogspot.com

From dragonoe at mcmaster.ca  Thu Jan 19 11:06:05 2006
From: dragonoe at mcmaster.ca (O.E. Dragon)
Date: Thu Jan 19 11:06:08 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST
	interface	requirement
In-Reply-To: <43CFB60F.1060908@jazillian.com>
Message-ID: <web-115263793@cgpsrv2.cis.mcmaster.ca>

On Thu, 19 Jan 2006 10:53:51 -0500
 Andy Tripp <antlr@jazillian.com> wrote:
> Also, I'd get rid of all the antlr.collections stuff and ASTIterator
> and ASTPair and use
> use the standard collections and generics.

I don't know for sure but wouldn't that cause a backwards compatibility
problem if people need to use a Java 1.4 compiler. Otherwise I
completely agree.

In particular there's a number of things that would be much easier for
me if TokenTypes was an enum type instead of an int. I don't suppose it
would be too difficult to have ANTLR v3 output both Java 1.4 and Java
1.5, seeing as the new ST-based translation back-end appears to be very
flexible.

I'd be up to the task of writing the ST templates for Java 1.5 if
Terence's plan was to only do 1.4. But then the problem of having the
ANTLR library using 1.4 or 1.5 could become an issue.

I think it might be worth it to seperate ANTLR the compiler compiler
from outside utilities like ASTIterator, etc. Let the ANTLR tool
standalone and be used only to translate grammars, written in one
language (Java). And make an external library coded in various
different languages (possibly all the target languages) and contain
various augmenting utilities that can be used by the user.

About the AST interface, I wouldn't say I got "bitten hard" by it, but
I started using it and quickly noticed it was too restrictive. I
basically ended up subclassing CommonAST and use that subclass
everywhere because there were a lot of added methods that weren't part
of the interface, which I couldn't access by declaring variables as
AST.

-Olivier
From brannonking at yahoo.com  Thu Jan 19 11:20:12 2006
From: brannonking at yahoo.com (Brannon King)
Date: Thu Jan 19 11:19:45 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's
	ASTinterface	requirement
In-Reply-To: <web-115263793@cgpsrv2.cis.mcmaster.ca>
Message-ID: <000001c61d2d$609948b0$8a0a0a0a@starbridgesystems.com>

The 1.5.6 release fixed the threading issues that had plagued the other 1.5
releases. I see no need to support 1.4, especially if it is something
planned for a release six months from now. I only run Linux (FC4) and
Windows (2k and XP) so I can't speak for those running Solaris, etc. Is it
common to have a program that runs in 1.4 that doesn't run in 1.5? I haven't
seen any but I mostly just work with Eclipse-based stuff.

>I don't know for sure but wouldn't that cause a backwards compatibility
problem if people need to use a Java 1.4 compiler. Otherwise I completely
agree.

From parrt at cs.usfca.edu  Thu Jan 19 12:12:14 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Thu Jan 19 12:12:19 2006
Subject: [antlr-interest] Terence teaching grad programming language course
	starting monday
Message-ID: <030BD4C1-4DD0-4565-B0A8-5ACAB33086E0@cs.usfca.edu>

Hi,

In case anybody is interested in taking or sitting in (auditing) my  
CS652 grad programming language course this semester (taught once  
every two years) at University of San Francisco, let me know.  To  
audit is cheap, $1200/semester.  We'll be doing lots of cool stuff  
and you'll definitely be a language animal when you're done (as well  
as an ANTLR maniac). :)

I am revamping the course completely and hence my description is not  
quite done yet; I'll post the link soon.

Regards,
Terence
From parrt at cs.usfca.edu  Thu Jan 19 12:13:31 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Thu Jan 19 12:13:35 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <43CFB60F.1060908@jazillian.com>
References: <A5704556-1BB6-433F-8FA1-0983B7CD51BD@cs.usfca.edu>
	<43CFB60F.1060908@jazillian.com>
Message-ID: <5F6ECF6A-6E3A-4F70-A6B2-AFE41ED92373@cs.usfca.edu>


On Jan 19, 2006, at 7:53 AM, Andy Tripp wrote:

> Terence Parr wrote:
>
>> Howdy, i'm working on tree parser error recovery over next few   
>> days...my efforts are hampered by my earlier decision to not  
>> require  nodes to answer any interface...i use an adaptor for  
>> construction and  navigation.  No biggie.  However, it sure would  
>> be nice to say "all  antlr trees satisfy the Tree" interface.   
>> This is what v2 does (AST  interface).  Was this a huge problem  
>> for anyone?
>>
>> Ter
>>
> Not sure if this is on-topic, but...
>
> There was that guy who had the complaint about the way the AST  
> hierarchy is
> currently structured. IIRC, his complaint was that BaseAST, as an  
> abstract class,
> should not declare variables "down" and "right". He's prefer if you  
> had declared
> abstract getDown() and getRight() methods in BaseAST, and implement  
> those methods
> in CommonAST. He had ASTs that were huge, and he had some other  
> mechanism to
> use lazy evaluation rather than allocate "down" and "right" for  
> every AST. But he couldn't
> extend BaseAST and reuse its other functionality, he basically had  
> to modify BaseAST.

Good to know.  Though in his case he could still implement AST with  
no ill effects.

> Also, I'd get rid of all the antlr.collections stuff and  
> ASTIterator and ASTPair and use
> use the standard collections and generics.

Yup. :)

Ter
From parrt at cs.usfca.edu  Thu Jan 19 12:15:37 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Thu Jan 19 12:15:40 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST
	interface	requirement
In-Reply-To: <web-115263793@cgpsrv2.cis.mcmaster.ca>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
Message-ID: <A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>


On Jan 19, 2006, at 11:06 AM, O.E. Dragon wrote:

> On Thu, 19 Jan 2006 10:53:51 -0500
>  Andy Tripp <antlr@jazillian.com> wrote:
>> Also, I'd get rid of all the antlr.collections stuff and ASTIterator
>> and ASTPair and use
>> use the standard collections and generics.
>
> I don't know for sure but wouldn't that cause a backwards  
> compatibility
> problem if people need to use a Java 1.4 compiler. Otherwise I
> completely agree.

Oh, right.  Yeah, i won't be using generics...don't need 'em.

> In particular there's a number of things that would be much easier for
> me if TokenTypes was an enum type instead of an int. I don't  
> suppose it
> would be too difficult to have ANTLR v3 output both Java 1.4 and Java
> 1.5, seeing as the new ST-based translation back-end appears to be  
> very
> flexible.

not a problem.  Just a subgroup of the main Java template group.  I'm  
using this very example in my ST paper.

> I'd be up to the task of writing the ST templates for Java 1.5 if
> Terence's plan was to only do 1.4. But then the problem of having the
> ANTLR library using 1.4 or 1.5 could become an issue.

Ah.  That is true.

> About the AST interface, I wouldn't say I got "bitten hard" by it, but
> I started using it and quickly noticed it was too restrictive. I
> basically ended up subclassing CommonAST and use that subclass
> everywhere because there were a lot of added methods that weren't part
> of the interface, which I couldn't access by declaring variables as
> AST.

Ok, well, seems like Object as the AST type is pretty useful then.   
I'll leave it.

Ter
From parrt at cs.usfca.edu  Thu Jan 19 12:45:17 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Thu Jan 19 12:45:19 2006
Subject: [antlr-interest] sample template dependency graph
Message-ID: <1F03ABC0-5079-4D28-BFB4-C60E152D4FF5@cs.usfca.edu>

Howdy,

For those interested, I have improved ST to let you generate a graph  
(for graphviz) that illustrates template dependencies.  It shows how  
a big output file is constructed from smaller templates.  The  
enclosing PDF shows templates needed by ANTLR v3 to generate a parser  
for a new language called Mantra Jean Bovet and I are designing.   
It's kinda cool.

Ter

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Mantra.template.dependencies.pdf
Type: application/pdf
Size: 22280 bytes
Desc: not available
Url : http://www.antlr.org/pipermail/antlr-interest/attachments/20060119/11c6f87e/Mantra.template.dependencies-0001.pdf
-------------- next part --------------



From mail at martin-probst.com  Thu Jan 19 15:43:12 2006
From: mail at martin-probst.com (Martin Probst)
Date: Thu Jan 19 15:43:19 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST
	interface	requirement
In-Reply-To: <A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
Message-ID: <1137714192.9792.5.camel@localhost.localdomain>

> > I'd be up to the task of writing the ST templates for Java 1.5 if
> > Terence's plan was to only do 1.4. But then the problem of having the
> > ANTLR library using 1.4 or 1.5 could become an issue.
> 
> Ah.  That is true.

Just FYI, we use a tool called "Retroweaver" to backport our fully Java
1.5 software so that it runs on Java 1.4. It basically removes all the
generics stuff and does some minor other things (StringBuilder vs.
StringBuffer), after running your jar through it you can directly use it
in 1.4 environments without any manual intervention. Might be an option
for ANTLR, too.

Martin

From prashant.deva at gmail.com  Thu Jan 19 19:20:44 2006
From: prashant.deva at gmail.com (Prashant Deva)
Date: Thu Jan 19 19:20:49 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <1137714192.9792.5.camel@localhost.localdomain>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
Message-ID: <41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>

> Just FYI, we use a tool called "Retroweaver" to backport our fully Java
> 1.5 software so that it runs on Java 1.4. It basically removes all the
> generics stuff and does some minor other things (StringBuilder vs.
> StringBuffer), after running your jar through it you can directly use it
> in 1.4 environments without any manual intervention. Might be an option
> for ANTLR, too.
>
> Martin
>

Although 'retroweaver' sounds good, I dont see how it will convert some
stuff like the new classes for thread management (by Doug Lea). Also some of
those new language features do take off a bit of load (esp the enhanced for
loop).

Also I really dont understand why people dont want to switch to java 5. i
mean the jvm is100% backward compatible with 1.4 plus it will run your
1.5programs too.
Almost every week I get an email from somebody who asks me why it is
important to install jvm 1.5 to run ANTLR Studio and when i ask him what the
problem is installing it, they all tell the same thing, that they work on
1.4.


--
Prashant Deva
Creator, ANTLR Studio
Founder, Placid Systems, www.placidsystems.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060120/34c2c73f/attachment.html
From mail at martin-probst.com  Fri Jan 20 00:49:23 2006
From: mail at martin-probst.com (Martin Probst)
Date: Fri Jan 20 00:49:27 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
Message-ID: <1137746963.9838.6.camel@localhost.localdomain>

Hi,

> Although 'retroweaver' sounds good, I dont see how it will convert
> some stuff like the new classes for thread management (by Doug Lea).
> Also some of those new language features do take off a bit of load
> (esp the enhanced for loop). 

Well, the threading probably doesn't apply to ANTLR, and I don't see how
the enhanced for loop should be any faster, but whatever.

> Also I really dont understand why people dont want to switch to java
> 5. i mean the jvm is100% backward compatible with 1.4 plus it will run
> your 1.5 programs too.

Up until recently there was neither a 1.5 JVM for AIX nor for MacOS, and
there are those companys who rather terrorize their employees than just
let them install their JVM of choice ...

A 1.5 feature I consider quite important never gets mentioned btw:
overriding methods can now declare a subclass as the return type, e.g.
if you have "class B extends A {}" and some method "A doFoo()" you can
override it to "B doFoo()". User correctly this can significantly
enhance APIs and type safety.

Martin

From parrt at cs.usfca.edu  Fri Jan 20 09:19:07 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Fri Jan 20 09:19:11 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <1137746963.9838.6.camel@localhost.localdomain>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
	<1137746963.9838.6.camel@localhost.localdomain>
Message-ID: <A7D673A7-CF23-483E-BA93-46A056FD0F3A@cs.usfca.edu>


On Jan 20, 2006, at 12:49 AM, Martin Probst wrote:
> A 1.5 feature I consider quite important never gets mentioned btw:
> overriding methods can now declare a subclass as the return type, e.g.
> if you have "class B extends A {}" and some method "A doFoo()" you can
> override it to "B doFoo()". User correctly this can significantly
> enhance APIs and type safety.

Ah!  Wow!  I have been complaining about this inability for a long  
time.  Glad they fixed it ;)

Ter
From admytren at engin.umich.edu  Fri Jan 20 15:23:48 2006
From: admytren at engin.umich.edu (Artem Dmytrenko)
Date: Fri Jan 20 15:23:50 2006
Subject: [antlr-interest] Can lexer take hints
In-Reply-To: <67e2ed240601190357m1a50222bw@mail.gmail.com>
References: <Pine.GSO.4.63.0601181731230.24649@alumni.engin.umich.edu>
	<67e2ed240601190357m1a50222bw@mail.gmail.com>
Message-ID: <Pine.GSO.4.63.0601201818161.10331@alumni.engin.umich.edu>

Thank you Gabriel - it works like a charm! I vote for adding your 
description to ANTLR manual section on syntactic predicates :)

I've also found it helpful splitting tokens/id's into several smaller 
lexers and then using TokenStreamSelector to switch between them.

Regards,
Art.

On Thu, 19 Jan 2006, Gabriel Radu wrote:

> I think your best bet will be to declare your lexer rules as protected
> and use syntactic predicates in a "main" rule as follows:
>
> protected ALPHA : 'a'..'z' | 'A'..'Z';
> protected DIGIT : '0'..'9';
>
> protected ID1: (ALPHA)+;
> protected ID2: (DIGIT)+;
> protected ID3: (ALPHA | DIGIT)+;
>
> protected TOKEN: "MY_TOKEN";
>
> ID_or_TOKEN // This is the "main" rule
>  : ( ID3 ) => ( ID3 { $setType( ID3 ); } )
>  | ( ID1 ) => ( ID1 { $setType( ID1 ); } )
>  | ( ID2 ) => ( ID2 { $setType( ID2 ); } )
>  | ( TOKEN ) => ( ID2 { $setType( TOKEN ); } )
> ;
>
> So if you try to parse a string like "test1 test2 testtree 44
> MY_TOKEN", the lexer will match this to "ID3 ID3 ID1 ID2 TOKEN".
>
> Note that the first production in the ID_or_TOKEN rule is ID3. This is
> because otherwise tokens of (ALPHA | DIGIT)+ type will never be
> matched.
>
> I hope that this was what you was after. If not or have other
> questions let me know.
>
>
> Kind regards,
> Gabriel
>
>
> On 18/01/06, Artem Dmytrenko <admytren@engin.umich.edu> wrote:
>> Hello Antlr experts.
>>
>> I'm an antlr newbie struggling with all these pesky nondeterminism
>> warnings. I'm trying to implement a parser for ABNF grammar that has
>> overlaping tokens and matching rules. For example, it may have a token
>> "media" as well as matching rules a="a..z" and b="a..z0..9". Essentially
>> token "media" will match rule a and rule b, while a string like "blah"
>> will match rule a and rule b. To make it even worse, tokens have a long
>> and short term notation (e.g. "media" and "m" mean the same thing).
>>
>> My question is if it's possible for parser to instruct lexer to use only a
>> subset of tokens. For example, let's say I have the following tokens
>> defined in lexer:
>>
>> ID1: (ALPHA)+;
>> ID2: (DIGIT)+;
>> ID3: (ALPHA | DIGIT)+;
>> TOKEN: "MY_TOKEN";
>>
>> Now I know in parser that at a particular point of time I only expect ID2
>> or TOKEN and ask it not to match ID1 and ID2. For example:
>>
>> messageStart:
>>    (ID2 | TOKEN)
>>    { System.out.println("Detected message start"); }
>>    ;
>>
>> When I compile code similar to the one above lexer matches all 4 (ID1,
>> ID2, ID3, TOKEN) giving me unexpected results. So I don't think it works.
>>
>> Essentially what I'm trying to do is create a list of all possible lexer
>> tokens and then specify in parser which ones to expect at any particular
>> time. Is it possible to do with some sort of custom lexer/parser? If not,
>> what would be the best approach to implementing this? I suspect that
>> states is the only way - but they look very messy and I'm afraid they will
>> cause the grammar to depart even further from original ABNF syntax and
>> make it difficult to read.
>>
>> Thank you in advance for any help/pointers/examples on this topic.
>>
>> Similar questions must have been posted a million times on this forum, I
>> apologize if mine is not much different (although it appears so to me!).
>>
>> Art.
>>
>
>
From mabuehle at student.ethz.ch  Fri Jan 20 15:42:54 2006
From: mabuehle at student.ethz.ch (=?ISO-8859-1?Q?Marc_B=FChler?=)
Date: Fri Jan 20 15:42:49 2006
Subject: [antlr-interest] Re: Standalone Parser?
In-Reply-To: <dqodqo$vbg$1@sea.gmane.org>
References: <43CFA4AC.3090309@student.ethz.ch> <dqodqo$vbg$1@sea.gmane.org>
Message-ID: <43D1757E.1000904@student.ethz.ch>

Xue Yong Zhi wrote:
> Even the lexer/parser requires(inheritance) codes from antlr.jar. You 
> can definately take them out and build your own jar, but this is not out 
> of box for antlr 2.7.6.
> Antlr 3.0 will be more modular, as Tool, Runtime being seperated.

Thanks for you explanation. I can't wait for v3.0. Do you know a tool similar to antlr which can 
handle that?

Thank you,
Marc

-- 
Marc B?hler
mabuehle@student.ethz.ch
From sohail at taggedtype.net  Fri Jan 20 17:49:31 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Fri Jan 20 17:49:37 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <1137746963.9838.6.camel@localhost.localdomain>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
	<1137746963.9838.6.camel@localhost.localdomain>
Message-ID: <1137808171.8158.0.camel@localhost.localdomain>

On Fri, 2006-01-20 at 09:49 +0100, Martin Probst wrote:
> A 1.5 feature I consider quite important never gets mentioned btw:
> overriding methods can now declare a subclass as the return type, e.g.
> if you have "class B extends A {}" and some method "A doFoo()" you can
> override it to "B doFoo()". User correctly this can significantly
> enhance APIs and type safety.

I think these are called covariant returns in the C++ world. Are they
the same idea?

Sohail

From prashant.deva at gmail.com  Fri Jan 20 19:23:07 2006
From: prashant.deva at gmail.com (Prashant Deva)
Date: Fri Jan 20 19:23:11 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <1137746963.9838.6.camel@localhost.localdomain>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
	<1137746963.9838.6.camel@localhost.localdomain>
Message-ID: <41fed8f80601201923i614d0767ha7b0e439cea7bbb6@mail.gmail.com>

I don't see how the enhanced for loop should be any faster, but whatever.


Its not faster, it just makes reading/writing the code easier :)

--
Prashant Deva
Creator, ANTLR Studio
Founder, Placid Systems, www.placidsystems.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060121/10a39860/attachment.html
From inshua at gmail.com  Sat Jan 21 01:49:45 2006
From: inshua at gmail.com (=?GB2312?B?0MLC8g==?=)
Date: Sat Jan 21 01:49:49 2006
Subject: [antlr-interest] not Abstract Syntax Tree, but Parse Tree
Message-ID: <2506dcb70601210149n1592c8d9i@mail.gmail.com>

can i use antlr  to generate parse tree ? i'll locate the text in source
code, but these information gone in the AST.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060121/436fef25/attachment.html
From scott at javadude.com  Sat Jan 21 08:33:44 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Sat Jan 21 08:33:52 2006
Subject: [antlr-interest] Updated antlreclipse plugin
Message-ID: <200601211621.k0LGLIR4016354@s2.eroute.net>

I've updated the ANTLR eclipse plugin to bring it up to date with the
official ANTLR 2.7.6 distribution.

I've done some testing on it, but not a huge amount -- it seems ok, but let
me know if anything seems broken.

Breakpoint setting by double-clicking in the ruler works in Eclipse 3.1.1
but not in Eclipse 3.1.0. Looks like a bug in Eclipse 3.1.0 itself.

I have not updated the plugin to work with Eclipse 3.2.x yet. I received a
patch from a user, and I'm going to try it out, but it will require more
testing to see if it'll still work with eclipse 3.1.x and eclipse 3.0.x.

See http://antlreclipse.sourceforge.net/ for update instructions; I
recommend you use the Eclipse update manager.

-- Scott

-----------------------------------------------------------
Scott Stanchfield      Gumby: Do you want to try it, Pokey? 
http://javadude.com    Pokey: No thanks, I prefer grass. 
-----------------------------------------------------------


From scott at javadude.com  Sat Jan 21 09:24:44 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Sat Jan 21 09:24:53 2006
Subject: [antlr-interest] ANTLR eclipse plugin now works with eclipse 3.2m2
Message-ID: <200601211712.k0LHCHvV001836@s2.eroute.net>

I applied a patch submitted by Gunnar Wagenknecht, and now the current
version of the antlreclipse plugin works in eclipse 3.2m4. I've also tested
it under eclipse 3.0.2 and 3.1.1.

Thanks Gunnar!

To update your antlr-eclipse plugin, see.
http://antlreclipse.sourceforge.net/

-- Scott

-----------------------------------------------------------
Scott Stanchfield      Gumby: Do you want to try it, Pokey? 
http://javadude.com    Pokey: No thanks, I prefer grass. 
-----------------------------------------------------------


From jsamort at sympatico.ca  Sat Jan 21 15:02:02 2006
From: jsamort at sympatico.ca (Scott Amort)
Date: Sat Jan 21 15:02:06 2006
Subject: [antlr-interest] beginner questions concerning nondeterminism
	warnings
Message-ID: <1137884522.13019.26.camel@localhost>

Hello All,

I'm new to ANTLR and compiler building in general, and am trying to
build a scanner (and eventually a parser) for a relatively simple
textual description language to get myself familiar with the ANTLR
program.

Here is a snippet of my .g file:

protected CHAR
  : 'a'..'z'
  | 'A'..'Z'
  ;

protected ALPHA
  : (CHAR) (CHAR)+
  ;

EVENT
  : ('a'..'h') ( "is" | "es" | '&' | '#' | "&&" | "##" )?
  | '_'
  ;

TAG
  : "\\"! ALPHA
  ;

IDENT
  : ALPHA EQUALS!
  ;

EQUALS   : '=';

Essentially, I am dealing with with a language that's needs to
differentiate between events (i.e. letters a through h, with an optional
postfix of 'is', 'es', '#', '##', '&' or '&&'; or the underscore '_',
for example cis, a# or _) and possible variables (i.e. style="bold" or
width=1cm).  The scanner currently recognizes numbers, operators, string
literals and units of measurement fine, but is giving me non-determinism
warnings when I add in the IDENT section.  It works as expected with the
IDENT section commented out (but of course, doesn't correctly scan the
input file).  Here is the warning:

test.g: warning:lexical nondeterminism between rules EVENT and IDENT
upon
test.g:     k==1:'a'..'h'
test.g:     k==2:'e','i'

I think I understand what this means -- with a k=2 lookahead, the
scanner is unable to differentiate between the two rules.

test.g: warning:lexical nondeterminism between rules EVENT and IDENT
upon
test.g:     k==1:'a'..'h'
test.g:     k==2:'e','i'
test.g:     k==3:<end-of-token>,'s'

But, if I change to k=3 lookahead, the situation does not improve, as I
get the above error message (nor does it help with k=4).  However, it
would seem to me that at this point I have looked far enough ahead to
determine that it does or does not match EVENT.  So, I am clearly
misunderstanding something here.  Perhaps someone could lend me a hand?

As well, when I add in some debug lines, I get some very strange results
if I try to run the scanner despite the warnings:

Found equals: style=
Found identifier: style

The equals rule seems to be matching the entire ident string, instead of
just the equals sign.  And it seems to be matching the equals rule
before the ident rule.  Now I am even more confused!

What is the best way to differentiate between matching ALPHA '=' and a
specific sub-set of ALPHA (i.e. EVENT)?  Thanks very much for any help
that can be provided.

Best Regards,
Scott


From matthias.gutheil at informatik.uni-mannheim.de  Sat Jan 21 15:17:03 2006
From: matthias.gutheil at informatik.uni-mannheim.de (Matthias Gutheil)
Date: Sat Jan 21 15:17:13 2006
Subject: [antlr-interest] Parsing Parts of Java Code
Message-ID: <43D2C0EF.6040606@informatik.uni-mannheim.de>

Hello,

I am using the java1.5 grammer from John Mitchell and Terence Parr and
others. I can build the AST and worked on it to add the code line and
view comments.

Now I need to parse only parts of a java program e.g.

stack.push("need");
stack.push("help");
System.out.println(stack.toString());
top();

Is that possible with the java1.5 grammer by a trick? :-)

Cheers
Matthias

-- 
Matthias Gutheil, Dipl. Inform.
Universit?t Mannheim
Lehrstuhl f?r Softwaretechnik
A5, 6, Geb?udeteil B
68131 Mannheim
Germany

E-Mail: matthias.gutheil@informatik.uni-mannheim.de
Tel: (+49) 621 181 3913
From scott at javadude.com  Sat Jan 21 18:18:27 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Sat Jan 21 18:18:36 2006
Subject: [antlr-interest] Parsing Parts of Java Code
In-Reply-To: <43D2C0EF.6040606@informatik.uni-mannheim.de>
Message-ID: <200601220206.k0M25vP8004275@s2.eroute.net>

You may be able to just call the statement-list rule, but I haven't looked
at that grammar in a while.

In general, any public rules in the grammar can be used as a starting point,
unless the action code in the grammar expects certain state to already
exist.

Good luck!
-- Scott 

> -----Original Message-----
> From: antlr-interest-bounces@antlr.org 
> [mailto:antlr-interest-bounces@antlr.org] On Behalf Of 
> Matthias Gutheil
> Sent: Saturday, January 21, 2006 6:17 PM
> To: antlr-interest@antlr.org
> Subject: [antlr-interest] Parsing Parts of Java Code
> 
> Hello,
> 
> I am using the java1.5 grammer from John Mitchell and Terence 
> Parr and others. I can build the AST and worked on it to add 
> the code line and view comments.
> 
> Now I need to parse only parts of a java program e.g.
> 
> stack.push("need");
> stack.push("help");
> System.out.println(stack.toString());
> top();
> 
> Is that possible with the java1.5 grammer by a trick? :-)
> 
> Cheers
> Matthias
> 
> --
> Matthias Gutheil, Dipl. Inform.
> Universit?t Mannheim
> Lehrstuhl f?r Softwaretechnik
> A5, 6, Geb?udeteil B
> 68131 Mannheim
> Germany
> 
> E-Mail: matthias.gutheil@informatik.uni-mannheim.de
> Tel: (+49) 621 181 3913
> 


From dev at arabink.com  Sat Jan 21 18:31:13 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Sat Jan 21 18:31:29 2006
Subject: [antlr-interest] beginner questions concerning nondeterminism
	warnings
In-Reply-To: <1137884522.13019.26.camel@localhost>
References: <1137884522.13019.26.camel@localhost>
Message-ID: <43D2EE71.1060208@arabink.com>

Scott Amort wrote:
> Hello All,
> 
> I'm new to ANTLR and compiler building in general, and am trying to
> build a scanner (and eventually a parser) for a relatively simple
> textual description language to get myself familiar with the ANTLR
> program.
...

Well, I'm a beginner too, so take this with a grain of salt, but here's
what occurs to me:

Suppose the input is "ais"?  EVENT or ALPHA?

What happens if you put a syntactic predicate on IDENT to recognize the
EQUALS?

-g
From jbarnesweb at yahoo.com  Sat Jan 21 19:28:58 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Sat Jan 21 19:29:00 2006
Subject: [antlr-interest] onerous lex pattern
Message-ID: <20060122032858.74383.qmail@web54509.mail.yahoo.com>

Hi all,

I'm creating a .mdl file parser. Mostly
straightforward, but one thing is getting past me...

Rose serializes strings that have a quote or a newline
in them by starting them at column 1 and beginning
each line of the string with a '|'. So my lexer rule
looks like this:

MULTILINESTRING:
    ({inputState.guessing != 0 || getColumn() == 1}?
'|'!)
    ( options { greedy = false; }:
        ~('\r' | '\n')
        )*
        (NL)+
;

NL:
    (
        '\r' 
    |   '\n' {newline();}
    ) { _ttype = Token.SKIP; }
;

The thing is, I don't want the multi-line string to
use more than one token. It's only one string, just
many lines. But right now, my parser rule looks like
this:

value
{
}
:
        list
    |   object
    |   STRING
    |   (MULTILINESTRING)+ 
    |   INT 
    |   DOUBLE 
    |   BOOLEAN
    |   REFERENCE 
    |   valueSet 
    |   point 
;

I want to get rid of the '+'.

Any help appreciated.

Jeff


From parrt at cs.usfca.edu  Sun Jan 22 11:43:32 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sun Jan 22 11:43:34 2006
Subject: [antlr-interest] Parsing Parts of Java Code
In-Reply-To: <200601220206.k0M25vP8004275@s2.eroute.net>
References: <200601220206.k0M25vP8004275@s2.eroute.net>
Message-ID: <7522DBD7-544D-4EC9-9625-F3BA9CD273D3@cs.usfca.edu>

Hi.  Investigate filter mode for lexers.

Terence

On Jan 21, 2006, at 6:18 PM, Scott Stanchfield wrote:

> You may be able to just call the statement-list rule, but I haven't  
> looked
> at that grammar in a while.
>
> In general, any public rules in the grammar can be used as a  
> starting point,
> unless the action code in the grammar expects certain state to already
> exist.
>
> Good luck!
> -- Scott 
>
>> -----Original Message-----
>> From: antlr-interest-bounces@antlr.org
>> [mailto:antlr-interest-bounces@antlr.org] On Behalf Of
>> Matthias Gutheil
>> Sent: Saturday, January 21, 2006 6:17 PM
>> To: antlr-interest@antlr.org
>> Subject: [antlr-interest] Parsing Parts of Java Code
>>
>> Hello,
>>
>> I am using the java1.5 grammer from John Mitchell and Terence
>> Parr and others. I can build the AST and worked on it to add
>> the code line and view comments.
>>
>> Now I need to parse only parts of a java program e.g.
>>
>> stack.push("need");
>> stack.push("help");
>> System.out.println(stack.toString());
>> top();
>>
>> Is that possible with the java1.5 grammer by a trick? :-)
>>
>> Cheers
>> Matthias
>>
>> --
>> Matthias Gutheil, Dipl. Inform.
>> Universit?t Mannheim
>> Lehrstuhl f?r Softwaretechnik
>> A5, 6, Geb?udeteil B
>> 68131 Mannheim
>> Germany
>>
>> E-Mail: matthias.gutheil@informatik.uni-mannheim.de
>> Tel: (+49) 621 181 3913
>>
>
>

From debackerl at gmail.com  Mon Jan 23 03:36:48 2006
From: debackerl at gmail.com (Laurent Debacker)
Date: Mon Jan 23 04:05:15 2006
Subject: [antlr-interest] Lexer nondeterminism
Message-ID: <75751ca80601230336r1aa828b9i24163c6048001843@mail.gmail.com>

Hi,

There is something I do not understand:

I have the following operators:
AND		: ("and" | "&&") ;
OR		: ("or" | "||") ;
EQ		: '=' | "==" ;
LT		: '<' ;
LTE		: ("<=" | "=<") ;
GT		: '>' ;
GTE		: (">=" | "=>") ;
NEQ		: ("!=" | "<>") ;
NOT		: '!' ;
IMPLIES		: "->" ;
ASSIGN		: ":=" ;

ANTLR says there are lexical nondeterminisms with (EQ,LTE), (EQ, GTE),
(LTE, GTE) and (LTE, NEQ). k is 2.

But why doesn't he complains about LT and NEQ?

Also in the C# grammar I found and which is compiling fine I found:

SL: "<<";
LTHAN: "<";

Why is ANTLR happy with that? Well maybe because ANTLR is greedy, but
then my =< should also be matched even with the = rule.

Also, is there any good page that explains what testLiterals is? I
looked around, but it was really vague.

Thanks for your help!
Laurent.
From krishanu at cal.interrasystems.com  Mon Jan 23 04:18:51 2006
From: krishanu at cal.interrasystems.com (Krishanu Debnath)
Date: Mon Jan 23 04:17:36 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <1137808171.8158.0.camel@localhost.localdomain>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>	<1137714192.9792.5.camel@localhost.localdomain>	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>	<1137746963.9838.6.camel@localhost.localdomain>
	<1137808171.8158.0.camel@localhost.localdomain>
Message-ID: <43D4C9AB.4000405@cal.interrasystems.com>

Sohail Somani wrote:
> On Fri, 2006-01-20 at 09:49 +0100, Martin Probst wrote:
>> A 1.5 feature I consider quite important never gets mentioned btw:
>> overriding methods can now declare a subclass as the return type, e.g.
>> if you have "class B extends A {}" and some method "A doFoo()" you can
>> override it to "B doFoo()". User correctly this can significantly
>> enhance APIs and type safety.
> 
> I think these are called covariant returns in the C++ world. Are they
> the same idea?
> 

No. This is not allowed in C++. Functions declarations that differ only in the
return type cannot be overloaded.

Krishanu
From mail at martin-probst.com  Mon Jan 23 05:10:32 2006
From: mail at martin-probst.com (Martin Probst)
Date: Mon Jan 23 05:10:37 2006
Subject: [antlr-interest] ANTLR eclipse plugin now works with eclipse 3.2m2
In-Reply-To: <200601211712.k0LHCHvV001836@s2.eroute.net>
References: <200601211712.k0LHCHvV001836@s2.eroute.net>
Message-ID: <1138021832.7760.47.camel@siau.xhive.archipel>

On Sat, 2006-01-21 at 12:24 -0500, Scott Stanchfield wrote:
> I applied a patch submitted by Gunnar Wagenknecht, and now the current
> version of the antlreclipse plugin works in eclipse 3.2m4. I've also tested
> it under eclipse 3.0.2 and 3.1.1.
> 
> Thanks Gunnar!

Thanks to both of you!

Martin

From ewbank at gmail.com  Mon Jan 23 05:58:21 2006
From: ewbank at gmail.com (Bryan Ewbank)
Date: Mon Jan 23 05:58:24 2006
Subject: [antlr-interest] onerous lex pattern
In-Reply-To: <20060122032858.74383.qmail@web54509.mail.yahoo.com>
References: <20060122032858.74383.qmail@web54509.mail.yahoo.com>
Message-ID: <dd3a065f0601230558h4c72ba9r212d653e47bf78a2@mail.gmail.com>

Hi Jeff,

How about if you change the way you think about this multi-line token so that
it starts with a "|" in col 1, and continues through the first newline not
followed by a "|" char?  It requires k=2, but that shouldn't be a problem...

I'm not too good with ANTLR lexer rules - I just use lex - but it would look
something like this:

MULTILINESTRING:
    ( {inputState.guessing != 0 || getColumn() == 1}?
        '|'!
        ( options {greedy=true;}: ~('\r' | '\n') )*
        ( options {greedy=true;}:
            NL
            '|'!
            ( options {greedy=true;}: ~('\r' | '\n') )*
        )*
    )
    ;

Is the final NL of the last line starting with "|" considered part of the
token?  I'd assume "no", right?

Note that there is a difference between what you described and the rule that
you wrote:

> Rose serializes strings that have a quote or a newline
> in them by starting them at column 1 and beginning
> each line of the string with a '|'. So my lexer rule
> looks like this:

> MULTILINESTRING:
>     ({inputState.guessing != 0 || getColumn() == 1}?
> '|'!)
>     ( options { greedy = false; }:
>         ~('\r' | '\n')
>         )*
>         (NL)+
> ;

The description requires every line in the string to have a leading "|", but
the rule allows blank lines to be part of the token.  Is this desired, rather
than requiring a "|" between adjacent newlines?

E.g.
    |this is the question - one string or two?

    |is this the same string?
    |description says no, rule says yes...
From gudnabrsam at yahoo.com  Mon Jan 23 07:16:41 2006
From: gudnabrsam at yahoo.com (Matt Benson)
Date: Mon Jan 23 07:16:42 2006
Subject: [antlr-interest] 2.7.6 makes more output files than 2.7.5?
Message-ID: <20060123151641.4962.qmail@web30901.mail.mud.yahoo.com>

Anyone know what I'm talking about?

-Matt

__________________________________________________
Do You Yahoo!?
Tired of spam?  Yahoo! Mail has the best spam protection around 
http://mail.yahoo.com 
From gudnabrsam at yahoo.com  Mon Jan 23 07:21:32 2006
From: gudnabrsam at yahoo.com (Matt Benson)
Date: Mon Jan 23 07:21:38 2006
Subject: [antlr-interest] .smap files WAS 2.7.6 makes more output files
	than 2.7.5?
In-Reply-To: <20060123151641.4962.qmail@web30901.mail.mud.yahoo.com>
Message-ID: <20060123152132.92701.qmail@web30902.mail.mud.yahoo.com>

The .smap files are those in question, if that sheds
any more light.

--- Matt Benson <gudnabrsam@yahoo.com> wrote:

> Anyone know what I'm talking about?
> 
> -Matt
> 
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam
> protection around 
> http://mail.yahoo.com 
> 


__________________________________________________
Do You Yahoo!?
Tired of spam?  Yahoo! Mail has the best spam protection around 
http://mail.yahoo.com 
From scott at javadude.com  Mon Jan 23 07:25:46 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Mon Jan 23 07:38:36 2006
Subject: [antlr-interest] 2.7.6 makes more output files than 2.7.5?
In-Reply-To: <20060123151641.4962.qmail@web30901.mail.mud.yahoo.com>
References: <20060123151641.4962.qmail@web30901.mail.mud.yahoo.com>
Message-ID: <7806.65.114.139.158.1138029946.squirrel@www.javadude.com>

If you're talking about the .smap files, then yes. I added these to track
the source line in the grammar.

If you use the antlreclipse plugin, it'll merge these into the compiled
.class files for the parser so you can debug the grammar itself.

-- Scott

> Anyone know what I'm talking about?
>
> -Matt
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>


From stanio at myrealbox.com  Mon Jan 23 07:54:12 2006
From: stanio at myrealbox.com (Stanimir Stamenkov)
Date: Mon Jan 23 07:55:56 2006
Subject: [antlr-interest] Inherit grammar and specify base scanner class at
	the same time
Message-ID: <43D4FC24.8000501@myrealbox.com>

Hello,

I'm new to the ANTLR framework and I'm currently trying to generate 
a lexer which employs grammar inheritance and specifies to be of 
specific |antlr.CharScanner| subtype, at the same type. I've tried 
both of these work:

class MyLexer extends SuperLexer;

or:

class MyLexer extends Lexer("name.stanio.MyScanner");

But I want the effect of both at the same time, so I've first tried 
specifying the scanner class on the super grammar as:

class SuperLexer extends Lexer("name.stanio.MyScanner");

but the generated "MyLexer" was direct subclass of 
|antlr.CharScanner| again. Then I've tried:

class MyLexer extends SuperLexer("name.stanio.MyScanner");

but I get error:

.\expandedmylexer.g:5:23: rule classDef trapped:
.\expandedmylexer.g:5:23: expecting "Parser", found '('
error: aborting grammar 'unknown grammar' due to errors

I see line 5 in the generated "expandedmylexer.g":

class MyLexer extends ("name.stanio.MyScanner");

while normally (using the first declaration for grammar inheritance 
I've pointed) in that file I see:

class MyLexer extends Lexer;

Is it possible what I'm trying?

-- 
Thank you in advance,
Stanimir

From seclib at seclib.com  Mon Jan 23 09:10:08 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Mon Jan 23 09:12:24 2006
Subject: [antlr-interest] Re: Lexer nondeterminism
In-Reply-To: <75751ca80601230336r1aa828b9i24163c6048001843@mail.gmail.com>
References: <75751ca80601230336r1aa828b9i24163c6048001843@mail.gmail.com>
Message-ID: <dr32lf$s4i$1@sea.gmane.org>

The answer is antlr uses "linear approximate lookahead".

If you look at the generated code you may find the clue. For example, 
GTE will match "==", ">>", ">=" and "=>", and of course it conflicts 
with EQ.

Please read this:
http://www.antlr.org/doc/glossary.html#Linear_approximate_lookahead
and related entries in antlr's FAQ.

You may find my blog usefully as well:
http://seclib.blogspot.com/2005/11/linear-approximate-lookahead.html


Laurent Debacker wrote:
> Hi,
> 
> There is something I do not understand:
> 
> I have the following operators:
> AND		: ("and" | "&&") ;
> OR		: ("or" | "||") ;
> EQ		: '=' | "==" ;
> LT		: '<' ;
> LTE		: ("<=" | "=<") ;
> GT		: '>' ;
> GTE		: (">=" | "=>") ;
> NEQ		: ("!=" | "<>") ;
> NOT		: '!' ;
> IMPLIES		: "->" ;
> ASSIGN		: ":=" ;
> 
> ANTLR says there are lexical nondeterminisms with (EQ,LTE), (EQ, GTE),
> (LTE, GTE) and (LTE, NEQ). k is 2.
> 
> But why doesn't he complains about LT and NEQ?
> 
> Also in the C# grammar I found and which is compiling fine I found:
> 
> SL: "<<";
> LTHAN: "<";
> 
> Why is ANTLR happy with that? Well maybe because ANTLR is greedy, but
> then my =< should also be matched even with the = rule.
> 
> Also, is there any good page that explains what testLiterals is? I
> looked around, but it was really vague.
> 
> Thanks for your help!
> Laurent.
> 


-- 
Xue Yong Zhi
http://seclib.blogspot.com

From seclib at seclib.com  Mon Jan 23 09:19:11 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Mon Jan 23 09:21:14 2006
Subject: [antlr-interest] Re: beginner questions concerning nondeterminism
	warnings
In-Reply-To: <1137884522.13019.26.camel@localhost>
References: <1137884522.13019.26.camel@localhost>
Message-ID: <dr336f$uam$1@sea.gmane.org>

Antlr gives you a warning because of "anything can follow" concept.
In your grammar, antlr thinks "EVENT EQUALS" can happen, which conflict 
with IDENT. Please check out antlr FAQ:
http://www.magelang.com/faq/view.jsp?EID=746286

-- 
Xue Yong Zhi
http://seclib.blogspot.com

> EVENT
>   : ('a'..'h') ( "is" | "es" | '&' | '#' | "&&" | "##" )?
>   | '_'
>   ;
> 
> IDENT
>   : ALPHA EQUALS!
>   ;
> 


From gudnabrsam at yahoo.com  Mon Jan 23 09:46:31 2006
From: gudnabrsam at yahoo.com (Matt Benson)
Date: Mon Jan 23 09:46:33 2006
Subject: [antlr-interest] 2.7.6 makes more output files than 2.7.5?
In-Reply-To: <7806.65.114.139.158.1138029946.squirrel@www.javadude.com>
Message-ID: <20060123174631.60425.qmail@web30913.mail.mud.yahoo.com>

Thanks, Scott.  They were breaking a unit test for the
Ant task; I modified the test to ignore them.  Any
update on the proposed rewrite of the task?

-Matt

--- Scott Stanchfield <scott@javadude.com> wrote:

> If you're talking about the .smap files, then yes. I
> added these to track
> the source line in the grammar.
> 
> If you use the antlreclipse plugin, it'll merge
> these into the compiled
> .class files for the parser so you can debug the
> grammar itself.
> 
> -- Scott
> 
> > Anyone know what I'm talking about?
> >
> > -Matt
> >
> > __________________________________________________
> > Do You Yahoo!?
> > Tired of spam?  Yahoo! Mail has the best spam
> protection around
> > http://mail.yahoo.com
> >
> 
> 
> 


__________________________________________________
Do You Yahoo!?
Tired of spam?  Yahoo! Mail has the best spam protection around 
http://mail.yahoo.com 
From matthias.gutheil at informatik.uni-mannheim.de  Mon Jan 23 10:29:14 2006
From: matthias.gutheil at informatik.uni-mannheim.de (Matthias Gutheil)
Date: Mon Jan 23 10:29:20 2006
Subject: [antlr-interest] Parsing Parts of Java Code
In-Reply-To: <7522DBD7-544D-4EC9-9625-F3BA9CD273D3@cs.usfca.edu>
References: <200601220206.k0M25vP8004275@s2.eroute.net>
	<7522DBD7-544D-4EC9-9625-F3BA9CD273D3@cs.usfca.edu>
Message-ID: <43D5207A.3030904@informatik.uni-mannheim.de>

Hi,

am I'm right, that the filter=true option for the lexer doesn't help me 
with this grammer?

http://www.antlr.org/grammar/1090713067533/index.html

And in the Recognizer I can't use the filter flag ( I get an error 
message when using the antlr.Tool).

Matthias

Terence Parr schrieb:
> Hi.  Investigate filter mode for lexers.
> 
> Terence
> 
> On Jan 21, 2006, at 6:18 PM, Scott Stanchfield wrote:
> 
>> You may be able to just call the statement-list rule, but I haven't 
>> looked
>> at that grammar in a while.
>>
>> In general, any public rules in the grammar can be used as a starting 
>> point,
>> unless the action code in the grammar expects certain state to already
>> exist.
>>
>> Good luck!
>> -- Scott
>>> -----Original Message-----
>>> From: antlr-interest-bounces@antlr.org
>>> [mailto:antlr-interest-bounces@antlr.org] On Behalf Of
>>> Matthias Gutheil
>>> Sent: Saturday, January 21, 2006 6:17 PM
>>> To: antlr-interest@antlr.org
>>> Subject: [antlr-interest] Parsing Parts of Java Code
>>>
>>> Hello,
>>>
>>> I am using the java1.5 grammer from John Mitchell and Terence
>>> Parr and others. I can build the AST and worked on it to add
>>> the code line and view comments.
>>>
>>> Now I need to parse only parts of a java program e.g.
>>>
>>> stack.push("need");
>>> stack.push("help");
>>> System.out.println(stack.toString());
>>> top();
>>>
>>> Is that possible with the java1.5 grammer by a trick? :-)
>>>
>>> Cheers
>>> Matthias
>>>
>>> -- 
>>> Matthias Gutheil, Dipl. Inform.
>>> Universit?t Mannheim
>>> Lehrstuhl f?r Softwaretechnik
>>> A5, 6, Geb?udeteil B
>>> 68131 Mannheim
>>> Germany
>>>
>>> E-Mail: matthias.gutheil@informatik.uni-mannheim.de
>>> Tel: (+49) 621 181 3913
>>>
>>
>>

-- 
Matthias Gutheil, Dipl. Inform.
Universit?t Mannheim
Lehrstuhl f?r Softwaretechnik
A5, 6, Geb?udeteil B
68131 Mannheim
Germany

E-Mail: matthias.gutheil@informatik.uni-mannheim.de
Tel: (+49) 621 181 3913
From parrt at cs.usfca.edu  Mon Jan 23 11:53:02 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan 23 11:53:05 2006
Subject: [antlr-interest] Parsing Parts of Java Code
In-Reply-To: <43D5207A.3030904@informatik.uni-mannheim.de>
References: <200601220206.k0M25vP8004275@s2.eroute.net>
	<7522DBD7-544D-4EC9-9625-F3BA9CD273D3@cs.usfca.edu>
	<43D5207A.3030904@informatik.uni-mannheim.de>
Message-ID: <FB0E6A08-7E09-41EE-8CF2-A6E006BA04BF@cs.usfca.edu>


On Jan 23, 2006, at 10:29 AM, Matthias Gutheil wrote:

> Hi,
>
> am I'm right, that the filter=true option for the lexer doesn't  
> help me with this grammer?
>
> http://www.antlr.org/grammar/1090713067533/index.html

That is a full grammar...you need to build some complex lexer rules  
with filter=true to find the patterns you want.

Here is my fuzzy java parser that finds function calls, function  
defs, class defs for ANTLR v3 but you can reverse engineer to v2 I  
think.

Ter

lexer grammar FuzzyJava;
options {filter=true;}

IMPORT
	:	'import' WS name=QIDStar WS? ';'
	;
	
/** Avoids having "return foo;" match as a field */
RETURN
	:	'return' (options {greedy=false;}:.)* ';'
	;

CLASS
	:	'class' WS name=ID WS? ('extends' WS QID WS?)?
		('implements' WS QID WS? (',' WS? QID WS?)*)? '{'
         {System.out.println("found class "+$name.text);}
	;
	
METHOD
     :   TYPE WS name=ID WS? '(' ( ARG WS? (',' WS? ARG WS?)* )? ')' WS?
        ('throws' WS QID WS? (',' WS? QID WS?)*)? '{'
         {System.out.println("found method "+$name.text);}
     ;

FIELD
     :   TYPE WS name=ID '[]'? WS? (';'|'=')
         {System.out.println("found var "+$name.text);}
     ;

STAT:	('if'|'while'|'switch'|'for') WS? '(' ;
	
CALL
     :   name=QID WS? '('
         {/*ignore if this/super */ System.out.println("found call "+ 
$name.text);}
     ;

COMMENT
     :   '/*' (options {greedy=false;} : . )* '*/'
         {System.out.println("found comment "+getText());}
     ;

SL_COMMENT
     :   '//' (options {greedy=false;} : . )* '\n'
         {System.out.println("found // comment "+getText());}
     ;
	
STRING
	:	'"' (options {greedy=false;}: ESC | .)* '"'
	;

CHAR
	:	'\'' (options {greedy=false;}: ESC | .)* '\''
	;

WS  :   (' '|'\t'|'\n')+
     ;

fragment
QID :	ID ('.' ID)*
	;
	
/** QID cannot see beyond end of token so using QID '.*'? somewhere  
won't
*  ever match since k=1 lookahead in the QID loop of '.' will make it  
loop.
*  I made this rule to compensate.
*/
fragment
QIDStar
	:	ID ('.' ID)* '.*'?
	;

fragment
TYPE:   QID '[]'?
     ;

fragment
ARG :   TYPE WS ID
     ;

fragment
ID  :   ('a'..'z'|'A'..'Z'|'_') ('a'..'z'|'A'..'Z'|'_'|'0'..'9')*
     ;

fragment
ESC	:	'\\' ('"'|'\''|'\\')
	;


From jsamort at sympatico.ca  Mon Jan 23 16:20:23 2006
From: jsamort at sympatico.ca (Scott Amort)
Date: Mon Jan 23 16:20:28 2006
Subject: [antlr-interest] beginner questions concerning nondeterminism
	warnings
In-Reply-To: <43D2EE71.1060208@arabink.com>
References: <1137884522.13019.26.camel@localhost>
	<43D2EE71.1060208@arabink.com>
Message-ID: <43D572C7.4040608@sympatico.ca>

Gregg Reynolds wrote:
> What happens if you put a syntactic predicate on IDENT to recognize the
> EQUALS?
>   
Hi Greg,

Thanks for the response... I did end up using a syntactic predicate, and 
that seems to have solved the problem!

Scott
From scott at javadude.com  Mon Jan 23 18:56:28 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Mon Jan 23 18:56:35 2006
Subject: [antlr-interest] 2.7.6 makes more output files than 2.7.5?
In-Reply-To: <20060123174631.60425.qmail@web30913.mail.mud.yahoo.com>
Message-ID: <200601240243.k0O2hc7Q007563@s2.eroute.net>

After working with the ant gang, we decided not to update the antlr task.

I'd recommend using the existing task unless you need a new option, in which
case you can always use the <java> task instead.

Sorry...
--Scott 

> -----Original Message-----
> From: Matt Benson [mailto:gudnabrsam@yahoo.com] 
> Sent: Monday, January 23, 2006 12:47 PM
> To: Scott Stanchfield; Antlr List
> Subject: Re: [antlr-interest] 2.7.6 makes more output files 
> than 2.7.5?
> 
> Thanks, Scott.  They were breaking a unit test for the Ant 
> task; I modified the test to ignore them.  Any update on the 
> proposed rewrite of the task?
> 


From sohail at taggedtype.net  Mon Jan 23 19:44:25 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Mon Jan 23 19:44:32 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <43D4C9AB.4000405@cal.interrasystems.com>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
	<1137746963.9838.6.camel@localhost.localdomain>
	<1137808171.8158.0.camel@localhost.localdomain>
	<43D4C9AB.4000405@cal.interrasystems.com>
Message-ID: <1138074266.8159.4.camel@localhost.localdomain>

On Mon, 2006-01-23 at 17:48 +0530, Krishanu Debnath wrote:
> Sohail Somani wrote:
> > On Fri, 2006-01-20 at 09:49 +0100, Martin Probst wrote:
> >> A 1.5 feature I consider quite important never gets mentioned btw:
> >> overriding methods can now declare a subclass as the return type, e.g.
> >> if you have "class B extends A {}" and some method "A doFoo()" you can
> >> override it to "B doFoo()". User correctly this can significantly
> >> enhance APIs and type safety.
> > 
> > I think these are called covariant returns in the C++ world. Are they
> > the same idea?
> > 
> No. This is not allowed in C++. Functions declarations that differ only in the
> return type cannot be overloaded.

Ah. Clarified. doFoo() are in the same class.

Thanks!


From sohail at taggedtype.net  Mon Jan 23 19:54:28 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Mon Jan 23 19:54:33 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <43D4C9AB.4000405@cal.interrasystems.com>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
	<1137746963.9838.6.camel@localhost.localdomain>
	<1137808171.8158.0.camel@localhost.localdomain>
	<43D4C9AB.4000405@cal.interrasystems.com>
Message-ID: <1138074868.8309.2.camel@localhost.localdomain>

On Mon, 2006-01-23 at 17:48 +0530, Krishanu Debnath wrote:
> Sohail Somani wrote:
> > On Fri, 2006-01-20 at 09:49 +0100, Martin Probst wrote:
> >> A 1.5 feature I consider quite important never gets mentioned btw:
> >> overriding methods can now declare a subclass as the return type, e.g.
> >> if you have "class B extends A {}" and some method "A doFoo()" you can
> >> override it to "B doFoo()". User correctly this can significantly
> >> enhance APIs and type safety.
> > 
> > I think these are called covariant returns in the C++ world. Are they
> > the same idea?
> > 
> 
> No. This is not allowed in C++. Functions declarations that differ only in the
> return type cannot be overloaded.

Perhaps I should've looked at this earlier, but the site here seems to
say that you can't have two doFoo()'s in the same class that return
different types:

http://java.sun.com/developer/JDCTechTips/2004/tt1201.html


From jbarnesweb at yahoo.com  Tue Jan 24 01:11:25 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Tue Jan 24 01:11:29 2006
Subject: [antlr-interest] onerous lex pattern
In-Reply-To: <dd3a065f0601230558h4c72ba9r212d653e47bf78a2@mail.gmail.com>
Message-ID: <20060124091125.59176.qmail@web54512.mail.yahoo.com>

Hi Bryan,

Looks good! I've not done a lot of LR stuff; looks
like your bias is towards that kind of thinking. Good
job with the analysis.

Thanks!

:)


--- Bryan Ewbank <ewbank@gmail.com> wrote:

> Hi Jeff,
> 
> How about if you change the way you think about this
> multi-line token so that
> it starts with a "|" in col 1, and continues through
> the first newline not
> followed by a "|" char?  It requires k=2, but that
> shouldn't be a problem...
> 
> I'm not too good with ANTLR lexer rules - I just use
> lex - but it would look
> something like this:
> 
> MULTILINESTRING:
>     ( {inputState.guessing != 0 || getColumn() ==
> 1}?
>         '|'!
>         ( options {greedy=true;}: ~('\r' | '\n') )*
>         ( options {greedy=true;}:
>             NL
>             '|'!
>             ( options {greedy=true;}: ~('\r' | '\n')
> )*
>         )*
>     )
>     ;
> 
> Is the final NL of the last line starting with "|"
> considered part of the
> token?  I'd assume "no", right?
> 
> Note that there is a difference between what you
> described and the rule that
> you wrote:
> 
> > Rose serializes strings that have a quote or a
> newline
> > in them by starting them at column 1 and beginning
> > each line of the string with a '|'. So my lexer
> rule
> > looks like this:
> 
> > MULTILINESTRING:
> >     ({inputState.guessing != 0 || getColumn() ==
> 1}?
> > '|'!)
> >     ( options { greedy = false; }:
> >         ~('\r' | '\n')
> >         )*
> >         (NL)+
> > ;
> 
> The description requires every line in the string to
> have a leading "|", but
> the rule allows blank lines to be part of the token.
>  Is this desired, rather
> than requiring a "|" between adjacent newlines?
> 
> E.g.
>     |this is the question - one string or two?
> 
>     |is this the same string?
>     |description says no, rule says yes...
> 


=========
Jeff Barnes
(206)245-6100

There are two rules for being a successful consultant: Rule 1 - Don't tell people everything you know.
From mail at martin-probst.com  Tue Jan 24 01:59:52 2006
From: mail at martin-probst.com (Martin Probst)
Date: Tue Jan 24 01:59:58 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <1138074868.8309.2.camel@localhost.localdomain>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
	<1137746963.9838.6.camel@localhost.localdomain>
	<1137808171.8158.0.camel@localhost.localdomain>
	<43D4C9AB.4000405@cal.interrasystems.com>
	<1138074868.8309.2.camel@localhost.localdomain>
Message-ID: <1138096792.7587.16.camel@siau.xhive.archipel>

In code:

class X { .. }
class Y extends X { .. }

class A {
  X foo();
}

class B extends A {
  Y foo(); // <-- !!!
}

The class B with the overriding foo() returning Y was not possible
before, and it can really enhance complicated APIs. E.g. if you move
down the API abstraction level you can now have the more concrete
classes also return more concrete types, and that is nice.

Martin

From rhill03 at eds.com  Tue Jan 24 03:10:47 2006
From: rhill03 at eds.com (Hill, Robert)
Date: Tue Jan 24 03:11:06 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST
	interfacerequirement
Message-ID: <2E909902FD3A03419E3A905908AE3DD40185BBA1@UKNSM201.emea.corp.eds.com>

You can do this in C#2 I believe.
'Covariance' IIRC.



--
Rob Hill
EDS - Hallamshire Business Park
F1E/087
Sheffield	
T:	+44 (0) 114 291 1928
M:	+44 (0) 791 732 1227
E:	rhill03@eds.com

 

>-----Original Message-----
>From: antlr-interest-bounces@antlr.org 
>[mailto:antlr-interest-bounces@antlr.org] On Behalf Of Martin Probst
>Sent: 24 January 2006 10:00
>To: antlr-interest@antlr.org
>Subject: Re: [antlr-interest] anybody get bitten by ANTLR's 
>AST interfacerequirement
>
>In code:
>
>class X { .. }
>class Y extends X { .. }
>
>class A {
>  X foo();
>}
>
>class B extends A {
>  Y foo(); // <-- !!!
>}
>
>The class B with the overriding foo() returning Y was not 
>possible before, and it can really enhance complicated APIs. 
>E.g. if you move down the API abstraction level you can now 
>have the more concrete classes also return more concrete 
>types, and that is nice.
>
>Martin
>
>
From stanio at myrealbox.com  Tue Jan 24 08:17:49 2006
From: stanio at myrealbox.com (Stanimir Stamenkov)
Date: Tue Jan 24 08:22:01 2006
Subject: [antlr-interest] Inherit grammar and specify base scanner class
	at	the same time
In-Reply-To: <43D4FC24.8000501@myrealbox.com>
References: <43D4FC24.8000501@myrealbox.com>
Message-ID: <43D6532D.9060509@myrealbox.com>

/Stanimir Stamenkov/:

> I'm new to the ANTLR framework and I'm currently trying to generate a 
> lexer which employs grammar inheritance and specifies to be of specific 
> |antlr.CharScanner| subtype, at the same type.
> [...]
> Is it possible what I'm trying?

If my explanation wasn't as clear as it needs, I'm posting the exact 
example files attached - I'm trying to process the "mylexer.g" 
grammar running:

antlr -glib superlexer.g mylexer.g

I'm using ANTLR 2.7.5.

-- 
Stanimir
-------------- next part --------------
/*
 *
 */

class SuperLexer extends Lexer;

WS : ( ' ' | '\t' | '\f' | '\r' | '\n' )+;
-------------- next part --------------
/*
 *
 */
header
{
package name.stanio;
}

class MyLexer extends SuperLexer("name.stanio.MyScanner");
//class MyLexer extends Lexer("name.stanio.MyScanner");

COMMENT : "//" (~('\n'|'\r'))* ('\n'|'\r'('\n')?) { myFancyMethod(); };
-------------- next part --------------
package name.stanio;

import antlr.CharScanner;
import antlr.LexerSharedInputState;

public abstract class MyScanner extends CharScanner {

    public MyScanner(LexerSharedInputState inputState) {
        super(inputState);
    }
    
    protected void myFancyMethod() {
    	  System.out.println("Say \"Hi\"!");
    }

}
From andrew.bell.ia at gmail.com  Tue Jan 24 09:22:48 2006
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue Jan 24 09:22:52 2006
Subject: [antlr-interest] Crash in consumeUntil()
Message-ID: <e80abd30601240922qd56ae78gc14d394bd6037fc6@mail.gmail.com>

Hi,

I am throwing a SemanticException in a parser action.  It gets caught
by the default handler which catches the exception as a
RecognitionException.  The exception handler calls reportError() and
then dies when it calls recover().  Here's the stack trace:

#0  0x0000000000523cdd in antlr::TokenBuffer::LA ()
#1  0x000000000043d343 in antlr::Parser::consumeUntil ()
#2  0x00000000004bd227 in StageParser::stagename ()
#3  0x00000000004bd975 in StageParser::stage ()
#4  0x00000000004bdc3c in StageParser::lang ()

I'm generating C++ on a 64bit x86 machine running linux:

$ uname -a
Linux galaga.cssm.iastate.edu 2.6.9-22.0.1.ELsmp #1 SMP Tue Oct 18
18:39:02 EDT 2005 x86_64 x86_64 x86_64 GNU/Linux

Any help appreciated,

--
Andrew Bell
andrew.bell.ia@gmail.com
From shomano at hotmail.com  Tue Jan 24 09:32:49 2006
From: shomano at hotmail.com (Jean-Francois Allard)
Date: Tue Jan 24 09:32:52 2006
Subject: [antlr-interest] A newbie question about warning:nondeterminism and
	Parser
Message-ID: <BAY108-F3764128EC7995EBF71AFB6B6130@phx.gbl>

An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060124/c93a5c60/attachment-0001.html
From gudnabrsam at yahoo.com  Tue Jan 24 10:23:00 2006
From: gudnabrsam at yahoo.com (Matt Benson)
Date: Tue Jan 24 10:23:03 2006
Subject: [antlr-interest] 2.7.6 makes more output files than 2.7.5?
In-Reply-To: <200601240243.k0O2hc7Q007563@s2.eroute.net>
Message-ID: <20060124182300.57627.qmail@web30915.mail.mud.yahoo.com>

Hmm... I'm not a user, I'm the Ant gang.  Apparently I
missed the end result of the conversation on the
task... or was not part of some other discussion with
some other part of the Ant gang.

br,
Matt

--- Scott Stanchfield <scott@javadude.com> wrote:

> After working with the ant gang, we decided not to
> update the antlr task.
> 
> I'd recommend using the existing task unless you
> need a new option, in which
> case you can always use the <java> task instead.
> 
> Sorry...
> --Scott 
> 
> > -----Original Message-----
> > From: Matt Benson [mailto:gudnabrsam@yahoo.com] 
> > Sent: Monday, January 23, 2006 12:47 PM
> > To: Scott Stanchfield; Antlr List
> > Subject: Re: [antlr-interest] 2.7.6 makes more
> output files 
> > than 2.7.5?
> > 
> > Thanks, Scott.  They were breaking a unit test for
> the Ant 
> > task; I modified the test to ignore them.  Any
> update on the 
> > proposed rewrite of the task?
> > 
> 
> 
> 


__________________________________________________
Do You Yahoo!?
Tired of spam?  Yahoo! Mail has the best spam protection around 
http://mail.yahoo.com 
From shomano at hotmail.com  Tue Jan 24 12:19:37 2006
From: shomano at hotmail.com (Jean-Francois Allard)
Date: Tue Jan 24 12:19:41 2006
Subject: [antlr-interest] A newbie question about warning:nondeterminism and
	Parser
Message-ID: <BAY108-F7F68D2FD0E5D7EFEB41F2B6130@phx.gbl>

Sorry, forgot to diseable HTML editor in previous post...

--------------------------------------------------------------

Hi,

    I am working on a grammar for a very small query language.  The problem 
I get is that for this language, operators (and or) may sometime be a 
litteral, sometime be part of the condition expressions.

    Currently, I get a "warning:nondeterminism" problem as soon as I add 
theses operators to the condition expressions rules.  Is there any way to 
solve it?  I know it is possible to ends up with very bizarre constructs, 
like (or and or or)  In that case, the last matching conditional expression 
should be returned and other token should not be treated as operators:
((or and) OR (or)).

Parser rules:

query
    :   (orExpr)* EOF^
    ;
subExpr
    :   (PAREN_OPEN_ PAREN_CLOSE_) => (PAREN_OPEN_! PAREN_CLOSE_!)
    |   PAREN_OPEN_^ (orExpr)* PAREN_CLOSE_!
    ;
orExpr
    :   andExpr (OR_^ andExpr (OR_! andExpr)*)?
    ;
andExpr
    :   condExpr (AND_^ condExpr (AND_! condExpr)*)?
    ;
condExpr
    : (atom | subExpr)
    ;
atom
    :   (WORD_) <== Would like to add OR_ and AND_ here if not a condition 
operator.
    ;

Thanks in advance
Jeff

_________________________________________________________________
Gardez le contr?le gr?ce ? la protection contre les fen?tres pop-up 
articul?e sur la technologie brevet?e Microsoft SmartScreen 
http://join.msn.com/?pgmarket=fr-ca&page=features/popup Commencez d?s 
maintenant ? profiter de tous les avantages de MSN Premium et obtenez les 
deux premiers mois GRATUITS*.

From scott at javadude.com  Tue Jan 24 13:07:17 2006
From: scott at javadude.com (Scott Stanchfield)
Date: Tue Jan 24 13:20:16 2006
Subject: [antlr-interest] 2.7.6 makes more output files than 2.7.5?
In-Reply-To: <20060124182300.57627.qmail@web30915.mail.mud.yahoo.com>
References: <200601240243.k0O2hc7Q007563@s2.eroute.net>
	<20060124182300.57627.qmail@web30915.mail.mud.yahoo.com>
Message-ID: <14685.65.114.139.158.1138136837.squirrel@www.javadude.com>

I'd have to dig up the notes, but the folks I chatted with said that the
new ant policy was that tool-specific tasks should be deployed with the
tool; they didn't want tool-specific tasks to be part of ant (nasty
maintenance...). I told them I'd work with Ter to get a new ant task
deployed with antlr.

However, the changes I was going to have in the ant task became moot once
I split out ANTXR (http://javadude.com/tools/antxr) from ANTLR, so I
dropped the whole thing.

The current task that comes with ant should still work (other than the
regression test breakage that you fixed).

Sorry for the confusion!
-- Scott

> Hmm... I'm not a user, I'm the Ant gang.  Apparently I
> missed the end result of the conversation on the
> task... or was not part of some other discussion with
> some other part of the Ant gang.
>
> br,
> Matt
>
> --- Scott Stanchfield <scott@javadude.com> wrote:
>
>> After working with the ant gang, we decided not to
>> update the antlr task.
>>
>> I'd recommend using the existing task unless you
>> need a new option, in which
>> case you can always use the <java> task instead.
>>
>> Sorry...
>> --Scott
>>
>> > -----Original Message-----
>> > From: Matt Benson [mailto:gudnabrsam@yahoo.com]
>> > Sent: Monday, January 23, 2006 12:47 PM
>> > To: Scott Stanchfield; Antlr List
>> > Subject: Re: [antlr-interest] 2.7.6 makes more
>> output files
>> > than 2.7.5?
>> >
>> > Thanks, Scott.  They were breaking a unit test for
>> the Ant
>> > task; I modified the test to ignore them.  Any
>> update on the
>> > proposed rewrite of the task?
>> >
>>
>>
>>
>
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>


From gudnabrsam at yahoo.com  Tue Jan 24 13:29:32 2006
From: gudnabrsam at yahoo.com (Matt Benson)
Date: Tue Jan 24 13:30:09 2006
Subject: [antlr-interest] 2.7.6 makes more output files than 2.7.5?
In-Reply-To: <14685.65.114.139.158.1138136837.squirrel@www.javadude.com>
Message-ID: <20060124212932.50378.qmail@web30914.mail.mud.yahoo.com>

Oh, your first reply "we decided not to update the
antlr task" referred to the one in Ant.  Right, a
rewritten task would be best hosted by ANTLR.  The
current task, from what I recall, is just not as
flexible as it could be... oh well.  :)

-Matt

--- Scott Stanchfield <scott@javadude.com> wrote:

> I'd have to dig up the notes, but the folks I
> chatted with said that the
> new ant policy was that tool-specific tasks should
> be deployed with the
> tool; they didn't want tool-specific tasks to be
> part of ant (nasty
> maintenance...). I told them I'd work with Ter to
> get a new ant task
> deployed with antlr.
> 
> However, the changes I was going to have in the ant
> task became moot once
> I split out ANTXR (http://javadude.com/tools/antxr)
> from ANTLR, so I
> dropped the whole thing.
> 
> The current task that comes with ant should still
> work (other than the
> regression test breakage that you fixed).
> 
> Sorry for the confusion!
> -- Scott
> 
> > Hmm... I'm not a user, I'm the Ant gang. 
> Apparently I
> > missed the end result of the conversation on the
> > task... or was not part of some other discussion
> with
> > some other part of the Ant gang.
> >
> > br,
> > Matt
> >
> > --- Scott Stanchfield <scott@javadude.com> wrote:
> >
> >> After working with the ant gang, we decided not
> to
> >> update the antlr task.
> >>
> >> I'd recommend using the existing task unless you
> >> need a new option, in which
> >> case you can always use the <java> task instead.
> >>
> >> Sorry...
> >> --Scott
> >>
> >> > -----Original Message-----
> >> > From: Matt Benson [mailto:gudnabrsam@yahoo.com]
> >> > Sent: Monday, January 23, 2006 12:47 PM
> >> > To: Scott Stanchfield; Antlr List
> >> > Subject: Re: [antlr-interest] 2.7.6 makes more
> >> output files
> >> > than 2.7.5?
> >> >
> >> > Thanks, Scott.  They were breaking a unit test
> for
> >> the Ant
> >> > task; I modified the test to ignore them.  Any
> >> update on the
> >> > proposed rewrite of the task?
> >> >
> >>
> >>
> >>
> >
> >
> > __________________________________________________
> > Do You Yahoo!?
> > Tired of spam?  Yahoo! Mail has the best spam
> protection around
> > http://mail.yahoo.com
> >
> 
> 
> 


__________________________________________________
Do You Yahoo!?
Tired of spam?  Yahoo! Mail has the best spam protection around 
http://mail.yahoo.com 
From dimax at gmx.de  Tue Jan 24 14:09:41 2006
From: dimax at gmx.de (dima)
Date: Tue Jan 24 14:04:08 2006
Subject: [antlr-interest] nondeterminism warning?
Message-ID: <000a01c62132$e035ee30$0201a8c0@dimax>

First of all, sorry for my english,

I have a problem with my C# grammer. It has non
keyword literals and if I try too add this words to 
identifier, I become this warning

her's simplified part of my grammer:

------------------------------
nonKeywords 
    : "assembly" | "type" ;

identifier
    : real_identifier | n:nonKeywords { #n.setType(ID); } ;

real_identifier!
    : ID ; 

c_unit
    : (global_attributes)* (class_declaration)* ;

class_declaration
    : (attributes)? "class" identifier SEMI! ;

global_attributes!
    : LBRACK "assembly" COLON attribute_list RBRACK ;

attributes
    : (attribute_section)+ ;

attribute_section!
    : LBRACK ("type" COLON)? attribute_list RBRACK ;

attribute_list 
    : attribute (COMMA! attribute)* ;

attribute!
    : identifier (attribute_arguments)? ;

attribute_arguments
    : LPAREN! (attribute_argument_list)? RPAREN! ;

attribute_argument_list
    : identifier (COMMA! identifier)* ;
-------------------------------

With this part, I become this warning:
    nondeterminism upon k==1:LBRACK k==2:"assembly" between alt 1 and exit branch of block

Without "assembly" in nonKeywords it works fine,
without global_attributes rule it works fine,
and without attributes rule it works fine too,
but all three together not.

Please help my to fix it.

Thanks!

Dima.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060124/15828b0e/attachment.html
From andrew.bell.ia at gmail.com  Tue Jan 24 15:16:35 2006
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue Jan 24 15:16:37 2006
Subject: [antlr-interest] C++ Crash in consumeUntil()
Message-ID: <e80abd30601241516t35d801a2h17b5c44900b62118@mail.gmail.com>

Hi,

I am throwing a SemanticException in a parser action.  It gets caught
by the default handler which catches the exception as a
RecognitionException.  The exception handler calls reportError() and
then dies when it calls recover().  Here's the stack trace:

#0  0x0000000000523cdd in antlr::TokenBuffer::LA ()
#1  0x000000000043d343 in antlr::Parser::consumeUntil ()
#2  0x00000000004bd227 in StageParser::stagename ()
#3  0x00000000004bd975 in StageParser::stage ()
#4  0x00000000004bdc3c in StageParser::lang ()

Since I didn't build with debug, I don't get all of the inlined code
in the trace.

Anyway, the problem seems to be that recover(), calls consume()
without regard to whether there is anything to consume.  This
condition would be caught by the assert clause in
CircularQueue::removeItems() in debug mode, but the assert is a NOOP
if not build with debug.  I think that part of this problem is that
there is an assumption that if an exception is thrown in an action, no
match has been made.  This is not the case in my circumstance.

Anyway, this seems to be a bug/hard to recognize issue in the C++
runtime.  Does anyone have any ideas on how to best deal with this?

Also, it has been about 7 years since I last used ANTLR and it STILL
doesn't appear have an option to set filename suffixes on generated
files for C++ output.  If I add such, would someone be willing to
accept/integrate?

Thanks in advance,

--
Andrew Bell
andrew.bell.ia@gmail.com
From vidar at hawkis.com  Tue Jan 24 15:31:36 2006
From: vidar at hawkis.com (Vidar =?iso-8859-1?q?H=E5kestad?=)
Date: Tue Jan 24 15:31:39 2006
Subject: [antlr-interest] Parsing Java: Missing parenthesis in AST for
	variable declaration?
Message-ID: <200601250031.36871.vidar@hawkis.com>

Hello.

I'm using one of the Java 1.5 parsers provided on the antlr home page.
In all of these grammars, there is a rule for handling declarations of 
variables specified like this:

variableDeclarator![AST mods, AST t]
	: id:IDENT
	  d:declaratorBrackets[t]
	  v:varInitializer
	  {
	    #variableDeclarator = 
#(#[VARIABLE_DEF,"VARIABLE_DEF"], mods,#(#[TYPE,"TYPE"],d), id, v);
	   System.err.println("Declaration: "+#variableDeclarator.toStringTree());
	   }
	;

(my formatting)
When this rule is applied to the following Java code (which is inside a 
method):

	String[] folders = path.list(new DirFilter()); // Find all folder entries

The output statement gives:

( VARIABLE_DEF
  MODIFIERS
  ( TYPE ( [ String ) ) folders 
( = ( EXPR ( ( ( . path list )
( ELIST ( EXPR ( new DirFilter ELIST ) ) ) ) ) ) )

which seems to be missing one closing parenthesis (11 and 10)? Is this 
intended behaviour, or is there some problem with the grammar?

Regards,
Hawkis
From sohail at taggedtype.net  Tue Jan 24 20:54:31 2006
From: sohail at taggedtype.net (Sohail Somani)
Date: Tue Jan 24 20:54:39 2006
Subject: [antlr-interest] anybody get bitten by ANTLR's AST interface
	requirement
In-Reply-To: <1138096792.7587.16.camel@siau.xhive.archipel>
References: <web-115263793@cgpsrv2.cis.mcmaster.ca>
	<A4A0AECE-BDD8-41AE-AD10-10378C5987D7@cs.usfca.edu>
	<1137714192.9792.5.camel@localhost.localdomain>
	<41fed8f80601191920t509acdcam5b1c35896e69806b@mail.gmail.com>
	<1137746963.9838.6.camel@localhost.localdomain>
	<1137808171.8158.0.camel@localhost.localdomain>
	<43D4C9AB.4000405@cal.interrasystems.com>
	<1138074868.8309.2.camel@localhost.localdomain>
	<1138096792.7587.16.camel@siau.xhive.archipel>
Message-ID: <1138164871.8050.3.camel@localhost.localdomain>

On Tue, 2006-01-24 at 10:59 +0100, Martin Probst wrote:
> In code:
> 
> class X { .. }
> class Y extends X { .. }
> 
> class A {
>   X foo();
> }
> 
> class B extends A {
>   Y foo(); // <-- !!!
> }
> 
> The class B with the overriding foo() returning Y was not possible
> before, and it can really enhance complicated APIs. E.g. if you move
> down the API abstraction level you can now have the more concrete
> classes also return more concrete types, and that is nice.

Yes, these are covariant returns types in C++. Thanks for clarifying!

From stanio at myrealbox.com  Wed Jan 25 01:05:27 2006
From: stanio at myrealbox.com (Stanimir Stamenkov)
Date: Wed Jan 25 01:09:57 2006
Subject: [antlr-interest] Inherit grammar and specify base scanner class
	at the same time
In-Reply-To: <43D4FC24.8000501@myrealbox.com>
References: <43D4FC24.8000501@myrealbox.com>
Message-ID: <43D73F57.2030800@myrealbox.com>

/Stanimir Stamenkov/:

> I've first tried 
> specifying the scanner class on the super grammar as:
> 
> class SuperLexer extends Lexer("name.stanio.MyScanner");
> 
> but the generated "MyLexer" was direct subclass of |antlr.CharScanner|

I can't manage to make it whatever I'm trying. :-1  I run:

antlr superlexer.g
antlr -glib superlexer.g mylexer.g

The generated "SuperLexer.java" extends |name.stanio.MyScanner| but 
"MyLexer.java" extends |antlr.CharScanner|, and if I specify:

class MyLexer extends SuperLexer("name.stanio.MyScanner");

the ANTLR tool reports an error. Could someone point me if it is a 
FAQ or well documented feature as I haven't been able to find more 
info on it.

-- 
Stanimir
-------------- next part --------------
/*
 *
 */

class SuperLexer extends Lexer("name.stanio.MyScanner");

WS : ( ' ' | '\t' | '\f' | '\r' | '\n' )+;
-------------- next part --------------
/*
 *
 */
header
{
package name.stanio;
}

class MyLexer extends SuperLexer; //("name.stanio.MyScanner");

COMMENT : "//" (~('\n'|'\r'))* ('\n'|'\r'('\n')?) { myFancyMethod(); };
-------------- next part --------------
package name.stanio;

import antlr.CharScanner;
import antlr.LexerSharedInputState;

public abstract class MyScanner extends CharScanner {

    public MyScanner(LexerSharedInputState inputState) {
        super(inputState);
    }
    
    protected void myFancyMethod() {
    	  System.out.println("Say \"Hi\"!");
    }

}
From ric.klaren at gmail.com  Wed Jan 25 04:41:28 2006
From: ric.klaren at gmail.com (Ric Klaren)
Date: Wed Jan 25 04:41:31 2006
Subject: [antlr-interest] C++ Crash in consumeUntil()
In-Reply-To: <e80abd30601241516t35d801a2h17b5c44900b62118@mail.gmail.com>
References: <e80abd30601241516t35d801a2h17b5c44900b62118@mail.gmail.com>
Message-ID: <bc607a4e0601250441g1d94b5d1gc57b56f019c392a5@mail.gmail.com>

On 1/25/06, Andrew Bell <andrew.bell.ia@gmail.com> wrote:
> I am throwing a SemanticException in a parser action.  It gets caught
> by the default handler which catches the exception as a
> RecognitionException.  The exception handler calls reportError() and
> then dies when it calls recover().  Here's the stack trace:
>
> #0  0x0000000000523cdd in antlr::TokenBuffer::LA ()
> #1  0x000000000043d343 in antlr::Parser::consumeUntil ()
> #2  0x00000000004bd227 in StageParser::stagename ()
> #3  0x00000000004bd975 in StageParser::stage ()
> #4  0x00000000004bdc3c in StageParser::lang ()
>
> Since I didn't build with debug, I don't get all of the inlined code
> in the trace.
>
> Anyway, the problem seems to be that recover(), calls consume()
> without regard to whether there is anything to consume.  This
> condition would be caught by the assert clause in
> CircularQueue::removeItems() in debug mode, but the assert is a NOOP
> if not build with debug.  I think that part of this problem is that
> there is an assumption that if an exception is thrown in an action, no
> match has been made.  This is not the case in my circumstance.

Could you cut this down to an small example+input that demonstrates it
and send it to me so I can look at stuff offline (currently without
internet which is quite a bother..)

> Anyway, this seems to be a bug/hard to recognize issue in the C++
> runtime.  Does anyone have any ideas on how to best deal with this?

You could try removing the assert and make removeItems just plain
return in those cases. The triggering of the assert sometimes points
at a problem in the grammar mostly related to rules matching nothing.
There are no clear pre/post conditons of many of these methods. As a
result I'm usually not really enthousiastic about changing something
without proper analysis.

Another (maybe better?) option is to override recover to check wether
the consume makes sense.

Throw something different than a semantic exception if that's an
option? And/or adapt the error handler for the case.

> Also, it has been about 7 years since I last used ANTLR and it STILL
> doesn't appear have an option to set filename suffixes on generated
> files for C++ output.  If I add such, would someone be willing to
> accept/integrate?

If it's a clean patch (e.g. implementing a C++ file level option) then
it should not be a problem to include. I prefer unified diffs or send
me the (minimally) changed files (starting from the latest release
preferably)

Cheers,

Ric
From news at admiraal.dds.nl  Wed Jan 25 08:00:09 2006
From: news at admiraal.dds.nl (A.J. Admiraal)
Date: Wed Jan 25 08:00:22 2006
Subject: [antlr-interest] Differences between ANTLR3 and ANTLR2
	tree-building operators
Message-ID: <op.s3xyqjaaqyjdlx@lex-workstation>

Hi,

I'm checking out some differences between ANTLR3 and ANTLR2 regarding the
tree-building operators. I've read the blog on trees
(http://www.antlr.org/blog/antlr3/trees.tml) and if I understand it
correctly, the ANTLR3 ^^ operator should behave exactly as the ANTLR2 ^
operator. I've done some experiments with the early access release from
December (ea7), but it seems there is a slight difference.

When I build a rule like this in ANTLR3:
A^^ (B C^^ D)+

And feed it with:
A B C D B C D

I get the following ast:
(C (C A B D) B D)


However when I do a similar thing in ANTLR2:
A^ (B C^ D)+

And feed it with:
A B C D B C D

I get the following ast:
(C (C (A B) D B) D)


It seems the ANTLR3 ^^ operator takes note of the parentheses so the C^^
takes the first B with it. Is this behavior intentional, or can it be
classified as a bug?


Another related question is how should these two operators work when
nested? For example when I do this:
A^^ ((B C^^) D^)

And feed it with:
A B C D B C D

I get:
(C (C A (D B))(D B))

Is this the correct behavior, or should it be different?


Thanks in advance,

Alex
From spa6 at sporty.org  Wed Jan 25 09:33:26 2006
From: spa6 at sporty.org (sporty)
Date: Wed Jan 25 09:21:59 2006
Subject: [antlr-interest] Understanding the Java Grammar, or Kelcy Grammer
Message-ID: <20060125173326.GA27281@sporty.org>

I read the Java grammar included w/ antlr, after trying to deal with mathematical equations.  I successfully got a parser in the form, similar to the java one, to work:

eplus  		  : NUMBER ((PLUS^|MINUS^) NUMBER)* ;
etimes        : eplus  ((TIMES^|DIV^) eplus)* ;
ecomp		  : etimes ((LT^|GT^|LTE^|GTE^) etimes)* };
eequal		  : ecomp  ((sequal|nsequal|NEQUAL|NNEQUAL) ecomp)* };
eor			  : eequal (OR^ eequal)* ;
eand		  : eor    (AND^ eor)* };

I can wholeheartedly accept that it works, but I do not understand why as yet.  I would expect and equation of the form 1*2+3*4+5 not to parse.  After it parses 1*2+3, I would expect it not to get to 4, since the token after 3 to be a *, and eplus specifies +'s and -'s to follow.

But it does, and it doesn't make sense.  Hepl?

Thanks,
-s
From matthias.gutheil at informatik.uni-mannheim.de  Wed Jan 25 11:25:29 2006
From: matthias.gutheil at informatik.uni-mannheim.de (Matthias Gutheil)
Date: Wed Jan 25 11:25:35 2006
Subject: [antlr-interest] LineNumber of JavaSource
Message-ID: <43D7D0A9.5060103@informatik.uni-mannheim.de>

Hello,

I am using the java15.g grammar from

http://www.antlr.org/grammar/1090713067533/index.html.

I need the linenumbers for all TokenTypes in my AST. I extended the 
AST-class and have linenumbers. But e.g. for CLASS_DEF or others there 
are no line numbers generated.

I coded a bit in the Recognizer and there are lineNumers for these 
Tokens, but then only

astFactory.create(CLASS_DEF, "CLASS_DEF")) is called, which constructs a 
node without linenumber.

When I change the grammer, I get another Recognizer and it would work. 
But I am not an expert in that (not yet), but I checked this for CLASS_DEF.

Is there another solution? The one with getting the linenumber from 
childs is not 100% correct.

Cheers
Matthias
			

-- 
Matthias Gutheil, Dipl. Inform.
Universit?t Mannheim
Lehrstuhl f?r Softwaretechnik
A5, 6, Geb?udeteil B
68131 Mannheim
Germany

E-Mail: matthias.gutheil@informatik.uni-mannheim.de
Tel: (+49) 621 181 3913
From seclib at seclib.com  Wed Jan 25 11:43:52 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Wed Jan 25 11:44:37 2006
Subject: [antlr-interest] Re: Understanding the Java Grammar,
	or Kelcy Grammer
In-Reply-To: <20060125173326.GA27281@sporty.org>
References: <20060125173326.GA27281@sporty.org>
Message-ID: <43D7D4F8.2030005@seclib.com>

sporty wrote:
> I read the Java grammar included w/ antlr, after trying to deal with mathematical equations.  I successfully got a parser in the form, similar to the java one, to work:
> 
> eplus  		  : NUMBER ((PLUS^|MINUS^) NUMBER)* ;
> etimes        : eplus  ((TIMES^|DIV^) eplus)* ;
> 
> I can wholeheartedly accept that it works, but I do not understand why as yet.  I would expect and equation of the form 1*2+3*4+5 not to parse.  After it parses 1*2+3, I would expect it not to get to 4, since the token after 3 to be a *, and eplus specifies +'s and -'s to follow.
> 

I suggest you run the code in a debugger to see how the parser works.
In short, if there is no "*"(I am talking things like (TIMES^|DIV^) 
eplus)*) in the rules, sure it won't. But in your case, when the parser 
sees TIMES after 3, it is back to the 'etimes' rules.



-- 
Xue Yong Zhi
http://seclib.blogspot.com

From seclib at seclib.com  Wed Jan 25 12:20:26 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Wed Jan 25 12:21:18 2006
Subject: [antlr-interest] Re: nondeterminism warning?
In-Reply-To: <000a01c62132$e035ee30$0201a8c0@dimax>
References: <000a01c62132$e035ee30$0201a8c0@dimax>
Message-ID: <43D7DD8A.3080400@seclib.com>


>  
> With this part, I become this warning:
>     nondeterminism upon k==1:LBRACK k==2:"assembly" between alt 1 and 
> exit branch of block
>  

Please be more clear with your question, which rule causes this 
warning(copy the entire antlr output please)?

If the warning comes from c_unit, it is because global_attributes and 
attribute_section can both start with LBRACK "assembly", and antlr can 
not distinguish when k = 2.

-- 
Xue Yong Zhi
http://seclib.blogspot.com

From seclib at seclib.com  Wed Jan 25 12:28:26 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Wed Jan 25 12:29:14 2006
Subject: [antlr-interest] Re: A newbie question about warning:nondeterminism
	and Parser
In-Reply-To: <BAY108-F7F68D2FD0E5D7EFEB41F2B6130@phx.gbl>
References: <BAY108-F7F68D2FD0E5D7EFEB41F2B6130@phx.gbl>
Message-ID: <43D7DF6A.9060600@seclib.com>

Jean-Francois Allard wrote:
> Sorry, forgot to diseable HTML editor in previous post...
> 
> --------------------------------------------------------------
> 
> Hi,
> 
>    I am working on a grammar for a very small query language.  The 
> problem I get is that for this language, operators (and or) may sometime 
> be a litteral, sometime be part of the condition expressions.
> 

You need to give some examples of the language. If the ambiguities can 
be avoided based on the "context", you can use syntax predict and 
semantic predict.

-- 
Xue Yong Zhi
http://seclib.blogspot.com

From dimax at gmx.de  Wed Jan 25 14:26:38 2006
From: dimax at gmx.de (Dima)
Date: Wed Jan 25 14:26:44 2006
Subject: [antlr-interest]  nondeterminism warning?
In-Reply-To: <43D7DD8A.3080400@seclib.com>
Message-ID: <20060125222641.0EECCDC75F@www.antlr.org>


>
> >  
> > With this part, I become this warning:
> >     nondeterminism upon k==1:LBRACK k==2:"assembly" between alt 1 and 
> > exit branch of block
> >  
>
> Please be more clear with your question, which rule causes this 
> warning(copy the entire antlr output please)?

> If the warning comes from c_unit, it is because global_attributes and 
> attribute_section can both start with LBRACK "assembly", and antlr can 
> not distinguish when k = 2.
>

Ok sorry, with k=2 it can't work, but I use k>=3.
It's true, the warning comes from c_unit.
With this rules global_attributes must be: 
	[ assembly : ...   (for k=3)
But attributes can be:
	[ assembly ] ... or
	[ assembly , ... or
	[ assembly ( ... or
	[ type :     ...
That's all not the same 

If I make attributes rule like this:
	LBRACK "type" COLON RBRACK
I get the same warning.
Antlr output:
	test1.g:39: warning:nondeterminism upon
	test1.g:39: 	k==1:LBRACK
	test1.g:39: 	k==2:"assembly"
	test1.g:39: 	k==3:COLON
	test1.g:39: 	between alt 1 and exit branch of block


Thanks!

Dima

From demakov at ispras.ru  Wed Jan 25 23:05:12 2006
From: demakov at ispras.ru (Alexey Demakov)
Date: Wed Jan 25 23:05:16 2006
Subject: [antlr-interest] Understanding the Java Grammar, or Kelcy Grammer
References: <20060125173326.GA27281@sporty.org>
Message-ID: <000c01c62246$d9e05290$8cc79553@marlboro>

Do you have EOF token referenced in parser?
If not, parser just stops without any errors messages
when it reaches unexpected token * after 1*2+3.

Regards,
Alexey

-----
Alexey Demakov
TreeDL: Tree Description Language: http://treedl.sourceforge.net
RedVerst Group: http://www.unitesk.com


----- Original Message ----- 
From: "sporty" <spa6@sporty.org>
To: <antlr-interest@antlr.org>
Sent: Wednesday, January 25, 2006 8:33 PM
Subject: [antlr-interest] Understanding the Java Grammar, or Kelcy Grammer


>I read the Java grammar included w/ antlr, after trying to deal with mathematical equations.  I successfully got a parser in the 
>form, similar to the java one, to work:
>
> eplus    : NUMBER ((PLUS^|MINUS^) NUMBER)* ;
> etimes        : eplus  ((TIMES^|DIV^) eplus)* ;
> ecomp   : etimes ((LT^|GT^|LTE^|GTE^) etimes)* };
> eequal   : ecomp  ((sequal|nsequal|NEQUAL|NNEQUAL) ecomp)* };
> eor   : eequal (OR^ eequal)* ;
> eand   : eor    (AND^ eor)* };
>
> I can wholeheartedly accept that it works, but I do not understand why as yet.  I would expect and equation of the form 1*2+3*4+5 
> not to parse.  After it parses 1*2+3, I would expect it not to get to 4, since the token after 3 to be a *, and eplus specifies 
> +'s and -'s to follow.
>
> But it does, and it doesn't make sense.  Hepl?
>
> Thanks,
> -s 


From ric.klaren at gmail.com  Thu Jan 26 01:47:31 2006
From: ric.klaren at gmail.com (Ric Klaren)
Date: Thu Jan 26 01:47:35 2006
Subject: [antlr-interest] Inherit grammar and specify base scanner class
	at the same time
In-Reply-To: <43D73F57.2030800@myrealbox.com>
References: <43D4FC24.8000501@myrealbox.com> <43D73F57.2030800@myrealbox.com>
Message-ID: <bc607a4e0601260147y6d656d6bsf884b8763172ed1a@mail.gmail.com>

Hi,

On 1/25/06, Stanimir Stamenkov <stanio@myrealbox.com> wrote:
> /Stanimir Stamenkov/:
>
> > I've first tried
> > specifying the scanner class on the super grammar as:
> >
> > class SuperLexer extends Lexer("name.stanio.MyScanner");
> >
> > but the generated "MyLexer" was direct subclass of |antlr.CharScanner|
>
> I can't manage to make it whatever I'm trying. :-1  I run:
>
> antlr superlexer.g
> antlr -glib superlexer.g mylexer.g
>
> The generated "SuperLexer.java" extends |name.stanio.MyScanner| but
> "MyLexer.java" extends |antlr.CharScanner|, and if I specify:
>
> class MyLexer extends SuperLexer("name.stanio.MyScanner");
>
> the ANTLR tool reports an error. Could someone point me if it is a
> FAQ or well documented feature as I haven't been able to find more
> info on it.

I would not be surprised if this is a bug. The inheritance thing isn't
the prettiest in the world. If you have to add/change a lot of action
code in the sub grammar then it's usually pretty much useless anyway.
(although some people seem to be happy with using it)

Cheers,

Ric
From ray at soartech.com  Thu Jan 26 06:57:28 2006
From: ray at soartech.com (David Ray)
Date: Thu Jan 26 06:57:26 2006
Subject: [antlr-interest] End of child list in tree parser
Message-ID: <43D8E358.2050102@soartech.com>

Hello,

In an ANTLR tree parser, is there any special token I can match against 
for "end of child list", kind of like EOF in a non-tree parser?  I'm 
writing a validator for the structure of my AST and I'd like to make 
sure there aren't any trailing nodes.

Something like this:

    formalParameter: #(FORMAL_PARAMETER IDENT IDENT *EOF*)

to ensure there are two and only two IDENT children of FORMAL_PARAMETER.

I know I can manually check getNextSibling() of the last child in a 
rule, but it would be cool if ANTLR did it for me :)

Thanks,
Dave
From seclib at seclib.com  Thu Jan 26 10:57:33 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Thu Jan 26 10:59:43 2006
Subject: [antlr-interest] Re: nondeterminism warning?
In-Reply-To: <20060125222641.0EECCDC75F@www.antlr.org>
References: <43D7DD8A.3080400@seclib.com>
	<20060125222641.0EECCDC75F@www.antlr.org>
Message-ID: <43D91B9D.7050206@seclib.com>

To understand this warning you have to be very familiar with "linear 
approximate lookahead".

I recommend the following articles:

http://www.antlr.org/doc/glossary.html#Linear_approximate_lookahead
and related entries in antlr's FAQ.
http://seclib.blogspot.com/2005/11/linear-approximate-lookahead.html

In your case, antlr needs to compute exit branch to know when to leave a 
loop, and it will use linear approximate lookahead(instead of full 
LL(K)) to do that. Normally there are several exit paths for a rule, for 
example:
"[ assembly {"
and "[ xxx :"

With linear approximate lookahead, antlr will compress them so you get 
the warning for "[ assembly  :".

You can check the generated code so if it is actually correct(there are 
a great chance it does even with the warning), if so we can shutdown the 
warning. Otherwise, use semantic predict or syntax predict.

Dima wrote:
>>> 
>>>With this part, I become this warning:
>>>    nondeterminism upon k==1:LBRACK k==2:"assembly" between alt 1 and 
>>>exit branch of block
>>> 
>>
>>Please be more clear with your question, which rule causes this 
>>warning(copy the entire antlr output please)?
> 
> 
>>If the warning comes from c_unit, it is because global_attributes and 
>>attribute_section can both start with LBRACK "assembly", and antlr can 
>>not distinguish when k = 2.
>>
> 
> 
> Ok sorry, with k=2 it can't work, but I use k>=3.
> It's true, the warning comes from c_unit.
> With this rules global_attributes must be: 
> 	[ assembly : ...   (for k=3)
> But attributes can be:
> 	[ assembly ] ... or
> 	[ assembly , ... or
> 	[ assembly ( ... or
> 	[ type :     ...
> That's all not the same 
> 
> If I make attributes rule like this:
> 	LBRACK "type" COLON RBRACK
> I get the same warning.
> Antlr output:
> 	test1.g:39: warning:nondeterminism upon
> 	test1.g:39: 	k==1:LBRACK
> 	test1.g:39: 	k==2:"assembly"
> 	test1.g:39: 	k==3:COLON
> 	test1.g:39: 	between alt 1 and exit branch of block
> 
> 
> Thanks!
> 
> Dima
> 
> 


-- 
Xue Yong Zhi
http://seclib.blogspot.com

From parrt at cs.usfca.edu  Thu Jan 26 14:10:13 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Thu Jan 26 14:10:16 2006
Subject: [antlr-interest] Differences between ANTLR3 and ANTLR2
	tree-building operators
In-Reply-To: <op.s3xyqjaaqyjdlx@lex-workstation>
References: <op.s3xyqjaaqyjdlx@lex-workstation>
Message-ID: <E8D42F64-A3BD-4CD5-9F84-9BD5A6F04A4B@cs.usfca.edu>


On Jan 25, 2006, at 8:00 AM, A.J. Admiraal wrote:

> Hi,
>
> I'm checking out some differences between ANTLR3 and ANTLR2  
> regarding the
> tree-building operators. I've read the blog on trees
> (http://www.antlr.org/blog/antlr3/trees.tml) and if I understand it
> correctly, the ANTLR3 ^^ operator should behave exactly as the  
> ANTLR2 ^
> operator. I've done some experiments with the early access release  
> from
> December (ea7), but it seems there is a slight difference.
>
> When I build a rule like this in ANTLR3:
> A^^ (B C^^ D)+
>
> And feed it with:
> A B C D B C D
>
> I get the following ast:
> (C (C A B D) B D)

That looks like a bug to me. :(  Thanks...added to list.

> Another related question is how should these two operators work when
> nested? For example when I do this:
> A^^ ((B C^^) D^)

i assume you have + on that loop...

> And feed it with:
> A B C D B C D
>
> I get:
> (C (C A (D B))(D B))
>
> Is this the correct behavior, or should it be different?

Ack.  Good question.  What is the "root of the current subtree" when  
D^ occurs?    Crap.  I think that it makes no sense to mix ^^ and ^,  
but I wonder what the proper thing to do is.  Should we make it  
illegal to mix?  Just subrules?  Hmm...

For now, can you use the -> notation?  Works much better, in general  
though for trees of unlimited height you usually need the operators.

Ter
From sunjigang1965 at yahoo.com.cn  Thu Jan 26 17:47:35 2006
From: sunjigang1965 at yahoo.com.cn (=?gb2312?q?=CB=EF=BC=CD=B8=D5?=)
Date: Thu Jan 26 17:47:44 2006
Subject: [antlr-interest] Could anyone give me an complete example using
	antlr to produce a compiler, type checking code generation
Message-ID: <20060127014735.93186.qmail@web15708.mail.cnb.yahoo.com>

Could anyone give me an complete example or available tutorial of using antlr to produce a compiler. What I mean how to do type checking with AST generated, code generation. 
   
  Thanks Jigang 

		
---------------------------------
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060127/0fc95420/attachment.html
From dimax at gmx.de  Fri Jan 27 07:15:52 2006
From: dimax at gmx.de (dima)
Date: Fri Jan 27 07:10:18 2006
Subject: [antlr-interest]  nondeterminism warning?
Message-ID: <001c01c62354$908491b0$0201a8c0@dimax>



> 
> 
> To understand this warning you have to be very familiar with "linear 
> approximate lookahead".
> 
> In your case, antlr needs to compute exit branch to know when to leave a 
> loop, and it will use linear approximate lookahead(instead of full 
> LL(K)) to do that. Normally there are several exit paths for a rule, for 
> example:
> "[ assembly {"
> and "[ xxx :"
>
> With linear approximate lookahead, antlr will compress them so you get 
> the warning for "[ assembly  :".
> 
 
 Many thanks Xue Yong Zhi!
It's 100% what you written.
 
My generated c_unit method has two if statements:
     1.  if((LA(1)==LBRACK) && (LA(2)==ASSEMBLY) && (LA(3)==COLON))
         {
               global_attributes();
         }
         ....
     2. if((LA(1)==CLASS || LA(1)==LBRACK))
         {
              class_declaration();
         }
 
 Both of them are true for "[ assembly :". Therefore I get this warning!
Nevertheless works my parser correct, because the global attributes will
be consumed on the first statement.
 
 So, over again
Many thanks!
 
 Dima.
From storri at torri.org  Fri Jan 27 16:55:03 2006
From: storri at torri.org (Stephen Torri)
Date: Fri Jan 27 16:55:06 2006
Subject: [antlr-interest] How to tell antlr to create a LALR(1) or LR(1)
	grammar
Message-ID: <1138409703.31013.3.camel@base.torri.org>

I have a grammar that will need left and right associative rules. As I
understand left associative rules they are recursive on the first
element:

A -> A + B |
     B

B -> 1

How do I setup my grammar file to create a parser that can handle left
recursion? Where in the manual is this for further reading?

Stephen

From prashant.deva at gmail.com  Fri Jan 27 18:49:15 2006
From: prashant.deva at gmail.com (Prashant Deva)
Date: Fri Jan 27 18:49:19 2006
Subject: [antlr-interest] How to tell antlr to create a LALR(1) or LR(1)
	grammar
In-Reply-To: <1138409703.31013.3.camel@base.torri.org>
References: <1138409703.31013.3.camel@base.torri.org>
Message-ID: <41fed8f80601271849k29ab4623lc50211da9c6b9542@mail.gmail.com>

ANTLR can generate only LL(k) grammars.

--
Prashant Deva
Creator, ANTLR Studio
Founder, Placid Systems, www.placidsystems.com
From parrt at cs.usfca.edu  Fri Jan 27 22:21:36 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Fri Jan 27 22:21:42 2006
Subject: [antlr-interest] How to tell antlr to create a LALR(1) or LR(1)
	grammar
In-Reply-To: <1138409703.31013.3.camel@base.torri.org>
References: <1138409703.31013.3.camel@base.torri.org>
Message-ID: <D022A9ED-FC2C-4C46-BE98-A25F4D2FC4DA@cs.usfca.edu>

Hi.  You need to avoid left-recursion.  See the various grammars for  
examples of doing left-associative stuff in LL.  Better yet, look at  
the tutorial Scott Stanchfield did to see how to convert.  See any  
grammar/language theory book on left-recursion elimination.

Ter

On Jan 27, 2006, at 4:55 PM, Stephen Torri wrote:

> I have a grammar that will need left and right associative rules. As I
> understand left associative rules they are recursive on the first
> element:
>
> A -> A + B |
>      B
>
> B -> 1
>
> How do I setup my grammar file to create a parser that can handle left
> recursion? Where in the manual is this for further reading?
>
> Stephen
>

From vijay at mindspring.com  Sat Jan 28 08:53:19 2006
From: vijay at mindspring.com (Vijay K. Ganesan)
Date: Sat Jan 28 08:53:22 2006
Subject: [antlr-interest] Capturing Line numbers
Message-ID: <8856684.1138467199370.JavaMail.root@mswamui-swiss.atl.sa.earthlink.net>


I'm using antlr to parse java-like source code and build an AST. 
I'd like to invoke getLine() on the AST nodes to return the line number corresponding to the AST root's token. Currently it returns 0 always. I believe I need to create my own AST class that extends BaseAST/CommonAST?? Could someone please provide an example of how to go about doing this?
Thanks a lot.

Vijay
From parrt at cs.usfca.edu  Sat Jan 28 13:40:46 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Sat Jan 28 13:40:50 2006
Subject: [antlr-interest] ST 2.3b5 (java) available
Message-ID: <6B9C184F-B784-4B08-B7F3-5301FD675234@cs.usfca.edu>

Howdy, 2.3 coming within a month...this has group interface  
implementation and lots of cool stuff...doc not updated yet though.   
Some bugs to fix still.  Change list:

http://www.stringtemplate.org/bugs.tml

Ter
From thiago.arrais at gmail.com  Sun Jan 29 09:23:43 2006
From: thiago.arrais at gmail.com (Thiago Arrais)
Date: Sun Jan 29 09:23:47 2006
Subject: [antlr-interest] Capturing Line numbers
In-Reply-To: <8856684.1138467199370.JavaMail.root@mswamui-swiss.atl.sa.earthlink.net>
References: <8856684.1138467199370.JavaMail.root@mswamui-swiss.atl.sa.earthlink.net>
Message-ID: <e163e2f50601290923s53b0c4bbl@mail.gmail.com>

Vijay,

2006/1/28, Vijay K. Ganesan <vijay@mindspring.com>:
> I'd like to invoke getLine() on the AST nodes to return the line number corresponding to
> the AST root's token. Currently it returns 0 always.

That should mean you are using the default AST node class, which is
CommonAST. Take a look at the getLine and getColumn methods (inherited
from BaseAST):

    public int getLine() {
        return 0;
    }

    public int getColumn() {
        return 0;
    }

> I believe I need to create my own
> AST class that extends BaseAST/CommonAST?

Yep. From the above code excerpt, we can see that using BaseAST and
CommonAST for node classes won't do. We'll need to have a subclass of
them that records the location info and properly informs it when
asked.

Maybe there is some other standard way to do that (maybe antlr already
has a class that does that), but you can achieve it by creating your
own, say, MyAST class and using the parser's setASTNodeClass method.
By the way, the docs say to use the setASTNodeType method, but it is
currently deprecated (meaning its use is discouraged).

That MyAST class will need to override the initialize, getLine and
setLine methods. Initialize is where things get recorded. You can
write something like:

	public void initialize(Token tok) {
		super.initialize(tok);
		setLocation(tok.getLine(), tok.getColumn());
	}

And setup the get methods accordingly.

After this, you'll need to tell the parser to use the new MyAST class,
instead of CommonAST, when creating the nodes. I have done this by
calling the setASTNodeClass method just after the creation of the
parser and before the call to the grammar root method. Code looked a
lot like this:

        MyParser parser = new MyParser(...);
        parser.setASTNodeClass("org.example.antlr.ast");
        parser.expr();
        AST root = parser.getAST();

Maybe there is a more elegant way to do that (for example, by
injecting the call to the method inside the parser or even setting a
parser option on the grammar file to do the trick). But, being a antlr
newbie, that's the way I got around it.

Hope this helps.

Cheers,

Thiago Arrais
From craig.williams at free.fr  Sun Jan 29 10:57:43 2006
From: craig.williams at free.fr (Craig Williams)
Date: Sun Jan 29 10:57:51 2006
Subject: [antlr-interest] Backslash ambiguity in lexer
Message-ID: <002d01c62505$e379c3b0$c539933e@MOINIKA>

Hi!
  
How would you implement a lexer rule allowing single backslashes as well as normal escaped characters including double quotes within a string?
For instance if all the following are considered to be valid strings:

"asd\" "a\"b" "\"

The below grammar succeeds only for the 2nd case ("a\"b"), it does not resolve the ambiguity
when the last backslash in the string be interpreted as a lonely backslash, not as an escaped quote.

STRING_LITERAL
options { paraphrase = "string literal"; }
  : '"' (options {greedy=false;}: (ESC)=> ESC | BACKSLASH | ~'"' )* '"'
  ;

BACKSLASH
options { paraphrase = "backslash"; }
  : '\\'
  ;

protected
ESC : BACKSLASH
  ( 'n'  { $setText("\n"); }
  | 'r'  { $setText("\r"); }
  | 't'  { $setText("\t"); }
  | 'b'  { $setText("\b"); }
  | 'f'  { $setText("\f"); }
  | '"'  { $setText("\""); }
  | '\'' { $setText("\'"); }
  | BACKSLASH
  )

Any tips much appreciated...

CraigW
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060129/4691ab2b/attachment.html
From mansuk at gmail.com  Sun Jan 29 11:14:57 2006
From: mansuk at gmail.com (Suman Karumuri)
Date: Sun Jan 29 11:14:59 2006
Subject: [antlr-interest] Terence teaching grad programming language
	course starting monday
In-Reply-To: <030BD4C1-4DD0-4565-B0A8-5ACAB33086E0@cs.usfca.edu>
References: <030BD4C1-4DD0-4565-B0A8-5ACAB33086E0@cs.usfca.edu>
Message-ID: <c26541e00601291114ge8a3d3di9de0fdda5373389d@mail.gmail.com>

Hi Terence,

Will these lectuers also be recorded?If so, will they be sold/will be
put up on the site?

-Suman

On 1/20/06, Terence Parr <parrt@cs.usfca.edu> wrote:
> Hi,
>
> In case anybody is interested in taking or sitting in (auditing) my
> CS652 grad programming language course this semester (taught once
> every two years) at University of San Francisco, let me know.  To
> audit is cheap, $1200/semester.  We'll be doing lots of cool stuff
> and you'll definitely be a language animal when you're done (as well
> as an ANTLR maniac). :)
>
> I am revamping the course completely and hence my description is not
> quite done yet; I'll post the link soon.
>
> Regards,
> Terence
>
From aaanwar at yahoo.com  Sun Jan 29 12:51:45 2006
From: aaanwar at yahoo.com (Arman Anwar)
Date: Sun Jan 29 12:51:49 2006
Subject: [antlr-interest] Terence teaching grad programming language
	course starting monday
In-Reply-To: <c26541e00601291114ge8a3d3di9de0fdda5373389d@mail.gmail.com>
Message-ID: <20060129205145.10705.qmail@web52613.mail.yahoo.com>

My sentiments exactly,

I would like to attend but I live on the west coast.

Would there be any interest in doing this over the internet.

I would be willing to loan out a copy of polycom's pvx ... (or possibly
some polycom hardware) for this purpose.

If there is interest I could consider donating an movie editor's time
who would [I have to check on a resource I know about this]

Thanks,

Arman.

--- Suman Karumuri <mansuk@gmail.com> wrote:

> Hi Terence,
> 
> Will these lectuers also be recorded?If so, will they be sold/will be
> put up on the site?
> 
> -Suman
> 
> On 1/20/06, Terence Parr <parrt@cs.usfca.edu> wrote:
> > Hi,
> >
> > In case anybody is interested in taking or sitting in (auditing) my
> > CS652 grad programming language course this semester (taught once
> > every two years) at University of San Francisco, let me know.  To
> > audit is cheap, $1200/semester.  We'll be doing lots of cool stuff
> > and you'll definitely be a language animal when you're done (as
> well
> > as an ANTLR maniac). :)
> >
> > I am revamping the course completely and hence my description is
> not
> > quite done yet; I'll post the link soon.
> >
> > Regards,
> > Terence
> >
> 

From aaanwar at yahoo.com  Sun Jan 29 12:52:17 2006
From: aaanwar at yahoo.com (Arman Anwar)
Date: Sun Jan 29 12:52:19 2006
Subject: [correction west -> east ] Re: [antlr-interest] Terence teaching grad
	programming language course starting monday
In-Reply-To: <c26541e00601291114ge8a3d3di9de0fdda5373389d@mail.gmail.com>
Message-ID: <20060129205217.41438.qmail@web52612.mail.yahoo.com>

My sentiments exactly,

I would like to attend but I live on the east coast.

Would there be any interest in doing this over the internet.

I would be willing to loan out a copy of polycom's pvx ... (or possibly
some polycom hardware) for this purpose.

If there is interest I could consider donating an movie editor's time
who would [I have to check on a resource I know about this]

Thanks,

Arman.

--- Suman Karumuri <mansuk@gmail.com> wrote:

> Hi Terence,
> 
> Will these lectuers also be recorded?If so, will they be sold/will be
> put up on the site?
> 
> -Suman
> 
> On 1/20/06, Terence Parr <parrt@cs.usfca.edu> wrote:
> > Hi,
> >
> > In case anybody is interested in taking or sitting in (auditing) my
> > CS652 grad programming language course this semester (taught once
> > every two years) at University of San Francisco, let me know.  To
> > audit is cheap, $1200/semester.  We'll be doing lots of cool stuff
> > and you'll definitely be a language animal when you're done (as
> well
> > as an ANTLR maniac). :)
> >
> > I am revamping the course completely and hence my description is
> not
> > quite done yet; I'll post the link soon.
> >
> > Regards,
> > Terence
> >
> 

From vijay at mindspring.com  Sun Jan 29 17:00:25 2006
From: vijay at mindspring.com (Vijay K. Ganesan)
Date: Sun Jan 29 17:00:28 2006
Subject: [antlr-interest] Capturing Line numbers
Message-ID: <27493185.1138582825750.JavaMail.root@mswamui-swiss.atl.sa.earthlink.net>


Thanks for your recommendation. Unfortunately this does not work when I have "anonymous" tokens such as DECLSTMT below:

declarationStmt!
    : v:declaration SEMI!
      {#declarationStmt = #([DECLSTMT, "DeclStmt"], #v);

In this scenario, the initialize method that gets called is:
public void initialize(int t, String txt) {
}
and not:
public void initialize(Token tok) {
}

Any ideas how I can handle this scenario?

Thanks
Vijay

-----Original Message-----
>From: Thiago Arrais <thiago.arrais@gmail.com>
>Sent: Jan 29, 2006 9:23 AM
>To: antlr-interest@antlr.org
>Subject: Re: [antlr-interest] Capturing Line numbers
>
>Vijay,
>
>2006/1/28, Vijay K. Ganesan <vijay@mindspring.com>:
>> I'd like to invoke getLine() on the AST nodes to return the line number corresponding to
>> the AST root's token. Currently it returns 0 always.
>
>That should mean you are using the default AST node class, which is
>CommonAST. Take a look at the getLine and getColumn methods (inherited
>from BaseAST):
>
>    public int getLine() {
>        return 0;
>    }
>
>    public int getColumn() {
>        return 0;
>    }
>
>> I believe I need to create my own
>> AST class that extends BaseAST/CommonAST?
>
>Yep. From the above code excerpt, we can see that using BaseAST and
>CommonAST for node classes won't do. We'll need to have a subclass of
>them that records the location info and properly informs it when
>asked.
>
>Maybe there is some other standard way to do that (maybe antlr already
>has a class that does that), but you can achieve it by creating your
>own, say, MyAST class and using the parser's setASTNodeClass method.
>By the way, the docs say to use the setASTNodeType method, but it is
>currently deprecated (meaning its use is discouraged).
>
>That MyAST class will need to override the initialize, getLine and
>setLine methods. Initialize is where things get recorded. You can
>write something like:
>
>	public void initialize(Token tok) {
>		super.initialize(tok);
>		setLocation(tok.getLine(), tok.getColumn());
>	}
>
>And setup the get methods accordingly.
>
>After this, you'll need to tell the parser to use the new MyAST class,
>instead of CommonAST, when creating the nodes. I have done this by
>calling the setASTNodeClass method just after the creation of the
>parser and before the call to the grammar root method. Code looked a
>lot like this:
>
>        MyParser parser = new MyParser(...);
>        parser.setASTNodeClass("org.example.antlr.ast");
>        parser.expr();
>        AST root = parser.getAST();
>
>Maybe there is a more elegant way to do that (for example, by
>injecting the call to the method inside the parser or even setting a
>parser option on the grammar file to do the trick). But, being a antlr
>newbie, that's the way I got around it.
>
>Hope this helps.
>
>Cheers,
>
>Thiago Arrais

From sunjigang1965 at yahoo.com.cn  Sun Jan 29 17:13:04 2006
From: sunjigang1965 at yahoo.com.cn (=?gb2312?q?=CB=EF=BC=CD=B8=D5?=)
Date: Sun Jan 29 17:13:09 2006
Subject: [antlr-interest] Could anyone extend the caculator with string /
	boolean types?
Message-ID: <20060130011304.57568.qmail@web15708.mail.cnb.yahoo.com>

      Could anyone extend the well known example http://www.cs.usfca.edu/~parrt/course/652/lectures/antlr.html with string or / and boolean data type(s)?
   




		
---------------------------------
 1G
 -  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060130/2a75493a/attachment.html
From jsamort at sympatico.ca  Sun Jan 29 17:44:05 2006
From: jsamort at sympatico.ca (Scott Amort)
Date: Sun Jan 29 17:44:10 2006
Subject: [antlr-interest] help requested for selective whitespace
Message-ID: <1138585445.7879.16.camel@localhost>

Hi All,

I'm working away at trying to understand ANTLR and compiler generation
in general.  The current project I am using to help in my learning is
the creation of scanner/parser for a textual musical description
language.  Things are going quite well, except that I have run into a
problem with whitespace.  Currently, my scanner is set to ignore
whitespace (with $setType(Token.SKIP);), so the parser has no knowledge
of any of the whitespace (or comments) contained in the original
document.  However, the description language requires whitespace in a
few instances, for example between musical note descriptions (musical
notes are described by note name, i.e. c, d, e, f..., etc. followed by
other additional data to specificy accidentals, octave and duration).
So, something like this:

a b c

is valid, while:

abc

is not.  My current scanner treats both those examples as equivalent,
since it is discarding whitespace.  Now, if I instead allow the scanner
to tokenize whitespace, the parser gets very confused as I cannot easily
or adequately address all possible locations of whitespace in the
original document.  So, what I am hoping is that there is a method to
selectively test for whitespace in certain cases, while ignoring all
other instances.  Would someone be able to point me in the right
direction?  Perhaps with additional reading or a simple example to get
me started?  Thanks very much for any help!

Best,
Scott

From mail at martin-probst.com  Mon Jan 30 03:16:28 2006
From: mail at martin-probst.com (Martin Probst)
Date: Mon Jan 30 03:16:32 2006
Subject: [antlr-interest] Capturing Line numbers
In-Reply-To: <27493185.1138582825750.JavaMail.root@mswamui-swiss.atl.sa.earthlink.net>
References: <27493185.1138582825750.JavaMail.root@mswamui-swiss.atl.sa.earthlink.net>
Message-ID: <1138619788.7862.9.camel@localhost.localdomain>



> declarationStmt!
>     : v:declaration SEMI!
>       {#declarationStmt = #([DECLSTMT, "DeclStmt"], #v);
> 
> In this scenario, the initialize method that gets called is:
> public void initialize(int t, String txt) {
> }
> and not:
> public void initialize(Token tok) {
> }
> 
> Any ideas how I can handle this scenario?

Well, either you set the lines manually, or you implement getLine() like
this:
public int getLine() {
  if (line == -1 && getFirstChild() != null)
    return getFirstChild().getLine();
  else
    return line;
}

E.g. if you don't have a line number set (and use -1 as the initial
value, like in this example) it will query any existing children. This
works pretty good as the most common usecase is to insert artificial
parent nodes to trees. If you reorder the subtrees you will have to do
some magic though (e.g. set manually).

Martin

From ewbank at gmail.com  Mon Jan 30 05:25:55 2006
From: ewbank at gmail.com (Bryan Ewbank)
Date: Mon Jan 30 05:25:58 2006
Subject: [antlr-interest] End of child list in tree parser
In-Reply-To: <43D8E358.2050102@soartech.com>
References: <43D8E358.2050102@soartech.com>
Message-ID: <dd3a065f0601300525t53ee7906gc1ff3ef4b7dea0fc@mail.gmail.com>

There's nothing directly in antlr; I've found it useful to create a
standard "nothingElse" production that reports an error if it matches
anything.  It keeps me honest in my tree parsing without being too
intrusive:

nothingElse [ ... ] // pass parent to this production, for error messages
:
   (
      err:. // any node matched is a problem...
      {
         // blammo - encountered node #err as illegal extra child of parent
      }
   )?
;

Now, use this wherever you need it.

formalParameter = #(op:FORMAL_PARAMETER IDENT IDENT nothingElse[op] ) ;

I use it in my audit tree walks, not in the main tree transformation
passes, simply to keep things separate and too allow easy removal of
the tree audits for production use.

On 1/26/06, David Ray <ray@soartech.com> wrote:
> In an ANTLR tree parser, is there any special token I can match against
> for "end of child list", kind of like EOF in a non-tree parser?  I'm
> writing a validator for the structure of my AST and I'd like to make
> sure there aren't any trailing nodes.
From dcaton at shorelinesoftware.com  Mon Jan 30 05:57:49 2006
From: dcaton at shorelinesoftware.com (Don Caton)
Date: Mon Jan 30 05:58:02 2006
Subject: [antlr-interest] Unicode
Message-ID: <003001c625a5$28633660$640fa8c0@ssdev1>

I know the subject of Unicode comes up now and again, but it seems to me
that at best, the offered solutions are a hack.

It seems that it would be difficult, it not impossible to create a Unicode
parser and lexer from Antlr, given the way it currently generates code (I'm
talking specifically about C++ output here).

The C++ code generator insists on using string, rather than a typedef or
#define that could be set to string or wstring.  And throughout the
generated code as well as the static code, char * is assumed rather than
TCHAR *, single byte literal strings are used, etc. etc.

What's the rationale for this?  Is there something obvious I'm overlooking?
Unicode isn't exactly a new concept.  Why are we limited to the relatively
ancient world of 7 or 8 bit character sets?   

It seems to me that a few typedefs or #defines would make creating true
Unicode lexers and parsers a no-brainer and wouldn't break anything for
those who still need ansi parsers.

BTW, I know you can get a true Unicode parser from the C# code generator,
but I need C++.

Don


From ric.klaren at gmail.com  Mon Jan 30 06:49:13 2006
From: ric.klaren at gmail.com (Ric Klaren)
Date: Mon Jan 30 06:49:20 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <003001c625a5$28633660$640fa8c0@ssdev1>
References: <003001c625a5$28633660$640fa8c0@ssdev1>
Message-ID: <bc607a4e0601300649u1001911bka87e6551797332be@mail.gmail.com>

Hi Don,

On 1/30/06, Don Caton <dcaton@shorelinesoftware.com> wrote:
> I know the subject of Unicode comes up now and again, but it seems to me
> that at best, the offered solutions are a hack.

I've heart of a few cases of at least some success with the approach
from the unicode example. (Still some trouble with string literal
testing)

> It seems that it would be difficult, it not impossible to create a Unicode
> parser and lexer from Antlr, given the way it currently generates code (I'm
> talking specifically about C++ output here).
>
> The C++ code generator insists on using string, rather than a typedef or
> #define that could be set to string or wstring.  And throughout the
> generated code as well as the static code, char * is assumed rather than
> TCHAR *, single byte literal strings are used, etc. etc.

The string/wstring thing can be solved to some extent with the unicode
examples approach. For general unicode support it's probably easiest
(and most portable) to build on top of ICU.
When working on the unicode example I tried to fix some issues with
the codegenerator. If more is needed I can give a hand (if time
permits)

> What's the rationale for this?

I don't think any rationale, it's old code ;) Although the standard
tools/libs provided for C++ to do unicode-ish things seem to be not
very standard across various compiler implementations, so that may
have been a reason not to bother. I came to be C++ maintainer at a
later point in time so no idea.

> Is there something obvious I'm overlooking?

I'm not sure if you've seen the latest unicode example, it provides a
framework (although you need to fill in some blanks) on how to get a
unicode stream read through the lexer and packaged up again for the
parser. I did not investigate in how far it can be made to play nice
with the AST stuff. There's not really a standard way on how unicode
is handled in C++ e.g. dealing with encodings from files on disk. I'm
not even sure if it is standardized how a wide string constant is
encoded (I thought it was implementation dependent but not 100% sure
from the top of my head).

> Unicode isn't exactly a new concept.  Why are we limited to the relatively
> ancient world of 7 or 8 bit character sets?

I hope to do better for the support lib for antlr3 (through the use of
templates it will be easier to plug stuff in but I'll probably
standardize on ICU (next to old school 8-bit)).

> It seems to me that a few typedefs or #defines would make creating true
> Unicode lexers and parsers a no-brainer and wouldn't break anything for
> those who still need ansi parsers.

If you can provide sane patches to do this I'm happy to incorporate
them in antlr2.

Cheers,

Ric
From stanio at myrealbox.com  Mon Jan 30 08:17:10 2006
From: stanio at myrealbox.com (Stanimir Stamenkov)
Date: Mon Jan 30 08:17:12 2006
Subject: [antlr-interest] Inherit grammar and specify base scanner class
	at the same time
In-Reply-To: <bc607a4e0601260147y6d656d6bsf884b8763172ed1a@mail.gmail.com>
References: <43D4FC24.8000501@myrealbox.com> <43D73F57.2030800@myrealbox.com>
	<bc607a4e0601260147y6d656d6bsf884b8763172ed1a@mail.gmail.com>
Message-ID: <43DE3C06.6060406@myrealbox.com>

/Ric Klaren/:
> On 1/25/06, Stanimir Stamenkov <stanio@myrealbox.com> wrote:
>>
>> if I specify:
>>
>> class MyLexer extends SuperLexer("name.stanio.MyScanner");
>>
>> the ANTLR tool reports an error.
> 
> I would not be surprised if this is a bug. The inheritance thing isn't 
> the prettiest in the world. If you have to add/change a lot of action 
> code in the sub grammar then it's usually pretty much useless anyway. 
> (although some people seem to be happy with using it)

Thank you for giving me a direction. Unfortunately I'm pretty new to 
ANTLR and the grammars in question are given on me, so I won't be 
able to make any significant modifications to them soon. Looking at 
the grammars I didn't actually see any rules/actions overridden, so 
I'll have to live with it and perform hacks as I find appropriate.

I've found the ANTLR feedback page [1] and I'll post a bug report 
for it.

[1] http://www.antlr.org/misc/feedback

-- 
Stanimir
From seclib at seclib.com  Mon Jan 30 08:30:20 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Mon Jan 30 08:31:28 2006
Subject: [antlr-interest] Re: Backslash ambiguity in lexer
In-Reply-To: <002d01c62505$e379c3b0$c539933e@MOINIKA>
References: <002d01c62505$e379c3b0$c539933e@MOINIKA>
Message-ID: <43DE3F1C.4070705@seclib.com>

Craig Williams wrote:
> Hi!
>  
> How would you implement a lexer rule allowing single backslashes as well 
> as normal escaped characters including double quotes within a string?
> For instance if all the following are considered to be valid strings:
>  
> "asd\" "a\"b" "\"
>  
> The below grammar succeeds only for the 2nd case ("a\"b"), it does not 
> resolve the ambiguity
> when the last backslash in the string be interpreted as a lonely 
> backslash, not as an escaped quote.
>  
> STRING_LITERAL
> options { paraphrase = "string literal"; }
>   : '"' (options {greedy=false;}: (ESC)=> ESC | BACKSLASH | ~'"' )* '"'
>   ;
>  

The language you described has ambiguity in it. So far there is no way 
to tell if \" is an escaped character or the end of the string. The 
parser does not know where to go after seeing \".

You have to add other elements into the language to aid the parser. For 
example, if your intention is " followed by a whitespace is the end of a 
string, then you need to tell antlr explicitly.

-- 
Xue Yong Zhi
http://seclib.blogspot.com

From admytren at engin.umich.edu  Mon Jan 30 11:14:00 2006
From: admytren at engin.umich.edu (Artem Dmytrenko)
Date: Mon Jan 30 11:14:03 2006
Subject: [antlr-interest] Syntactic predicates question
Message-ID: <Pine.GSO.4.63.0601301353570.9406@alumni.engin.umich.edu>

Another newbie question here :)

I'm running into some problems while using syntactic predicates to 
resolve between ambiguous grammar rules. Here's a snippet from my lexer:

protected ActionToken: ("Action" | 'A');
protected ID: ALPHA (ALPHA | DIGIT)+;

SyntacticPredicate:
   (ActionToken) => (ActionToken { $setType (ActionToken); } ) |
   (ID) => (ID { $setType (ID); } );

The expectation is that this rule will match either "Action" or "A" and 
tag it as ActionToken or it will match alphanumeric string that starts 
with a letter and mark it as ID. However when parsing a string like 
"A12345" the rule returns neither to the parser. Here's an example 
misparsing message that my parser emits:

line 1:94: expecting ID, found 'A'

It appears that the match is stuck in the middle - e.g. ActionToken rule 
rejected the string but ID did not match it. Is that the expected 
behavior for syntactic predicates? Are there any workarounds for this 
problem?

Thank you in advance for any help and/or pointers.

Sincerely,
Artem Dmytrenko
From seclib at seclib.com  Mon Jan 30 11:40:30 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Mon Jan 30 11:41:06 2006
Subject: [antlr-interest] Re: Syntactic predicates question
In-Reply-To: <Pine.GSO.4.63.0601301353570.9406@alumni.engin.umich.edu>
References: <Pine.GSO.4.63.0601301353570.9406@alumni.engin.umich.edu>
Message-ID: <43DE6BAE.9080307@seclib.com>



Artem Dmytrenko wrote:

> 
> line 1:94: expecting ID, found 'A'
> 
> It appears that the match is stuck in the middle - e.g. ActionToken rule 
> rejected the string but ID did not match it. Is that the expected 
> behavior for syntactic predicates? Are there any workarounds for this 
> problem?
> 

Your parser is thinking this way when parsing "A12345":

1. Try ActionToken, and match the first 'A'.
2. Try ActionToken again with the rest of the input "123456", do not match.
3. Then try ID, still no match.
4. Give you the warning.

Most of the time Antlr does not follow "the longest one that matches 
wins" rules.

-- 
Xue Yong Zhi
http://seclib.blogspot.com

From parrt at cs.usfca.edu  Mon Jan 30 12:07:07 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Mon Jan 30 12:07:11 2006
Subject: [antlr-interest] Terence teaching grad programming language
	course starting monday
In-Reply-To: <20060129205145.10705.qmail@web52613.mail.yahoo.com>
References: <20060129205145.10705.qmail@web52613.mail.yahoo.com>
Message-ID: <2B8808C6-29D2-4BAB-9EEA-5D44FA766919@cs.usfca.edu>

Hi, unfortunately I will be unable to do the recording this semester. :(

  Regards, Terence.
On Jan 29, 2006, at 12:51 PM, Arman Anwar wrote:

> My sentiments exactly,
>
> I would like to attend but I live on the west coast.
>
> Would there be any interest in doing this over the internet.
>
> I would be willing to loan out a copy of polycom's pvx ... (or  
> possibly
> some polycom hardware) for this purpose.
>
> If there is interest I could consider donating an movie editor's time
> who would [I have to check on a resource I know about this]
>
> Thanks,
>
> Arman.
>
> --- Suman Karumuri <mansuk@gmail.com> wrote:
>
>> Hi Terence,
>>
>> Will these lectuers also be recorded?If so, will they be sold/will be
>> put up on the site?
>>
>> -Suman
>>
>> On 1/20/06, Terence Parr <parrt@cs.usfca.edu> wrote:
>>> Hi,
>>>
>>> In case anybody is interested in taking or sitting in (auditing) my
>>> CS652 grad programming language course this semester (taught once
>>> every two years) at University of San Francisco, let me know.  To
>>> audit is cheap, $1200/semester.  We'll be doing lots of cool stuff
>>> and you'll definitely be a language animal when you're done (as
>> well
>>> as an ANTLR maniac). :)
>>>
>>> I am revamping the course completely and hence my description is
>> not
>>> quite done yet; I'll post the link soon.
>>>
>>> Regards,
>>> Terence
>>>
>>
>

From antlr at jazillian.com  Mon Jan 30 12:47:35 2006
From: antlr at jazillian.com (Andy Tripp)
Date: Mon Jan 30 12:49:41 2006
Subject: [antlr-interest] help requested for selective whitespace
In-Reply-To: <1138585445.7879.16.camel@localhost>
References: <1138585445.7879.16.camel@localhost>
Message-ID: <43DE7B67.2050209@jazillian.com>

I, too, need to keep whitespace (and newlines and comments). I do this 
so that I
can determine what code the comments "seem to go with" by analyzing the 
spacing and indentation.
I have the scanner keep all whitespace, and then do a little processing 
with the whitespace tokens
in the mix, and then remove all whitespace,newline, and comment tokens 
from token stream.
I just wrote Java code to manipulate Lists, didn't do it in ANTLR.

Andy

Scott Amort wrote:

>Hi All,
>
>I'm working away at trying to understand ANTLR and compiler generation
>in general.  The current project I am using to help in my learning is
>the creation of scanner/parser for a textual musical description
>language.  Things are going quite well, except that I have run into a
>problem with whitespace.  Currently, my scanner is set to ignore
>whitespace (with $setType(Token.SKIP);), so the parser has no knowledge
>of any of the whitespace (or comments) contained in the original
>document.  However, the description language requires whitespace in a
>few instances, for example between musical note descriptions (musical
>notes are described by note name, i.e. c, d, e, f..., etc. followed by
>other additional data to specificy accidentals, octave and duration).
>So, something like this:
>
>a b c
>
>is valid, while:
>
>abc
>
>is not.  My current scanner treats both those examples as equivalent,
>since it is discarding whitespace.  Now, if I instead allow the scanner
>to tokenize whitespace, the parser gets very confused as I cannot easily
>or adequately address all possible locations of whitespace in the
>original document.  So, what I am hoping is that there is a method to
>selectively test for whitespace in certain cases, while ignoring all
>other instances.  Would someone be able to point me in the right
>direction?  Perhaps with additional reading or a simple example to get
>me started?  Thanks very much for any help!
>
>Best,
>Scott
>
>  
>

From admytren at engin.umich.edu  Mon Jan 30 14:36:50 2006
From: admytren at engin.umich.edu (Artem Dmytrenko)
Date: Mon Jan 30 14:36:55 2006
Subject: [antlr-interest] Re: Syntactic predicates question
In-Reply-To: <43DE6BAE.9080307@seclib.com>
References: <Pine.GSO.4.63.0601301353570.9406@alumni.engin.umich.edu>
	<43DE6BAE.9080307@seclib.com>
Message-ID: <Pine.GSO.4.63.0601301716370.16009@alumni.engin.umich.edu>

Hmm, I'm really confused by the behavior then. "A12345" definitely doesn't 
match rule 'A' so (1) should fail and not consume the first character of 
the string. Shouldn't ANTLR examine at least k characters (in my case 
k=2, so it should be looking at 'A' and '1') from input stream before 
making a decision about which token matched? The generated code for 
matching 'A' in lexer is as follows:

if ((LA(1)=='A') && (true)) {
   match('A');
}

Shouldn't it be something similar to the following?

if ((LA(1)=='A') && (LA(2)==END_OF_TOKEN) {
   match('A');
}

I'm trying to use syntactic predicates for parsing a language with 
keywords that may be part of identifiers (e.g. keyword "Action", 
identifier "Action/*/123"). Is there a better approach than syntactic 
predicates to attack this scenario?

Thank you again for your help.

Sincerely,
Artem Dmytrenko

On Mon, 30 Jan 2006, Xue Yong Zhi wrote:

>
>
> Artem Dmytrenko wrote:
>
>> 
>> line 1:94: expecting ID, found 'A'
>> 
>> It appears that the match is stuck in the middle - e.g. ActionToken rule 
>> rejected the string but ID did not match it. Is that the expected behavior 
>> for syntactic predicates? Are there any workarounds for this problem?
>> 
>
> Your parser is thinking this way when parsing "A12345":
>
> 1. Try ActionToken, and match the first 'A'.
> 2. Try ActionToken again with the rest of the input "123456", do not match.
> 3. Then try ID, still no match.
> 4. Give you the warning.
>
> Most of the time Antlr does not follow "the longest one that matches wins" 
> rules.
>
> -- 
> Xue Yong Zhi
> http://seclib.blogspot.com
>
>
From xx_ayu at hotmail.com  Mon Jan 30 15:43:13 2006
From: xx_ayu at hotmail.com (Zack Nammari)
Date: Mon Jan 30 15:43:17 2006
Subject: [antlr-interest] Help with Tree Parser (ANTLR 2.7.5)
Message-ID: <BAY104-F40F6FBEB1D7B54C497F672FD090@phx.gbl>

An HTML attachment was scrubbed...
URL: http://www.antlr.org/pipermail/antlr-interest/attachments/20060130/7a04b68c/attachment.html
From jbarnesweb at yahoo.com  Tue Jan 31 00:29:31 2006
From: jbarnesweb at yahoo.com (Jeff Barnes)
Date: Tue Jan 31 00:29:41 2006
Subject: [antlr-interest] Help with Tree Parser (ANTLR 2.7.5)
Message-ID: <20060131082931.5951.qmail@web54505.mail.yahoo.com>

To the list this time...

Hi,

I'm not real experienced with ANTLR tree parsers, but
I believe what you are trying to accomplish is
something along the lines of this:

singleCommand returns [String s = null]
{
    int val;
    String id;
    boolean expr = false;
    String thenStr = null, elseStr = null;
}
:
   ...
    | #(D_SCIF expr=expression thenStr=singleCommand
elseStr=singleCommand) {s = "if "+expr+"\n"+thenStr
+"\nelse\n"+elseStr
    | #(D_SCWHILE expression singleCommand)
   ...
    ;

expression returns [boolean exprResult = false] :
...
//boolean expressions
...
;

Or you may be trying to do this, not sure which...
singleCommand returns [String s = null]
{
    int val;
    String id;
    boolean expr = false;
    String thenStr = null, elseStr = null;
}
   ...
    | #(D_SCIF expr=expression
            (
                 {expr}? singleCommand 
            |    singleCommand
            )
    | #(D_SCWHILE expression singleCommand)
   ...
    ;




--- Zack Nammari <xx_ayu@hotmail.com> wrote:


---------------------------------
Hello all,
 
I'm trying to use ANTLR 2.7.5 and Java to write a
small interpreter but I'm not sure how to get the tree
parser to branch on certain conditions.
 
A part of my tree parser grammer is below:
 
singleCommand
{
    int val;
    String id;
}
   ...
    | #(D_SCIF expression singleCommand singleCommand)
    | #(D_SCWHILE expression singleCommand)
   ...
    ;

I would like the D_SCIF to operate as follows:
 
if (expression == true)
  singleCommand
else
  singleCommand
 
... and for the D_SCWHILE:
 
while (expression == true)
  LOOP singleCommand
 
Is this possible???
 
I was hoping something like this would work:
 
#(D_SCIF val=expression { if (val) }singleCommand {
else }singleCommand)
 
... but curly brackets {} are needed for the if-else
to operate correctly and I can't find a way to include
them inside an action.
 
Thank you in advance for any help.
 
Kind regards,
 
Zack Nammari



=========
Jeff Barnes
(206)245-6100

There are two rules for being a successful consultant: Rule 1 - Don't tell people everything you know.
From antlr at shmuelhome.mine.nu  Tue Jan 31 00:33:24 2006
From: antlr at shmuelhome.mine.nu (shmuel siegel)
Date: Tue Jan 31 00:33:06 2006
Subject: [antlr-interest] Re: Syntactic predicates question
In-Reply-To: <Pine.GSO.4.63.0601301716370.16009@alumni.engin.umich.edu>
References: <Pine.GSO.4.63.0601301353570.9406@alumni.engin.umich.edu>	<43DE6BAE.9080307@seclib.com>
	<Pine.GSO.4.63.0601301716370.16009@alumni.engin.umich.edu>
Message-ID: <43DF20D4.5060000@shmuelhome.mine.nu>

Artem Dmytrenko wrote:
> match rule 'A' so (1) should fail and not consume the first character of 
> the string. Shouldn't ANTLR examine at least k characters (in my case 
> k=2, so it should be looking at 'A' and '1') from input stream before 
> making a decision about which token matched? The generated code for 
> matching 'A' in lexer is as follows:
> 
> if ((LA(1)=='A') && (true)) {
>   match('A');
> }
> 
> Shouldn't it be something similar to the following?
> 
> if ((LA(1)=='A') && (LA(2)==END_OF_TOKEN) {
>   match('A');
> }
> 

Why would you expect a lexer to look for more characters than was asked 
for. "A" is a valid ActionToken so when the lexer saw "A", it returned 
the "A". I would have called it an error if it had done anything else. 
If instead of ActionToken you used ActionToken WS in your predicate, or 
whatever could legally terminate ActionToken, the lexer should have 
returned the token that you wanted. There is nothing in your description 
that says that A of A12345 is not a valid ActionToken.

At least, this is how I understand lexers in general. Can someone with 
more knowledge verify or reject my assertion.

Shmuel


-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.375 / Virus Database: 267.14.25/246 - Release Date: 1/30/2006



-- 
No virus found in this outgoing message.
Checked by AVG Free Edition.
Version: 7.1.375 / Virus Database: 267.14.25/246 - Release Date: 1/30/2006

From dcaton at shorelinesoftware.com  Tue Jan 31 06:53:55 2006
From: dcaton at shorelinesoftware.com (Don Caton)
Date: Tue Jan 31 06:53:59 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <bc607a4e0601300649u1001911bka87e6551797332be@mail.gmail.com>
Message-ID: <006001c62676$294c4ae0$640fa8c0@ssdev1>

> Hi Don,

> The string/wstring thing can be solved to some extent with 
> the unicode examples approach. 

The "Unicode" example isn't a Unicode program though.  There's still hard
coded std::string, literal ansi strings, etc.  It might lex Unicode input,
but you still end up with code that is ansi, with UTF8 encoded strings.  A
reasonable solution in some cases perhaps, but not a true end-to-end Unicode
system.  

For a true Unicode program you need to use wstring, wcout, literal Unicode
strings, and so on.  All of which can be abstracted with a handful of
typedefs.  The Unicode example does a little of that by using the
'char_type' typedef.  That just needs to be continued throughout all the
code, including the generated code.

> For general unicode support 
> it's probably easiest (and most portable) to build on top of ICU.

ICU?

> I don't think any rationale, it's old code ;) Although the 
> standard tools/libs provided for C++ to do unicode-ish things 
> seem to be not very standard across various compiler 
> implementations, so that may have been a reason not to 
> bother. I came to be C++ maintainer at a later point in time 
> so no idea.

Understood.

> There's not really a standard way on how unicode is handled 
> in C++ e.g. dealing with encodings from files on disk. I'm 
> not even sure if it is standardized how a wide string 
> constant is encoded (I thought it was implementation 
> dependent but not 100% sure from the top of my head).

There are encoding prefixes in disk files, which I believe are standardized.
But that could be left to the end user, you just have to insure that you're
providing valid unicode input.

All of this could be encapsulated in #defines and typedefs though, and any
compiler that supports the standard C++ library should be able to handle it.
That could be abstracted out in config.hpp, perhaps something like:

#if defined( MSC_VER ) && defined( _UNICODE )
   #define ANTLR_UNICODE
#else
   ...  // other compilers that support unicode
#endif

#ifdef ANTLR_UNICODE
   typedef char_type   wchar_t;
   typedef string_type wstring;
   typedef stream_type wistream;
   #define _T( x ) L##x
#else
   typedef char_type   char;
   typedef string_type string;  
   typedef stream_type istream;
   #define _T( x ) x
#endif

and so on...

> If you can provide sane patches to do this I'm happy to 
> incorporate them in antlr2.

I'll take a look and see what I can do.  Problem is that I'm using a
customized version of the runtime stuff that inlines a lot of stuff, for
performance reasons.  Let me see what I can come up with.  

Don


From ric.klaren at gmail.com  Tue Jan 31 07:35:37 2006
From: ric.klaren at gmail.com (Ric Klaren)
Date: Tue Jan 31 07:35:39 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <006001c62676$294c4ae0$640fa8c0@ssdev1>
References: <bc607a4e0601300649u1001911bka87e6551797332be@mail.gmail.com>
	<006001c62676$294c4ae0$640fa8c0@ssdev1>
Message-ID: <bc607a4e0601310735r1e72193fy932626abdc26e28e@mail.gmail.com>

Hi,

On 1/31/06, Don Caton <dcaton@shorelinesoftware.com> wrote:
> > The string/wstring thing can be solved to some extent with
> > the unicode examples approach.
>
> The "Unicode" example isn't a Unicode program though.  There's still hard
> coded std::string, literal ansi strings, etc.  It might lex Unicode input,
> but you still end up with code that is ansi, with UTF8 encoded strings.  A
> reasonable solution in some cases perhaps, but not a true end-to-end Unicode
> system.

Yes true, it provides an example on how to make an antlr CharScanner
subclass that can deal with a certain kind of unicode input (UTF8) and
that can package the lexed tokens once more into something for backend
stuff. (in this case the choice was to reencode to UTF8 in
std::string's)

> For a true Unicode program you need to use wstring, wcout, literal Unicode
> strings, and so on.  All of which can be abstracted with a handful of
> typedefs.  The Unicode example does a little of that by using the
> 'char_type' typedef.  That just needs to be continued throughout all the
> code, including the generated code.

Agree, the runtime needs work and probably also the generated code.
The unicode example is a proof of concept thing. I lack a real
application to test the idea against and making it a standard feature
for antlr2.

> > For general unicode support
> > it's probably easiest (and most portable) to build on top of ICU.
>
> ICU?

This one:

http://www-306.ibm.com/software/globalization/icu/index.jsp

It seems to be one of the most portable ways of supporting unicode.
Although I'm reluctant to tie (part of) the antlr runtime to such a
big library.

> > There's not really a standard way on how unicode is handled
> > in C++ e.g. dealing with encodings from files on disk. I'm
> > not even sure if it is standardized how a wide string
> > constant is encoded (I thought it was implementation
> > dependent but not 100% sure from the top of my head).
>
> There are encoding prefixes in disk files, which I believe are standardized.

There might be issues when you want to do a compare between a
L"sumthin" (from say a literals table) with something you just got
from disk.. have to match the encoding and/or have both encoded
canonically (or what was the term in unicode) (it's been a while when
I looked into this, but there might be a few gotchas (or I'm
pessimistic ;) ))

> But that could be left to the end user, you just have to insure that you're
> providing valid unicode input.
>
> All of this could be encapsulated in #defines and typedefs though, and any
> compiler that supports the standard C++ library should be able to handle it.
> That could be abstracted out in config.hpp, perhaps something like:
>
> #if defined( MSC_VER ) && defined( _UNICODE )
>    #define ANTLR_UNICODE
> #else
>    ...  // other compilers that support unicode
> #endif
>
> #ifdef ANTLR_UNICODE
>    typedef char_type   wchar_t;
>    typedef string_type wstring;
>    typedef stream_type wistream;
>    #define _T( x ) L##x
> #else
>    typedef char_type   char;
>    typedef string_type string;
>    typedef stream_type istream;
>    #define _T( x ) x
> #endif
>
> and so on...
>
> > If you can provide sane patches to do this I'm happy to
> > incorporate them in antlr2.
>
> I'll take a look and see what I can do.  Problem is that I'm using a
> customized version of the runtime stuff that inlines a lot of stuff, for
> performance reasons.  Let me see what I can come up with.

I guess we'll see. What platform(s) are you working on? Once you have
something it might be an idea to do a sanity check against some other
os/compiler combinations to see how portable things are.

Cheers,

Ric
From mail at martin-probst.com  Tue Jan 31 07:49:19 2006
From: mail at martin-probst.com (Martin Probst)
Date: Tue Jan 31 07:49:25 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <bc607a4e0601310735r1e72193fy932626abdc26e28e@mail.gmail.com>
References: <bc607a4e0601300649u1001911bka87e6551797332be@mail.gmail.com>
	<006001c62676$294c4ae0$640fa8c0@ssdev1>
	<bc607a4e0601310735r1e72193fy932626abdc26e28e@mail.gmail.com>
Message-ID: <1138722559.18310.10.camel@localhost.localdomain>

Hi,

> > There are encoding prefixes in disk files, which I believe are standardized.

Well, on Windows boxes you have this horrible Byte Order Mark thing in
(some) text files. Unixes don't have something like that, the general
assumption (as far as I know) is that all files have to match the
encoding specified in LANG (LC_*) environment variables - everything
else is an error.

> There might be issues when you want to do a compare between a
> L"sumthin" (from say a literals table) with something you just got
> from disk.. have to match the encoding and/or have both encoded
> canonically (or what was the term in unicode) (it's been a while when
> I looked into this, but there might be a few gotchas (or I'm
> pessimistic ;) ))

The major problem is that even after you have both strings in the right
Unicode encoding (e.g. UTF-16) they might still be identical but
different. E.g. a German "?" (A-umlaut) can be expressed as a "a"
followed by the special character for a combining diaeresis mark or by
the direct symbol for an "?", depending on the normalization form of the
string. Probably the same for "ij" if that example is more appealing to
you ;-)

When I was using ANTLR/C++ I actually got along very good by treating
everything as UTF-8 and otherwise as "magic opaque values".

Martin

From dcaton at shorelinesoftware.com  Tue Jan 31 08:21:01 2006
From: dcaton at shorelinesoftware.com (Don Caton)
Date: Tue Jan 31 08:21:02 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <1138722559.18310.10.camel@localhost.localdomain>
Message-ID: <007401c62682$54119440$640fa8c0@ssdev1>

Martin:

> Well, on Windows boxes you have this horrible Byte Order Mark thing in
> (some) text files. Unixes don't have something like that, the 
> general assumption (as far as I know) is that all files have 
> to match the encoding specified in LANG (LC_*) environment 
> variables - everything else is an error.

There are many horrible things about Windows, but this isn't one of them.

http://www.unicode.org/faq/utf_bom.html#22

Don


From seclib at seclib.com  Tue Jan 31 08:36:18 2006
From: seclib at seclib.com (Xue Yong Zhi)
Date: Tue Jan 31 08:37:56 2006
Subject: [antlr-interest] Re: Syntactic predicates question
In-Reply-To: <43DF20D4.5060000@shmuelhome.mine.nu>
References: <Pine.GSO.4.63.0601301353570.9406@alumni.engin.umich.edu>	<43DE6BAE.9080307@seclib.com>	<Pine.GSO.4.63.0601301716370.16009@alumni.engin.umich.edu>
	<43DF20D4.5060000@shmuelhome.mine.nu>
Message-ID: <43DF9202.9010700@seclib.com>


> 
> Why would you expect a lexer to look for more characters than was asked 
> for. "A" is a valid ActionToken so when the lexer saw "A", it returned 
> the "A". I would have called it an error if it had done anything else. 


Shmuel is right. Google antlr and "whatever follows" you will find some 
useful discussion.

-- 
Xue Yong Zhi
http://seclib.blogspot.com

From dcaton at shorelinesoftware.com  Tue Jan 31 08:37:39 2006
From: dcaton at shorelinesoftware.com (Don Caton)
Date: Tue Jan 31 08:42:17 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <bc607a4e0601310735r1e72193fy932626abdc26e28e@mail.gmail.com>
Message-ID: <007801c62684$a6d93870$640fa8c0@ssdev1>

Ric:

> http://www-306.ibm.com/software/globalization/icu/index.jsp
> 
> It seems to be one of the most portable ways of supporting unicode.
> Although I'm reluctant to tie (part of) the antlr runtime to 
> such a big library.

I don't think anything like this is necessary. Let the end user determine
what the data actually represents and what encodings if any, are present.

The only thing I'm after here is to remove the assumption in ANTLR that
characters are 8 bits wide.  If you stick with the wide character support
that's in the std C++ library, I think that will be sufficient and eliminate
any portability concerns.

Antlr shouldn't worry about how something is encoded on disk or any of that,
it's up to the programmer to provide correct input and take those things
into consideration.  Just let me process 16-bit characters end-to-end and
store them in a wstring (or whatever I may choose to define as 'char_type'
and 'string_type').

> There might be issues when you want to do a compare between a 
> L"sumthin" (from say a literals table) with something you 
> just got from disk.. have to match the encoding and/or have 
> both encoded canonically (or what was the term in unicode) 
> (it's been a while when I looked into this, but there might 
> be a few gotchas (or I'm pessimistic ;) ))

That should be the end-user's responsibility to properly compare the two
strings.  Antlr should just compare them for binary equality.  Anything more
specific should be left for the end-user to override in a subclass, if
necessary.

> I guess we'll see. What platform(s) are you working on? 

Windows and Visual Studio 2005.

> Once 
> you have something it might be an idea to do a sanity check 
> against some other os/compiler combinations to see how 
> portable things are.

If it's properly abstracted, then any other compiler/os combination can just
define their own set of typedefs.  Or not, if they don't support Unicode.
By default, Antlr would continue to use 'char' and  'std::string' and
'istream' so it shouldn't create any portability or backwards compatibility
issues.

Don


From mail at martin-probst.com  Tue Jan 31 10:57:41 2006
From: mail at martin-probst.com (Martin Probst)
Date: Tue Jan 31 11:01:01 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <007401c62682$54119440$640fa8c0@ssdev1>
References: <007401c62682$54119440$640fa8c0@ssdev1>
Message-ID: <1138733861.9517.0.camel@localhost.localdomain>

> There are many horrible things about Windows, but this isn't one of them.
> 
> http://www.unicode.org/faq/utf_bom.html#22

Well I know it's standardised, it's just not used on Unix AFAIK. And I
think that's a good decision, with Unicode there is really no reason to
have a mixed-encoding system.

Martin

From thiago.arrais at gmail.com  Tue Jan 31 11:29:37 2006
From: thiago.arrais at gmail.com (Thiago Arrais)
Date: Tue Jan 31 11:29:39 2006
Subject: [antlr-interest] Keeping track of lengths
Message-ID: <e163e2f50601311129s12f2afaey@mail.gmail.com>

Has anyone tried to keep track of the lenghts of the language constructs?

For instance, suppose we are parsing a Java method

public void aMethod() {
    return;
}

I would like to record on the resulting AST node that the source code
for this method declaration is 38 characters long or, at least, that
it ends at line/column 3:2. How could we do that?

I have thought that the second (relaxed) version -- recording the end
token's position -- could be achieved by capturing the last token and
inspecting its source location. But there are some complications:

1. A rule calls other rules, so I don't ultimately know which token
ends a construct. I don't even necessarily know which child-rule was
applied at the end of the father-rule. This prevents me from capturing
the last token by using a label. Maybe there is something like a
getLastConsumedToken() method somewhere? (I couldn't find it). If not,
which would be an elegant way to implement it? Overriding the consume
method to store the last token?

2. On my context not all the tokens come directly from the underlying
input. Some of them are virtual tokens, created by a decorator token
stream that inserts them to help the parser. So, the method I want
would really rather be called getLastConsumedRealToken()

3. My parser is supposed to record the lengths of most constructs.
Inserting a call to the getLastConsumedToken (shall it really exist
somewhere) at the end of all rules as an action would be very
error-prone, and I would like to avoid it if possible. Is there a way
to insert a common action to be executed after every rule?

4. It would be very useful for me to have character length instead of
last token location info, if possible.

Any ideas?

Cheers,

Thiago Arrais
From duboimat at iro.umontreal.ca  Tue Jan 31 13:00:49 2006
From: duboimat at iro.umontreal.ca (duboimat@iro.umontreal.ca)
Date: Tue Jan 31 13:00:53 2006
Subject: [antlr-interest] How to duplicate a subtree into a tree
In-Reply-To: <e163e2f50601311129s12f2afaey@mail.gmail.com>
References: <e163e2f50601311129s12f2afaey@mail.gmail.com>
Message-ID: <20060131160049.ip0emcb74oswsc4g@webmail.iro.umontreal.ca>

Hello,

I would like to know how to duplicate a subtree to build a new one.
When I add two time the same subtree in a new one, my computer will stuck

like
klo.addChild(kl.getFirstChild());
klo.addChild(kl.getFirstChild());

thank you
Mat

----------------------------------------------------------------
This message was sent using IMP, the Internet Messaging Program.

From parrt at cs.usfca.edu  Tue Jan 31 13:47:22 2006
From: parrt at cs.usfca.edu (Terence Parr)
Date: Tue Jan 31 13:47:28 2006
Subject: [antlr-interest] added ANTLR v3 page
Message-ID: <D4E60F15-1DCB-4DB0-9D8D-E6B5B3E6DF1E@cs.usfca.edu>

Howdy,

I have finally added a description page for v3:

http://www.antlr.org/v3/index.html

Collects all the info into one place and has a brief description.

Also added links from the main page that are hard to miss. :)

Ter

From dev at arabink.com  Tue Jan 31 14:00:18 2006
From: dev at arabink.com (Gregg Reynolds)
Date: Tue Jan 31 14:00:50 2006
Subject: [antlr-interest] Unicode
In-Reply-To: <1138733861.9517.0.camel@localhost.localdomain>
References: <007401c62682$54119440$640fa8c0@ssdev1>
	<1138733861.9517.0.camel@localhost.localdomain>
Message-ID: <43DFDDF2.10609@arabink.com>

Martin Probst wrote:
>> There are many horrible things about Windows, but this isn't one of them.
>>
>> http://www.unicode.org/faq/utf_bom.html#22
> 
> Well I know it's standardised, it's just not used on Unix AFAIK. And I
> think that's a good decision, with Unicode there is really no reason to
> have a mixed-encoding system.

BOM is not an OS issue, nor is it about mixed-encodings; it addresses
the problem of hardware variance.  It's unavoidable; the "problem" is
simply how to manage the blessing of variety.  Software that can't
handle BOM?  Well, Milton said it best:

Wherefore did Nature powre her bounties forth,
With such a full and unwithdrawing hand,
Covering the earth with odours, fruits, and flocks,
Thronging the Seas with spawn innumerable,
But all to please, and sate the curious taste?
And set to work millions of spinning Worms,
That in their green shops weave the smooth-hair'd silk
To deck her Sons, and that no corner might
Be vacant of her plenty, in her own loyns
She hutch't th' all-worshipt ore, and precious gems
To store her children with; if all the world
Should in a pet of temperance feed on Pulse,
Drink the clear stream, and nothing wear but Freize,
Th' all-giver would be unthank't, would be unprais'd,
Not half his riches known, and yet despis'd,
And we should serve him as a grudging master,
As a penurious niggard of his wealth,
And live like Natures bastards, not her sons,
Who would be quite surcharged with her own weight,
And strangl'd with her waste fertility;
Th' earth cumber'd, and the wing'd air dark't with plumes,
The herds would over-multitude their Lords,
The Sea o'refraught would swell, and th' unsought diamonds
Would so emblaze the forhead of the Deep,
And so bestudd with Stars, that they below
Would grow inur'd to light, and com at last
To gaze upon the Sun with shameless brows.

So lest we live like Technology's bastards, not her sons, we should
support all the annoying Unicode stuff like BOM and canonical forms.

;)

-gregg

P.S.  This is an interesting page on cross-platform multibyte C stuff,
from the documentation of the libmba  ("A library of generic C modules")
library:

http://www.ioplex.com/~miallen/libmba/dl/docs/ref/text_details.html
From jsamort at sympatico.ca  Tue Jan 31 18:54:09 2006
From: jsamort at sympatico.ca (Scott Amort)
Date: Tue Jan 31 18:54:12 2006
Subject: [antlr-interest] help requested for selective whitespace
In-Reply-To: <1138585445.7879.16.camel@localhost>
References: <1138585445.7879.16.camel@localhost>
Message-ID: <1138762449.7476.8.camel@localhost>

On Sun, 2006-01-29 at 20:44 -0500, Scott Amort wrote:
> So, what I am hoping is that there is a method to
> selectively test for whitespace in certain cases, while ignoring all
> other instances.

Hi Again,

I read a recent post concerning 'Syntactic predicates' with some
interest, as it appears to be another way of looking at my problem.  The
author seemed to be wanting all whitespace separated values to be fully
evaluated as a token, not smaller segments (i.e. A of A12345 would match
as a token, instead of the entire unit being considered invalid).  This
is very similar to my wanting something like:

a b c

to be valid, but not:

abc

Anyways, I am still searching for a good means of only selectively
including whitespace.  I have read the field guide and its entry on
whitespace (http://www.antlr.org/article/whitespace/), and seem to
recall coming across a similar page that described the use of a hidden
token stream, but one that actually used the keyword 'hidden' as a token
in the parser, instead of requiring tree walker as in the example.  Does
this sound at all familiar to anyone?  I can't for the life of me find
that page again.

Thanks from a beginner just trying to figure things out!

Best,
Scott

From Scott.Case at ca.com  Tue Jan 31 21:52:47 2006
From: Scott.Case at ca.com (Case, Scott A)
Date: Tue Jan 31 21:52:51 2006
Subject: [antlr-interest] Unicode
Message-ID: <E2146407EB5E77429ACBE99BCBFA89323B9A96@USILMS14.ca.com>


>> There are many horrible things about Windows, but this isn't one of
them.
>> 
>> http://www.unicode.org/faq/utf_bom.html#22

> Well I know it's standardised, it's just not used on Unix AFAIK. And I
> think that's a good decision, with Unicode there is really no reason
to
> have a mixed-encoding system.

Here are my 2 cents regarding Unicode support.

There is a lot of data in existence that isn't encoded in Unicode so
even though Unicode is the primary encoding we process data in (for the
application area I handle), we must still be able to recognize and
convert data from other encodings and produce other encodings for
API/systems that don't support Unicode.  So multi/mixed encoding isn't
going away anytime soon - Unicode simply makes it easier to write code
with less dependence on knowing details about numerous other encodings.

We use a BOM and it simplified various things.  If all (internal & 3rd
party) libraries were able to guess encodings (reliably) then we
wouldn't need to use a BOM.  Since this isn't the case, with a BOM, we
are able to reuse data across platforms many times without needing to
convert the encoding (mainly endianess of UTF-16 in our case).  

Also, we use ICU4C (which is a fine library) and it simplifies our life
dramatically.  The choice of using it or not in an application (in our
case) is based on the need for a consistent representation for
particular libraries used and the performance characteristics the
application required.  The size of wchar on the various platforms can
vary and some libraries process data using a character size different
from the native wchar. So if processing little data and/or not using any
libraries with a different representation of UTF-16 - ICU might be
overkill.  For data intensive applications which require/process UTF-16
data represented differently than the native wchar - ICU is a great
choice.  The biggest pitfall is the (potential) need to convert data to
the native wchar for any required system/runtime calls.

So for Antlr v3, using typedefs for the character/string representation
is fine as long as the template/runtime support can account for a UTF-16
representation different than the native wchar.  i.e. for Antlr v3 C/C++
output, if the default runtime/templates/whatever used C runtime string
functions - it would not work for us if we needed to parse certain
UTF-16 data, we would need to re-implement the
runtime/templates/whatever using ICU so our code would work across
platforms. We tend to deem the cost of converting the data
representation (to/from wchar) as too high and make substantial attempts
to make it unnecessary.  

I'm also not sure about the use of straight binary comparisons
(mentioned in an earlier thread I think) - as someone else mentioned,
Unicode chars can be encoded in multiple ways and the options for
correct comparison involves either normalizing the data or using
comparison methods which account for denormalized data internally.  I
think that the second option would be preferred for us.  

So in general, if character/string types and all string processing
methods were defined in templates, it seems it would allow us to tailor
the behavior to our needs.  Hmm, I was kinda verbose - maybe I should
have just stuck with this paragraph.

- Scott

p.s. Thanks to Terence and all the people who are contributing!

